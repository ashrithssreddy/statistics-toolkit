{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0300ea",
   "metadata": {},
   "source": [
    "![Status: In Progress](https://img.shields.io/badge/status-in--progress-yellow)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-70%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green)\n",
    "\n",
    "<!-- ![Status: Complete](https://img.shields.io/badge/status-complete-brightgreen)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-95%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green) -->\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# 🧭 Causal Inference\n",
    "\n",
    "- [🎯 Introduction to Causal Inference](#intro)\n",
    "  - [🎓 What is Causal Inference?](#what-is-causal)\n",
    "  - [📌 Why go beyond Correlation?](#why-correlation)\n",
    "  - [🧭 Real-world problems that need causality](#real-world-examples)\n",
    "\n",
    "- [🧠 Core Concepts & Notation](#notation-assumptions)\n",
    "  - [🧮 Treatment, Outcome, Units](#treatment-outcome-units)\n",
    "  - [📐 Potential Outcomes (Rubin Causal Model)](#potential-outcomes)\n",
    "  - [🧵 Fundamental Problem of Causal Inference](#fundamental-problem)\n",
    "  - [🧠 Assumptions (SUTVA, Ignorability, Overlap)](#core-assumptions)\n",
    "\n",
    "- [🧪 Simulated Dataset Setup](#simulated-data)\n",
    "  - [🧬 Define treatment assignment logic](#treatment-logic)\n",
    "  - [🔬 Inject confounding intentionally](#inject-confounding)\n",
    "  - [🧊 Simulate potential outcomes + observed data](#simulate-outcomes)\n",
    "\n",
    "- [🚫 Naive Estimation](#naive-estimation)\n",
    "  - [❌ Simple difference in means](#diff-in-means)\n",
    "  - [⚠️ Bias due to confounding](#bias-confounding)\n",
    "\n",
    "- [🕸️ Causal Diagrams (DAGs)](#causal-diagrams)\n",
    "  - [🧿 Quick primer on DAGs](#primer-dags)\n",
    "  - [🕷️ Confounding vs. colliders vs. mediators](#confounder-collider-mediator)\n",
    "  - [🔗 What can/can’t be estimated just from data](#estimability-from-dags)\n",
    "\n",
    "- [🔍 Backdoor Adjustment Methods](#backdoor-adjustment)\n",
    "  - [🧾 Conditioning on confounders](#conditioning)\n",
    "  - [🕵️‍♂️ Stratification / Subgroup analysis](#stratification)\n",
    "  - [📊 Regression Adjustment](#regression-adjustment)\n",
    "  - [📌 Propensity Score Matching (PSM)](#psm)\n",
    "\n",
    "- [🎯 Instrumental Variables (IV)](#iv-methods)\n",
    "  - [🪝 When backdoor paths can’t be blocked](#when-use-iv)\n",
    "  - [🎯 Valid instrument conditions](#iv-conditions)\n",
    "  - [🧩 2-Stage Least Squares (2SLS)](#2sls)\n",
    "\n",
    "- [🧰 Double Machine Learning (DML)](#dml-methods)\n",
    "  - [🪛 Use ML models for nuisance functions](#ml-nuisance)\n",
    "  - [🧱 Residualization + orthogonalization logic](#residualization)\n",
    "  - [🧲 When to prefer over traditional regression](#dml-vs-regression)\n",
    "\n",
    "- [🌈 Heterogeneous Treatment Effects](#heterogeneous-effects)\n",
    "  - [🎨 ATE vs. CATE vs. ITE](#ate-cate-ite)\n",
    "  - [🌟 Uplift models and use cases](#uplift-usecases)\n",
    "  - [🧩 Tree-based methods (Causal Trees, Causal Forests)](#causal-forests)\n",
    "\n",
    "- [🧪 Placebo Tests & Robustness Checks](#placebo-robustness)\n",
    "  - [🧻 Randomized placebo treatments](#placebo)\n",
    "  - [⚗️ Sensitivity to unobserved confounding](#robustness)\n",
    "\n",
    "- [🧬 Counterfactual Thinking](#counterfactuals)\n",
    "  - [🤖 Predicting what would’ve happened](#what-if)\n",
    "  - [🔁 Usage in recommendation & personalization](#personalization)\n",
    "\n",
    "- [📌 Closing Notes](#closing-notes)\n",
    "  - [📝 Summary table of methods](#summary-table)\n",
    "  - [📋 When to use what](#method-choice)\n",
    "  - [📎 Causal vs Predictive mindset](#causal-vs-predictive)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65903c57",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# 🎯 Introduction to Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd39d98",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>🧠 Why this Notebook</h5>\n",
    "\n",
    "<p>Causal inference gives us the tools to answer \"what if\" questions — not just \"what is.\" In product, policy, medicine, and science, we often need to <strong>act</strong>, and actions require understanding their consequences.</p>\n",
    "\n",
    "<p>This field helps us:</p>\n",
    "<ul>\n",
    "  <li>Understand <strong>how</strong> and <strong>why</strong> outcomes change.</li>\n",
    "  <li>Move from data <em>descriptions</em> to data-<em>driven interventions</em>.</li>\n",
    "  <li>Avoid the trap of chasing noisy correlations.</li>\n",
    "</ul>\n",
    "\n",
    "<p>This notebook is a build-up from first principles to practical methods — with enough grounding to reason about experiments, models, and their assumptions clearly.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd6e5a",
   "metadata": {},
   "source": [
    "<a id=\"what-is-causal\"></a>\n",
    "#### 🎓 What is Causal Inference?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddec552",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>🎓 Causal inference is the process of estimating the <strong>effect</strong> of one variable (the treatment) on another (the outcome), holding all else constant.</h5>\n",
    "\n",
    "<p>The core idea is to estimate:</p>\n",
    "<blockquote>What would the outcome have been if the treatment had (or had not) occurred?</blockquote>\n",
    "\n",
    "<p>Unlike correlation or predictive modeling:</p>\n",
    "<ul>\n",
    "  <li>It asks <strong>counterfactual</strong> questions — what <em>would</em> have happened under different scenarios.</li>\n",
    "  <li>It requires <strong>assumptions</strong>, <strong>design</strong>, and often <strong>randomization</strong> or clever statistical tricks.</li>\n",
    "</ul>\n",
    "\n",
    "<p>At its heart, causal inference is about:</p>\n",
    "<ul>\n",
    "  <li>Designing better <strong>interventions</strong></li>\n",
    "  <li>Estimating <strong>treatment effects</strong></li>\n",
    "  <li>Avoiding misleading <strong>associational patterns</strong></li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e04cf",
   "metadata": {},
   "source": [
    "<a id=\"why-correlation\"></a>\n",
    "#### 📌 Why go beyond Correlation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7aa8cf",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>📌 Correlation can be dangerous when used as a proxy for causation.</h5>\n",
    "\n",
    "<p>Example: Ice cream sales are correlated with shark attacks. Should we ban dessert?  \n",
    "Clearly not — they’re both caused by heatwaves (a confounder).</p>\n",
    "\n",
    "<p>Correlation fails because it:</p>\n",
    "<ul>\n",
    "  <li>Ignores <strong>confounders</strong> (common causes of both variables)</li>\n",
    "  <li>Misses <strong>directionality</strong> (what affects what)</li>\n",
    "  <li>Can be driven by <strong>reverse causation</strong> or <strong>coincidence</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>Causal inference gives tools to:</p>\n",
    "<ul>\n",
    "  <li><strong>Identify</strong> confounding</li>\n",
    "  <li><strong>Design</strong> better studies (randomized or observational)</li>\n",
    "  <li><strong>Interpret</strong> results in terms of actionable causes</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd9a45",
   "metadata": {},
   "source": [
    "<a id=\"real-world-examples\"></a>\n",
    "#### 🧭 Real-world problems that need causality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cdc369",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>🧭 Correlation might be fine for dashboards. But when making <strong>decisions</strong>, causality is non-negotiable.</h5>\n",
    "\n",
    "<p>Examples:</p>\n",
    "<ul>\n",
    "  <li><strong>Product</strong>: Did that new button placement increase checkout, or was it a seasonal effect?</li>\n",
    "  <li><strong>Marketing</strong>: Did the email nudge lead to purchases, or did loyal users open it anyway?</li>\n",
    "  <li><strong>Policy</strong>: Did a tax cut help the economy, or was it already improving?</li>\n",
    "  <li><strong>Health</strong>: Does a drug reduce disease, or do healthier people tend to take it?</li>\n",
    "</ul>\n",
    "\n",
    "<p>These questions involve <strong>interventions</strong>, and only causal methods can tell us what would’ve happened under a different choice.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d999e6",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972fc15",
   "metadata": {},
   "source": [
    "<a id=\"notation-assumptions\"></a>\n",
    "# 🧠 Core Concepts & Notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb9997",
   "metadata": {},
   "source": [
    "<a id=\"treatment-outcome-units\"></a>\n",
    "#### 🧮 Treatment, Outcome, Units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7deb6",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Treatment (<code>T</code>)</strong>: The intervention or condition being tested (e.g., new design, drug, policy).</li>\n",
    "  <li><strong>Outcome (<code>Y</code>)</strong>: The result or metric affected by the treatment (e.g., click, recovery, score).</li>\n",
    "  <li><strong>Units (<code>i</code>)</strong>: The entities receiving treatment and producing outcomes (e.g., users, patients, schools).</li>\n",
    "</ul>\n",
    "\n",
    "<p>Each unit can receive a treatment or control, and we observe only one outcome — not both.</p>\n",
    "\n",
    "<p>This framing is universal and applies whether you're testing emails, ads, or vaccines.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e705a",
   "metadata": {},
   "source": [
    "<a id=\"potential-outcomes\"></a>\n",
    "#### 📐 Potential Outcomes (Rubin Causal Model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1931ace",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>The <strong>Potential Outcomes framework</strong> (aka Rubin Causal Model) imagines two parallel worlds for each unit:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><code>Y(1)</code>: Outcome if treated</li>\n",
    "  <li><code>Y(0)</code>: Outcome if not treated</li>\n",
    "</ul>\n",
    "\n",
    "<p>We define <strong>Individual Treatment Effect (ITE)</strong> as:</p>\n",
    "\n",
    "<blockquote>ITE = Y(1) - Y(0)</blockquote>\n",
    "\n",
    "<p><strong>Key idea:</strong></p>\n",
    "\n",
    "<p>Each unit has both potential outcomes — but we can only observe one. The other is <strong>counterfactual</strong>.</p>\n",
    "\n",
    "<p>This framework allows us to define:</p>\n",
    "\n",
    "<ul>\n",
    "  <li>ATE (Average Treatment Effect)</li>\n",
    "  <li>CATE (Conditional ATE, for subgroups)</li>\n",
    "</ul>\n",
    "\n",
    "<p>And formalizes why causal inference is hard: we never see both outcomes.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d3fd",
   "metadata": {},
   "source": [
    "<a id=\"fundamental-problem\"></a>\n",
    "#### 🧵 Fundamental Problem of Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f145ea",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>The <strong>Fundamental Problem of Causal Inference</strong>:</h5>\n",
    "\n",
    "<blockquote>For any individual, we can observe only one potential outcome — never both.</blockquote>\n",
    "\n",
    "<p>Example:</p>\n",
    "<ul>\n",
    "  <li>A user sees version A → you observe <code>Y(0)</code></li>\n",
    "  <li>You’ll never know what <code>Y(1)</code> would have been for that exact user</li>\n",
    "</ul>\n",
    "\n",
    "<p>This creates a missing data problem: the counterfactual is unobservable.</p>\n",
    "\n",
    "<p>To solve this, we rely on:</p>\n",
    "<ul>\n",
    "  <li><strong>Randomization</strong></li>\n",
    "  <li><strong>Modeling + assumptions</strong></li>\n",
    "  <li><strong>Matching or weighting approaches</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>All causal methods are, in some way, trying to <strong>approximate the missing counterfactual</strong>.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee05897",
   "metadata": {},
   "source": [
    "<a id=\"core-assumptions\"></a>\n",
    "#### 🧠 Assumptions (SUTVA, Ignorability, Overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed826353",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Causal inference relies heavily on assumptions — even when you don’t randomize.</p>\n",
    "\n",
    "<h5>Three core ones:</h5>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>SUTVA (Stable Unit Treatment Value Assumption)</strong><br>\n",
    "  → Your treatment doesn’t affect someone else’s outcome.<br>\n",
    "  → No interference across units.</li>\n",
    "\n",
    "  <li><strong>Ignorability (a.k.a. Unconfoundedness)</strong><br>\n",
    "  → Given the observed covariates, treatment assignment is as good as random.<br>\n",
    "  → This lets you use observed data for estimation.</li>\n",
    "\n",
    "  <li><strong>Overlap (a.k.a. Positivity)</strong><br>\n",
    "  → Every unit has a non-zero probability of receiving either treatment.<br>\n",
    "  → You can’t learn effects where there’s no variation.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Without these, causal estimates can be biased or undefined. Always question whether they hold before trusting results.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb1851",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361ddee",
   "metadata": {},
   "source": [
    "<a id=\"simulated-data\"></a>\n",
    "# 🧪 Simulated Dataset Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1f238",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Simulating data is the best way to <em>control the truth</em> when learning causal inference.</p>\n",
    "\n",
    "<p>Here’s why we simulate:</p>\n",
    "<ul>\n",
    "  <li>You get full knowledge of ground-truth treatment effects.</li>\n",
    "  <li>You can deliberately create <strong>confounding</strong>, <strong>bias</strong>, <strong>non-randomness</strong>.</li>\n",
    "  <li>You can practice recovering the true causal effect using different methods.</li>\n",
    "</ul>\n",
    "\n",
    "<p>In real-world observational data, the \"truth\" is hidden. Simulating lets you debug your causal intuition safely before dealing with messy production datasets.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cffe669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Dataset Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# We'll define features, treatment assignment, and outcomes step-by-step later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fe447",
   "metadata": {},
   "source": [
    "<a id=\"treatment-logic\"></a>\n",
    "#### 🧬 Define treatment assignment logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab191ac",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>To simulate treatment realistically:</p>\n",
    "<ul>\n",
    "  <li>Treatment should <strong>depend</strong> on observed features.</li>\n",
    "  <li>Treatment <strong>should not</strong> be random — otherwise, no confounding to deal with.</li>\n",
    "</ul>\n",
    "\n",
    "<p>For example:</p>\n",
    "<ul>\n",
    "  <li>Wealthier users might be more likely to receive a premium offer.</li>\n",
    "  <li>Healthier patients might be less likely to receive intensive care.</li>\n",
    "</ul>\n",
    "\n",
    "<p>We’ll simulate a <strong>non-random treatment assignment</strong> based on a few covariates to mimic real-world biases.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "541b4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define covariates (features)\n",
    "n = 5000\n",
    "\n",
    "age = np.random.normal(40, 12, n)       # Age\n",
    "income = np.random.normal(60000, 15000, n)  # Annual income\n",
    "prior_engagement = np.random.beta(2, 5, n)  # Past engagement score [0,1]\n",
    "\n",
    "# Treatment assignment probability based on features\n",
    "treatment_prob = (\n",
    "    0.3 * (income > 70000).astype(float) +\n",
    "    0.2 * (prior_engagement > 0.5).astype(float) +\n",
    "    0.1 * (age < 30).astype(float) +\n",
    "    np.random.normal(0, 0.05, n)  # small noise\n",
    ")\n",
    "treatment_prob = np.clip(treatment_prob, 0, 1)\n",
    "\n",
    "# Assign treatment\n",
    "T = np.random.binomial(1, treatment_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66180170",
   "metadata": {},
   "source": [
    "<a id=\"inject-confounding\"></a>\n",
    "#### 🔬 Inject confounding intentionally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6cc19a",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>In real-world datasets, treatment assignment is <strong>not random</strong> — it’s confounded by covariates.</p>\n",
    "\n",
    "<p>We deliberately inject confounding so that:</p>\n",
    "<ul>\n",
    "  <li>Covariates (age, income, engagement) affect both <strong>treatment</strong> and <strong>outcome</strong>.</li>\n",
    "  <li>If we naively compare treated vs untreated, we'll get biased results.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Confounding creates the need for adjustment, which will be a major theme later.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5463b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a \"true\" baseline outcome based on the same covariates\n",
    "base_outcome = (\n",
    "    50 + \n",
    "    0.02 * income +\n",
    "    5 * prior_engagement -\n",
    "    0.3 * age +\n",
    "    np.random.normal(0, 5, n)  # random noise\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca43ff",
   "metadata": {},
   "source": [
    "<a id=\"simulate-outcomes\"></a>\n",
    "#### 🧊 Simulate potential outcomes + observed data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4104ea8f",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>In the Rubin Potential Outcomes framework, each unit has two outcomes:</p>\n",
    "<ul>\n",
    "  <li><code>Y(1)</code> → If treated</li>\n",
    "  <li><code>Y(0)</code> → If not treated</li>\n",
    "</ul>\n",
    "\n",
    "<p>We can simulate this by:</p>\n",
    "<ul>\n",
    "  <li>Applying a <strong>true treatment effect</strong> to <code>Y(1)</code></li>\n",
    "  <li>Leaving <code>Y(0)</code> as the base outcome</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Important:</strong> We observe only one of <code>Y(1)</code> or <code>Y(0)</code>, depending on treatment assignment (<code>T</code>).</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79ae0cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>prior_engagement</th>\n",
       "      <th>T</th>\n",
       "      <th>Y_obs</th>\n",
       "      <th>Y_0</th>\n",
       "      <th>Y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.960570</td>\n",
       "      <td>53643.604770</td>\n",
       "      <td>0.188077</td>\n",
       "      <td>0</td>\n",
       "      <td>1114.502287</td>\n",
       "      <td>1114.502287</td>\n",
       "      <td>1124.502287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.340828</td>\n",
       "      <td>53198.788374</td>\n",
       "      <td>0.170389</td>\n",
       "      <td>0</td>\n",
       "      <td>1099.893323</td>\n",
       "      <td>1099.893323</td>\n",
       "      <td>1109.893323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.772262</td>\n",
       "      <td>33065.352411</td>\n",
       "      <td>0.511379</td>\n",
       "      <td>0</td>\n",
       "      <td>704.133035</td>\n",
       "      <td>704.133035</td>\n",
       "      <td>714.133035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.276358</td>\n",
       "      <td>55048.647124</td>\n",
       "      <td>0.318793</td>\n",
       "      <td>0</td>\n",
       "      <td>1139.203509</td>\n",
       "      <td>1139.203509</td>\n",
       "      <td>1149.203509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.190160</td>\n",
       "      <td>70992.436227</td>\n",
       "      <td>0.384439</td>\n",
       "      <td>0</td>\n",
       "      <td>1464.308234</td>\n",
       "      <td>1464.308234</td>\n",
       "      <td>1474.308234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age        income  prior_engagement  T        Y_obs          Y_0  \\\n",
       "0  45.960570  53643.604770          0.188077  0  1114.502287  1114.502287   \n",
       "1  38.340828  53198.788374          0.170389  0  1099.893323  1099.893323   \n",
       "2  47.772262  33065.352411          0.511379  0   704.133035   704.133035   \n",
       "3  58.276358  55048.647124          0.318793  0  1139.203509  1139.203509   \n",
       "4  37.190160  70992.436227          0.384439  0  1464.308234  1464.308234   \n",
       "\n",
       "           Y_1  \n",
       "0  1124.502287  \n",
       "1  1109.893323  \n",
       "2   714.133035  \n",
       "3  1149.203509  \n",
       "4  1474.308234  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a true treatment effect (could vary by subgroup later)\n",
    "true_treatment_effect = 10  # a flat +10 effect for everyone\n",
    "\n",
    "# Simulate potential outcomes\n",
    "Y_0 = base_outcome\n",
    "Y_1 = base_outcome + true_treatment_effect\n",
    "\n",
    "# Observed outcome based on treatment assignment\n",
    "Y_obs = T * Y_1 + (1 - T) * Y_0\n",
    "\n",
    "# Assemble into a dataframe\n",
    "df = pd.DataFrame({\n",
    "    'age': age,\n",
    "    'income': income,\n",
    "    'prior_engagement': prior_engagement,\n",
    "    'T': T,\n",
    "    'Y_obs': Y_obs,\n",
    "    'Y_0': Y_0,\n",
    "    'Y_1': Y_1,\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49e27e",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dde548",
   "metadata": {},
   "source": [
    "<a id=\"naive-estimation\"></a>\n",
    "# 🚫 Naive Estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4860605",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Many causal questions are first attacked by simply comparing the treated vs. untreated groups.</p>\n",
    "\n",
    "<p><strong>Naive Approach:</strong></p>\n",
    "<blockquote>Average outcome of treated - Average outcome of untreated.</blockquote>\n",
    "\n",
    "<p>This looks simple, but in observational data:</p>\n",
    "<ul>\n",
    "  <li>Treated and untreated units <strong>are not comparable</strong>.</li>\n",
    "  <li>Treatment assignment was <strong>not randomized</strong>.</li>\n",
    "  <li>Differences in baseline characteristics confound the simple difference.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Naive estimation <strong>almost always gives biased results</strong> unless you have perfect randomization.</p>\n",
    "\n",
    "<p>In this section, we'll see how bad the naive approach can get even on a simple synthetic dataset.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b2c08e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive difference in means: 250.53\n",
      "True treatment effect (ground truth): 10\n"
     ]
    }
   ],
   "source": [
    "# Quick naive estimation\n",
    "treated_mean = df.loc[df['T'] == 1, 'Y_obs'].mean()\n",
    "control_mean = df.loc[df['T'] == 0, 'Y_obs'].mean()\n",
    "\n",
    "naive_diff = treated_mean - control_mean\n",
    "\n",
    "print(f\"Naive difference in means: {naive_diff:.2f}\")\n",
    "print(f\"True treatment effect (ground truth): {true_treatment_effect}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc35de",
   "metadata": {},
   "source": [
    "<a id=\"diff-in-means\"></a>\n",
    "#### ❌ Simple difference in means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83c050",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>A simple difference in means is mathematically:</p>\n",
    "<blockquote><code>E[Y | T=1] - E[Y | T=0]</code></blockquote>\n",
    "\n",
    "<p>If treatment assignment were random:</p>\n",
    "<ul>\n",
    "  <li>The two groups would be exchangeable.</li>\n",
    "  <li>Baseline covariates would balance on average.</li>\n",
    "  <li>The simple difference would be an unbiased estimator of ATE.</li>\n",
    "</ul>\n",
    "\n",
    "<p>But if treatment is <strong>confounded</strong>, then:</p>\n",
    "<ul>\n",
    "  <li><code>T=1</code> units may systematically differ from <code>T=0</code> units.</li>\n",
    "  <li>The naive estimator picks up both <strong>causal effect</strong> and <strong>selection bias</strong>.</li>\n",
    "</ul>\n",
    "\n",
    "<p>We’ll soon quantify how large this bias can be.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78ccff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>prior_engagement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.389926</td>\n",
       "      <td>58304.201745</td>\n",
       "      <td>0.278891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.892227</td>\n",
       "      <td>70283.224987</td>\n",
       "      <td>0.330779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age        income  prior_engagement\n",
       "T                                           \n",
       "0  40.389926  58304.201745          0.278891\n",
       "1  37.892227  70283.224987          0.330779"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's quickly visualize how the treated vs control groups differ in covariates\n",
    "df.groupby('T')[['age', 'income', 'prior_engagement']].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c7490",
   "metadata": {},
   "source": [
    "<a id=\"bias-confounding\"></a>\n",
    "#### ⚠️ Bias due to confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d8ecd",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Bias from confounding</strong> happens when:</p>\n",
    "<ul>\n",
    "  <li>The treated group has systematically different baseline outcomes than the control group.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Mathematically:</p>\n",
    "<blockquote>Observed difference = True treatment effect + Bias from baseline differences</blockquote>\n",
    "\n",
    "<p>In our simulation:</p>\n",
    "<ul>\n",
    "  <li>Higher income users are more likely to be treated.</li>\n",
    "  <li>Income also directly influences outcome.</li>\n",
    "  <li>Therefore, the observed difference <strong>overstates</strong> the real effect.</li>\n",
    "</ul>\n",
    "\n",
    "<p>This is why adjusting for confounders is critical — naive methods can easily mislead interventions and business decisions.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cff38189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Y_0) difference between treated and control: 240.53\n",
      "This baseline imbalance creates bias in naive estimation.\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate the *average baseline outcome* (Y_0) in treated vs untreated groups\n",
    "treated_baseline = df.loc[df['T'] == 1, 'Y_0'].mean()\n",
    "control_baseline = df.loc[df['T'] == 0, 'Y_0'].mean()\n",
    "\n",
    "baseline_diff = treated_baseline - control_baseline\n",
    "\n",
    "print(f\"Baseline (Y_0) difference between treated and control: {baseline_diff:.2f}\")\n",
    "print(\"This baseline imbalance creates bias in naive estimation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2f4dd",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaffce9",
   "metadata": {},
   "source": [
    "<a id=\"causal-diagrams\"></a>\n",
    "# 🕸️ Causal Diagrams (DAGs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84191e2",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Directed Acyclic Graphs (DAGs)</strong> are a compact way to represent assumptions about the data generating process.</p>\n",
    "\n",
    "<ul>\n",
    "  <li>Nodes = variables</li>\n",
    "  <li>Edges (arrows) = direct causal influence</li>\n",
    "</ul>\n",
    "\n",
    "<p>DAGs are not learned from data. They are <strong>drawn from domain knowledge</strong> to help reason about:</p>\n",
    "<ul>\n",
    "  <li>Confounders</li>\n",
    "  <li>Biases</li>\n",
    "  <li>Valid adjustment strategies</li>\n",
    "</ul>\n",
    "\n",
    "<p>Almost every causal inference method implicitly or explicitly assumes a DAG about the world.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b06f1",
   "metadata": {},
   "source": [
    "<a id=\"primer-dags\"></a>\n",
    "#### 🧿 Quick primer on DAGs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66cfd3e",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>A <strong>DAG (Directed Acyclic Graph)</strong> encodes assumptions about how variables causally relate.</p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Directed</strong>: Arrows have direction (cause → effect).</li>\n",
    "  <li><strong>Acyclic</strong>: No feedback loops allowed (you can’t return to a node).</li>\n",
    "</ul>\n",
    "\n",
    "<p>Example:</p>\n",
    "<blockquote>Age → Income → Health</blockquote>\n",
    "\n",
    "<p>Means:</p>\n",
    "<ul>\n",
    "  <li>Age affects income.</li>\n",
    "  <li>Income affects health.</li>\n",
    "  <li>No reverse paths.</li>\n",
    "</ul>\n",
    "\n",
    "<p>DAGs help identify:</p>\n",
    "<ul>\n",
    "  <li>Which paths are confounded</li>\n",
    "  <li>Which variables to control for</li>\n",
    "  <li>Whether effects are identifiable</li>\n",
    "</ul>\n",
    "\n",
    "<p>They act like a <strong>map</strong> — letting you plan causal estimation strategies intelligently.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a48aa4",
   "metadata": {},
   "source": [
    "<a id=\"confounder-collider-mediator\"></a>\n",
    "#### 🕷️ Confounding vs. colliders vs. mediators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cccea1",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Confounders</strong>:</p>\n",
    "<ul>\n",
    "  <li>Variables that influence both treatment and outcome.</li>\n",
    "  <li>Must be adjusted for to block bias.</li>\n",
    "  <li>Example: Age confounds the relationship between Exercise (<code>T</code>) and Health (<code>Y</code>).</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Colliders</strong>:</p>\n",
    "<ul>\n",
    "  <li>Variables caused by two other variables.</li>\n",
    "  <li><strong>Must NOT adjust for colliders</strong> — doing so opens spurious associations.</li>\n",
    "  <li>Example: Adjusting for \"hospitalization\" might introduce bias when studying Smoking → Lung Disease.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Mediators</strong>:</p>\n",
    "<ul>\n",
    "  <li>Variables on the causal pathway between treatment and outcome.</li>\n",
    "  <li>Adjusting for them <strong>blocks part of the causal effect</strong> you want to measure.</li>\n",
    "  <li>Example: Exercise → Fitness → Health (fitness is a mediator).</li>\n",
    "</ul>\n",
    "\n",
    "<p>👉 Correct adjustment requires distinguishing among these roles.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5353f4",
   "metadata": {},
   "source": [
    "<a id=\"estimability-from-dags\"></a>\n",
    "#### 🔗 What can/can’t be estimated just from data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3355a",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Not everything is identifiable from data alone — assumptions are unavoidable.</p>\n",
    "\n",
    "<h5>What can be estimated:</h5>\n",
    "<ul>\n",
    "  <li>Associations (correlations, patterns)</li>\n",
    "  <li>Conditional independence structures</li>\n",
    "  <li>Causal effects <strong>if</strong> the right covariates are controlled (based on DAG structure)</li>\n",
    "</ul>\n",
    "\n",
    "<h5>What cannot be estimated:</h5>\n",
    "<ul>\n",
    "  <li>Whether a relationship is causal (without assumptions)</li>\n",
    "  <li>The full structure of a DAG (unless randomized experiments are used)</li>\n",
    "</ul>\n",
    "\n",
    "<p>Data + assumptions → Causal conclusions.<br>\n",
    "Data alone → Only correlational findings.</p>\n",
    "\n",
    "<p>DAGs clarify where you need domain knowledge vs where data suffices.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6b2de",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef463393",
   "metadata": {},
   "source": [
    "<a id=\"backdoor-adjustment\"></a>\n",
    "# 🔍 Backdoor Adjustment Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7450c130",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Backdoor adjustment methods aim to block <strong>backdoor paths</strong> — non-causal paths that create bias between treatment and outcome.</p>\n",
    "\n",
    "<p><strong>Core idea:</strong></p>\n",
    "<ul>\n",
    "  <li>Identify variables (confounders) that open backdoor paths.</li>\n",
    "  <li>Condition on them — either by stratifying, modeling, or matching.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Backdoor adjustment <strong>simulates</strong> what would happen if treatment assignment were random within levels of the confounders.</p>\n",
    "\n",
    "<p>It’s the foundational idea behind:</p>\n",
    "<ul>\n",
    "  <li>Regression</li>\n",
    "  <li>Matching</li>\n",
    "  <li>Stratification</li>\n",
    "  <li>Propensity scores</li>\n",
    "</ul>\n",
    "\n",
    "<p>If you can block all backdoor paths, you can estimate causal effects from observational data reliably.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7760664",
   "metadata": {},
   "source": [
    "<a id=\"conditioning\"></a>\n",
    "#### 🧾 Conditioning on confounders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1f903",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Conditioning means <strong>holding confounders constant</strong> when comparing treated vs untreated units.</p>\n",
    "\n",
    "<p>Examples:</p>\n",
    "<ul>\n",
    "  <li>Comparing treated vs untreated users <strong>within each income band</strong>.</li>\n",
    "  <li>Comparing recovery rates <strong>within each age group</strong>.</li>\n",
    "</ul>\n",
    "\n",
    "<p>By conditioning, you eliminate the variation due to confounders, isolating the causal effect.</p>\n",
    "\n",
    "<p><strong>Important:</strong><br>\n",
    "You should only condition on true confounders — not colliders or mediators.</p>\n",
    "\n",
    "<p>Conditioning can be implemented via:</p>\n",
    "<ul>\n",
    "  <li>Subgrouping</li>\n",
    "  <li>Regression</li>\n",
    "  <li>Matching</li>\n",
    "  <li>Weighting</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74217e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Conditional Difference by Income Group:\n",
      "T                 diff\n",
      "high_income           \n",
      "0            16.867043\n",
      "1            13.563878\n"
     ]
    }
   ],
   "source": [
    "# Simple conditioning by subgroup (example: income > 70k vs <= 70k)\n",
    "df['high_income'] = (df['income'] > 70000).astype(int)\n",
    "\n",
    "grouped = df.groupby(['high_income', 'T'])['Y_obs'].mean().unstack()\n",
    "grouped['diff'] = grouped[1] - grouped[0]\n",
    "\n",
    "print(\"Simple Conditional Difference by Income Group:\")\n",
    "print(grouped[['diff']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e16492",
   "metadata": {},
   "source": [
    "<a id=\"stratification\"></a>\n",
    "#### 🕵️‍♂️ Stratification / Subgroup analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93353a4f",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Stratification means <strong>breaking the dataset into buckets</strong> based on confounders and comparing treatment effects within each bucket.</p>\n",
    "\n",
    "<p>Typical steps:</p>\n",
    "<ol>\n",
    "  <li>Divide data based on a confounder (e.g., low vs high engagement).</li>\n",
    "  <li>Within each stratum, compute treated vs control differences.</li>\n",
    "  <li>Aggregate across strata (weighted average).</li>\n",
    "</ol>\n",
    "\n",
    "<p><strong>When useful:</strong></p>\n",
    "<ul>\n",
    "  <li>When confounders are categorical or easily discretized.</li>\n",
    "  <li>When interpretability is important.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Limits:</strong></p>\n",
    "<ul>\n",
    "  <li>Doesn’t scale well with many confounders (curse of dimensionality).</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66d78e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Difference by Engagement Group:\n",
      "T                      diff\n",
      "high_engagement            \n",
      "0                290.043114\n",
      "1                145.885304\n"
     ]
    }
   ],
   "source": [
    "# Stratify based on prior_engagement (simple high vs low)\n",
    "df['high_engagement'] = (df['prior_engagement'] > 0.5).astype(int)\n",
    "\n",
    "strat_grouped = df.groupby(['high_engagement', 'T'])['Y_obs'].mean().unstack()\n",
    "strat_grouped['diff'] = strat_grouped[1] - strat_grouped[0]\n",
    "\n",
    "print(\"Conditional Difference by Engagement Group:\")\n",
    "print(strat_grouped[['diff']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00bc7ca",
   "metadata": {},
   "source": [
    "<a id=\"regression-adjustment\"></a>\n",
    "#### 📊 Regression Adjustment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6549d05",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Regression adjustment estimates causal effects by <strong>controlling for confounders via regression</strong>.</p>\n",
    "\n",
    "<p>Simple linear model:</p>\n",
    "<blockquote><code>Y = β₀ + β₁·T + β₂·(confounder1) + β₃·(confounder2) + ... + ε</code></blockquote>\n",
    "\n",
    "<ul>\n",
    "  <li><code>β₁</code> captures the <strong>adjusted</strong> effect of treatment, controlling for confounders.</li>\n",
    "  <li>It removes bias from observable confounders (under correct model specification).</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Advantages:</strong></p>\n",
    "<ul>\n",
    "  <li>Easy to use.</li>\n",
    "  <li>Scales to many covariates.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Risks:</strong></p>\n",
    "<ul>\n",
    "  <li>Sensitive to model misspecification.</li>\n",
    "  <li>Wrong functional forms (nonlinearities, interactions) can bias estimates.</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a2f4b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Y_obs   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 4.652e+06\n",
      "Date:                Sat, 26 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        17:50:40   Log-Likelihood:                -15122.\n",
      "No. Observations:                5000   AIC:                         3.025e+04\n",
      "Df Residuals:                    4995   BIC:                         3.029e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const               50.3660      0.398    126.398      0.000      49.585      51.147\n",
      "T                   10.0641      0.220     45.761      0.000       9.633      10.495\n",
      "age                 -0.2942      0.006    -49.784      0.000      -0.306      -0.283\n",
      "income               0.0200   4.83e-06   4142.593      0.000       0.020       0.020\n",
      "prior_engagement     4.3802      0.452      9.681      0.000       3.493       5.267\n",
      "==============================================================================\n",
      "Omnibus:                        5.657   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.059   Jarque-Bera (JB):                5.136\n",
      "Skew:                          -0.029   Prob(JB):                       0.0767\n",
      "Kurtosis:                       2.854   Cond. No.                     4.38e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.38e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Estimated treatment effect (β₁) after adjustment: 10.06\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = df[['T', 'age', 'income', 'prior_engagement']]\n",
    "X = sm.add_constant(X)\n",
    "y = df['Y_obs']\n",
    "\n",
    "reg_model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(reg_model.summary())\n",
    "\n",
    "print(f\"\\nEstimated treatment effect (β₁) after adjustment: {reg_model.params['T']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5906e36",
   "metadata": {},
   "source": [
    "<a id=\"psm\"></a>\n",
    "#### 📌 Propensity Score Matching (PSM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f267aa",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Propensity Score Matching (PSM) is a two-step procedure:</p>\n",
    "<ol>\n",
    "  <li>Model the <strong>probability of receiving treatment</strong> (<code>P(T=1 | X)</code>) using observed covariates.</li>\n",
    "  <li>Match treated and control units with <strong>similar propensity scores</strong>.</li>\n",
    "</ol>\n",
    "\n",
    "<p><strong>Why PSM?</strong></p>\n",
    "<ul>\n",
    "  <li>Instead of adjusting for many covariates separately, you balance treated and control groups on a single dimension (the propensity score).</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>When useful:</strong></p>\n",
    "<ul>\n",
    "  <li>When covariate space is high-dimensional.</li>\n",
    "  <li>When you want a matched sample that resembles randomized data.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Limitations:</strong></p>\n",
    "<ul>\n",
    "  <li>Requires good overlap (common support).</li>\n",
    "  <li>Still relies on unconfoundedness assumption.</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e0ce90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propensity Score Matched Estimate of Treatment Effect: 197.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Step 1: Estimate propensity scores\n",
    "ps_model = LogisticRegression()\n",
    "ps_model.fit(df[['age', 'income', 'prior_engagement']], df['T'])\n",
    "df['propensity_score'] = ps_model.predict_proba(df[['age', 'income', 'prior_engagement']])[:,1]\n",
    "\n",
    "# Step 2: Nearest neighbor matching\n",
    "treated = df[df['T'] == 1]\n",
    "control = df[df['T'] == 0]\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(control[['propensity_score']])\n",
    "\n",
    "distances, indices = nn.kneighbors(treated[['propensity_score']])\n",
    "matched_control = control.iloc[indices.flatten()]\n",
    "\n",
    "# Calculate matched difference\n",
    "matched_diff = (treated['Y_obs'].values - matched_control['Y_obs'].values).mean()\n",
    "\n",
    "print(f\"Propensity Score Matched Estimate of Treatment Effect: {matched_diff:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b259b1",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229aa095",
   "metadata": {},
   "source": [
    "<a id=\"iv-methods\"></a>\n",
    "# 🎯 Instrumental Variables (IV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416579ed",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Instrumental Variables (IV)</strong> methods are used <strong>when simple adjustment for confounders is impossible</strong> or <strong>not credible</strong>.</p>\n",
    "\n",
    "<p>When treatment is <strong>endogenous</strong> (affected by unobserved factors also affecting outcome), traditional methods like regression fail.</p>\n",
    "\n",
    "<p><strong>IV solves this by:</strong></p>\n",
    "<ul>\n",
    "  <li>Using a \"proxy\" (instrument) that affects treatment but is otherwise unrelated to the outcome except through treatment.</li>\n",
    "  <li>\"Re-randomizing\" variation in treatment based on the instrument.</li>\n",
    "</ul>\n",
    "\n",
    "<p>You create <strong>quasi-randomization</strong> even in observational data.</p>\n",
    "\n",
    "<p>Classic examples:</p>\n",
    "<ul>\n",
    "  <li>Distance to hospital → instrument for getting surgery.</li>\n",
    "  <li>Random assignment of judges → instrument for harsher sentencing.</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b63f1d",
   "metadata": {},
   "source": [
    "<a id=\"when-use-iv\"></a>\n",
    "#### 🪝 When backdoor paths can’t be blocked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71bc02",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>You need IV methods when:</p>\n",
    "<ul>\n",
    "  <li>There are <strong>unobserved confounders</strong> you can’t measure.</li>\n",
    "  <li>No set of observed covariates satisfies ignorability.</li>\n",
    "  <li>Standard backdoor adjustment will be biased.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Example:</p>\n",
    "<ul>\n",
    "  <li>Studying the effect of education on income: natural intelligence is a hidden confounder (affects both education and income).</li>\n",
    "  <li>You can't just regress income ~ education — bias remains.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Key realization:</strong><br>\n",
    "If <strong>backdoor paths exist</strong> through unobserved variables, IV becomes necessary.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0322fe",
   "metadata": {},
   "source": [
    "<a id=\"iv-conditions\"></a>\n",
    "#### 🎯 Valid instrument conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe6d3a",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>For an instrument (<code>Z</code>) to be valid, it must satisfy:</p>\n",
    "\n",
    "<ol>\n",
    "  <li><strong>Relevance:</strong><br>\n",
    "  <code>Z</code> must affect treatment <code>T</code>.<br>\n",
    "  (There must be a first-stage effect.)</li>\n",
    "\n",
    "  <li><strong>Exclusion Restriction:</strong><br>\n",
    "  <code>Z</code> must affect the outcome <code>Y</code> <strong>only</strong> through <code>T</code>.<br>\n",
    "  (No direct path from <code>Z</code> to <code>Y</code>.)</li>\n",
    "\n",
    "  <li><strong>Independence (As-if Randomness):</strong><br>\n",
    "  <code>Z</code> must be independent of unobserved confounders affecting <code>Y</code>.</li>\n",
    "</ol>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p>If any of these fail:</p>\n",
    "<ul>\n",
    "  <li>IV estimates are biased or meaningless.</li>\n",
    "  <li>You can’t fix bad instruments with bigger sample sizes.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Choosing or arguing a valid instrument is 90% of the IV battle.</strong></p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fff624",
   "metadata": {},
   "source": [
    "<a id=\"2sls\"></a>\n",
    "#### 🧩 2-Stage Least Squares (2SLS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091cb2e9",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>2SLS (Two-Stage Least Squares)</strong> is the classic estimation procedure for IV:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Stage 1:</strong><br>\n",
    "  Regress treatment <code>T</code> on instrument <code>Z</code> (and any controls)<br>\n",
    "  → get predicted treatment (<code>T̂</code>)</li>\n",
    "\n",
    "  <li><strong>Stage 2:</strong><br>\n",
    "  Regress outcome <code>Y</code> on predicted treatment (<code>T̂</code>)</li>\n",
    "</ul>\n",
    "\n",
    "<p>The second-stage coefficient gives the <strong>causal effect</strong> of treatment on outcome, isolating variation driven by the instrument.</p>\n",
    "\n",
    "<p><strong>Warning:</strong></p>\n",
    "<ul>\n",
    "  <li>Standard regression software doesn't correct standard errors properly when doing 2SLS manually.</li>\n",
    "  <li>Later packages like <code>linearmodels</code> automate this.</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd70c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Y_obs   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 3.278e+06\n",
      "Date:                Sat, 26 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        17:50:40   Log-Likelihood:                -15996.\n",
      "No. Observations:                5000   AIC:                         3.200e+04\n",
      "Df Residuals:                    4995   BIC:                         3.203e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const               48.1296      0.474    101.498      0.000      47.200      49.059\n",
      "T_hat                0.2548      0.197      1.296      0.195      -0.131       0.640\n",
      "age                 -0.3133      0.007    -44.628      0.000      -0.327      -0.300\n",
      "income               0.0201   5.54e-06   3619.407      0.000       0.020       0.020\n",
      "prior_engagement     6.6954      0.540     12.391      0.000       5.636       7.755\n",
      "==============================================================================\n",
      "Omnibus:                       71.333   Durbin-Watson:                   1.970\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               74.381\n",
      "Skew:                           0.287   Prob(JB):                     7.05e-17\n",
      "Kurtosis:                       3.169   Cond. No.                     4.33e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.33e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Estimated causal effect (via 2SLS): 0.25\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "# Simulate an instrument Z (let's assume it's random and satisfies conditions)\n",
    "np.random.seed(42)\n",
    "df['Z'] = np.random.binomial(1, 0.5, size=len(df))\n",
    "\n",
    "# Make treatment depend partly on Z\n",
    "df['T_iv'] = (0.5 * df['Z'] + 0.5 * df['prior_engagement'] + np.random.normal(0, 0.1, len(df))) > 0.5\n",
    "df['T_iv'] = df['T_iv'].astype(int)\n",
    "\n",
    "# Stage 1: Predict treatment from instrument\n",
    "X_stage1 = add_constant(df[['Z', 'age', 'income', 'prior_engagement']])\n",
    "stage1_model = OLS(df['T_iv'], X_stage1).fit()\n",
    "df['T_hat'] = stage1_model.predict(X_stage1)\n",
    "\n",
    "# Stage 2: Predict outcome from predicted treatment\n",
    "X_stage2 = add_constant(df[['T_hat', 'age', 'income', 'prior_engagement']])\n",
    "stage2_model = OLS(df['Y_obs'], X_stage2).fit()\n",
    "\n",
    "print(stage2_model.summary())\n",
    "\n",
    "print(f\"\\nEstimated causal effect (via 2SLS): {stage2_model.params['T_hat']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1dff19",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff962ca0",
   "metadata": {},
   "source": [
    "<a id=\"dml-methods\"></a>\n",
    "# 🧰 Double Machine Learning (DML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddef79",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Double Machine Learning (DML)</strong> is a modern causal estimation technique that:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Separates</strong> the modeling of treatment and outcome.</li>\n",
    "  <li><strong>Uses flexible machine learning models</strong> to control for complex confounders.</li>\n",
    "  <li><strong>Debiases</strong> the final treatment effect estimation by orthogonalization.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Why DML matters:</strong></p>\n",
    "<ul>\n",
    "  <li>Traditional linear regression forces linearity.</li>\n",
    "  <li>DML allows for nonlinear, high-dimensional adjustment without overfitting causal estimates.</li>\n",
    "</ul>\n",
    "\n",
    "<p>It builds robust treatment effect estimators even when you use ML methods like Random Forests, XGBoost, or Neural Nets for intermediate steps.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9754c",
   "metadata": {},
   "source": [
    "<a id=\"ml-nuisance\"></a>\n",
    "#### 🪛 Use ML models for nuisance functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5116cb2",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>In DML, you model two \"nuisance functions\" first:</p>\n",
    "<ol>\n",
    "  <li><strong>Outcome model</strong>: <code>Y ~ X</code></li>\n",
    "  <li><strong>Treatment model</strong>: <code>T ~ X</code></li>\n",
    "</ol>\n",
    "\n",
    "<p>You can use <strong>any ML model</strong> (linear regression, random forest, gradient boosting, etc.) for these.</p>\n",
    "\n",
    "<p><strong>Key point:</strong><br>\n",
    "The goal is <strong>accurate prediction</strong>, not causal interpretation, at this stage.</p>\n",
    "\n",
    "<p>Later, DML uses the residuals from these models to isolate the causal effect of <code>T</code> on <code>Y</code>.</p>\n",
    "\n",
    "<p>This two-step process protects the final estimate from overfitting to noisy high-dimensional features.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e237a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features\n",
    "features = ['age', 'income', 'prior_engagement']\n",
    "\n",
    "# Split into train/test for honest estimation\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df['Y_obs'], test_size=0.3, random_state=42)\n",
    "T_train, T_test = train_test_split(df['T'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Outcome model: Y ~ X\n",
    "y_model = RandomForestRegressor()\n",
    "y_model.fit(X_train, y_train)\n",
    "df['y_hat'] = y_model.predict(df[features])\n",
    "\n",
    "# Treatment model: T ~ X\n",
    "t_model = RandomForestRegressor()\n",
    "t_model.fit(X_train, T_train)\n",
    "df['t_hat'] = t_model.predict(df[features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000b403",
   "metadata": {},
   "source": [
    "<a id=\"residualization\"></a>\n",
    "#### 🧱 Residualization + orthogonalization logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77758e",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>After fitting nuisance models:</p>\n",
    "\n",
    "<ul>\n",
    "  <li>Calculate <strong>residuals</strong>:\n",
    "    <ul>\n",
    "      <li><code>Residual_Y = Y - Ŷ</code></li>\n",
    "      <li><code>Residual_T = T - T̂</code></li>\n",
    "    </ul>\n",
    "  </li>\n",
    "\n",
    "  <li>Then regress <strong>Residual_Y ~ Residual_T</strong>.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Why?</strong></p>\n",
    "<ul>\n",
    "  <li>This removes the part of <code>Y</code> and <code>T</code> that is predictable from <code>X</code>.</li>\n",
    "  <li>What remains captures the <strong>\"clean\" causal variation</strong> of <code>T</code> on <code>Y</code>, orthogonal to confounders.</li>\n",
    "</ul>\n",
    "\n",
    "<p>This two-stage process is called <strong>orthogonalization</strong> — it minimizes bias from overfitting nuisance functions.</p>\n",
    "\n",
    "<p>It’s a key innovation that separates DML from naive ML-based adjustment.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df536cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             residual_Y   R-squared:                       0.127\n",
      "Model:                            OLS   Adj. R-squared:                  0.127\n",
      "Method:                 Least Squares   F-statistic:                     726.5\n",
      "Date:                Sat, 26 Apr 2025   Prob (F-statistic):          1.62e-149\n",
      "Time:                        17:50:41   Log-Likelihood:                -14928.\n",
      "No. Observations:                5000   AIC:                         2.986e+04\n",
      "Df Residuals:                    4998   BIC:                         2.987e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0842      0.068      1.243      0.214      -0.049       0.217\n",
      "residual_T     8.9188      0.331     26.953      0.000       8.270       9.567\n",
      "==============================================================================\n",
      "Omnibus:                     7090.850   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          9991352.741\n",
      "Skew:                           7.694   Prob(JB):                         0.00\n",
      "Kurtosis:                     221.453   Cond. No.                         4.88\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Estimated causal effect via DML: 8.92\n"
     ]
    }
   ],
   "source": [
    "# Calculate residuals\n",
    "df['residual_Y'] = df['Y_obs'] - df['y_hat']\n",
    "df['residual_T'] = df['T'] - df['t_hat']\n",
    "\n",
    "# Final stage: regress residual_Y ~ residual_T\n",
    "X_resid = sm.add_constant(df['residual_T'])\n",
    "y_resid = df['residual_Y']\n",
    "\n",
    "residual_model = sm.OLS(y_resid, X_resid).fit()\n",
    "\n",
    "print(residual_model.summary())\n",
    "\n",
    "print(f\"\\nEstimated causal effect via DML: {residual_model.params['residual_T']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd36b53",
   "metadata": {},
   "source": [
    "<a id=\"dml-vs-regression\"></a>\n",
    "#### 🧲 When to prefer over traditional regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde7c45",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>You should prefer DML over traditional regression when:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>High-dimensional confounders</strong> (lots of features) exist.</li>\n",
    "  <li><strong>Nonlinear relationships</strong> are likely between covariates and treatment/outcome.</li>\n",
    "  <li><strong>Flexible modeling</strong> is important (tree-based, neural nets, etc.)</li>\n",
    "  <li><strong>Concern about model misspecification</strong> in simple linear regression.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Traditional regression assumes:</p>\n",
    "<ul>\n",
    "  <li>Linear relationships</li>\n",
    "  <li>No complex interactions unless explicitly modeled</li>\n",
    "</ul>\n",
    "\n",
    "<p>DML frees you from strict parametric forms, allowing modern ML models while still aiming for valid causal estimates.</p>\n",
    "\n",
    "<p>✅ DML shines in modern settings: tech products, healthcare, online platforms — where datasets are messy, rich, and big.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14a213",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15edb2",
   "metadata": {},
   "source": [
    "<a id=\"heterogeneous-effects\"></a>\n",
    "# 🌈 Heterogeneous Treatment Effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb6bb3",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Until now, we've talked about the <strong>average</strong> effect of treatment across the entire population (ATE).</p>\n",
    "\n",
    "<p>But in reality:</p>\n",
    "<ul>\n",
    "  <li>Different users respond differently.</li>\n",
    "  <li>Treatment effects <strong>vary</strong> by user characteristics.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Heterogeneous Treatment Effects</strong> (HTE) study how effects vary:</p>\n",
    "<ul>\n",
    "  <li>Across groups (e.g., high engagement vs low engagement)</li>\n",
    "  <li>Across individuals (personalized effects)</li>\n",
    "</ul>\n",
    "\n",
    "<p>Estimating HTE is critical for:</p>\n",
    "<ul>\n",
    "  <li>Personalized recommendations</li>\n",
    "  <li>Smart targeting (marketing, healthcare, product launches)</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ad0cd",
   "metadata": {},
   "source": [
    "<a id=\"ate-cate-ite\"></a>\n",
    "#### 🎨 ATE vs. CATE vs. ITE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba90ea5",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Different layers of treatment effect granularity:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>ATE (Average Treatment Effect)</strong>:<br>\n",
    "    Average effect across everyone.</li>\n",
    "\n",
    "  <li><strong>CATE (Conditional Average Treatment Effect)</strong>:<br>\n",
    "    Average effect <strong>given some subgroup</strong> (e.g., CATE for users &lt;30 years old).</li>\n",
    "\n",
    "  <li><strong>ITE (Individual Treatment Effect)</strong>:<br>\n",
    "    Effect for a <strong>specific user</strong>.</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>In practice:</strong></p>\n",
    "<ul>\n",
    "  <li>ATE is easiest to estimate.</li>\n",
    "  <li>CATEs are often actionable (targeted marketing).</li>\n",
    "  <li>ITEs are the hardest — noisy and high-variance.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Good causal inference methods can recover CATEs/ITEs <strong>if</strong> enough data and signal exist.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1385a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ATE: 10.00\n",
      "CATE for high engagement users: 10.00\n",
      "\n",
      "Sample ITEs:\n",
      "         age        income  prior_engagement  ITE_true\n",
      "0  45.960570  53643.604770          0.188077      10.0\n",
      "1  38.340828  53198.788374          0.170389      10.0\n",
      "2  47.772262  33065.352411          0.511379      10.0\n",
      "3  58.276358  55048.647124          0.318793      10.0\n",
      "4  37.190160  70992.436227          0.384439      10.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate ATE (simple diff from simulation ground truth)\n",
    "ate = (df['Y_1'] - df['Y_0']).mean()\n",
    "print(f\"True ATE: {ate:.2f}\")\n",
    "\n",
    "# Calculate CATE for high engagement group\n",
    "cate_high_engagement = (df[df['prior_engagement'] > 0.5]['Y_1'] - df[df['prior_engagement'] > 0.5]['Y_0']).mean()\n",
    "print(f\"CATE for high engagement users: {cate_high_engagement:.2f}\")\n",
    "\n",
    "# Show a few ITEs\n",
    "df['ITE_true'] = df['Y_1'] - df['Y_0']\n",
    "print(\"\\nSample ITEs:\")\n",
    "print(df[['age', 'income', 'prior_engagement', 'ITE_true']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26833b",
   "metadata": {},
   "source": [
    "<a id=\"uplift-usecases\"></a>\n",
    "#### 🌟 Uplift models and use cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565df4a8",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Uplift modeling</strong> directly models the <strong>difference in probability</strong> of a positive outcome between treated and untreated users.</p>\n",
    "\n",
    "<p>Instead of modeling outcome probabilities separately, uplift models focus on:</p>\n",
    "<ul>\n",
    "  <li>Who is <strong>most persuadable</strong>?</li>\n",
    "  <li>Who would change behavior because of treatment?</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Where uplift models shine:</strong></p>\n",
    "<ul>\n",
    "  <li>Marketing campaigns (maximize conversions per dollar)</li>\n",
    "  <li>Customer retention (target save offers only to those who would churn)</li>\n",
    "  <li>Medical interventions (target high-risk patients)</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>Typical techniques:</strong></p>\n",
    "<ul>\n",
    "  <li>Uplift Decision Trees</li>\n",
    "  <li>Two-model approach (predict Y|T=1 and Y|T=0 separately, then subtract)</li>\n",
    "  <li>Causal Forests</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5969183",
   "metadata": {},
   "source": [
    "<a id=\"causal-forests\"></a>\n",
    "#### 🧩 Tree-based methods (Causal Trees, Causal Forests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a7811",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Tree-based methods are powerful for discovering treatment effect heterogeneity:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Causal Trees</strong>:\n",
    "    <ul>\n",
    "      <li>Split data to maximize treatment effect differences between branches.</li>\n",
    "      <li>One tree trained specifically for causal splits.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "\n",
    "  <li><strong>Causal Forests</strong>:\n",
    "    <ul>\n",
    "      <li>Ensemble of causal trees.</li>\n",
    "      <li>Averages treatment effect estimates across trees.</li>\n",
    "      <li>Reduces variance compared to a single tree.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<p>They can estimate <strong>CATEs</strong> reliably across different subgroups without manually specifying interactions.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>When useful:</strong></p>\n",
    "<ul>\n",
    "  <li>You expect heterogeneity but don't know in advance how to segment.</li>\n",
    "  <li>You want flexible, interpretable treatment effect estimation.</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2a80046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd33d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predicted CATEs:\n",
      "         age        income  prior_engagement  CATE_predicted\n",
      "0  45.960570  53643.604770          0.188077       15.767683\n",
      "1  38.340828  53198.788374          0.170389       18.062330\n",
      "2  47.772262  33065.352411          0.511379       -4.625701\n",
      "3  58.276358  55048.647124          0.318793       14.400047\n",
      "4  37.190160  70992.436227          0.384439       11.047467\n"
     ]
    }
   ],
   "source": [
    "# Causal Forest: Full Correct Code\n",
    "\n",
    "from econml.grf import CausalForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features and outcome\n",
    "X = df[['age', 'income', 'prior_engagement']].values  # Features (2D)\n",
    "T = df['T'].values  # Treatment (1D)\n",
    "Y = df['Y_obs'].values  # Observed outcome (1D)\n",
    "\n",
    "# Fit causal forest\n",
    "forest = CausalForest(n_estimators=100, random_state=42)\n",
    "forest.fit(X, T, Y)  # Correct order: X, T, Y\n",
    "\n",
    "# Predict treatment effects (CATEs)\n",
    "cate_preds = forest.predict(X)\n",
    "\n",
    "# Store predictions\n",
    "df['CATE_predicted'] = cate_preds\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample predicted CATEs:\")\n",
    "print(df[['age', 'income', 'prior_engagement', 'CATE_predicted']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296df001",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291ba4e",
   "metadata": {},
   "source": [
    "<a id=\"placebo-robustness\"></a>\n",
    "# 🧪 Placebo Tests & Robustness Checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfbd97b",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Even after careful causal estimation, you must ask:</p>\n",
    "<ul>\n",
    "  <li>Was it a real effect?</li>\n",
    "  <li>Could hidden bias still exist?</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Robustness checks</strong> build confidence that your findings are not artifacts of modeling choices, random noise, or hidden confounders.</p>\n",
    "\n",
    "<p><strong>Placebo tests</strong> simulate situations where you expect <strong>no effect</strong> — if you detect an effect there, something's wrong.</p>\n",
    "\n",
    "<p>Robust causal analysis is not just about point estimates — it’s about <strong>proving to yourself that you aren't fooling yourself</strong>.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec13654",
   "metadata": {},
   "source": [
    "<a id=\"placebo\"></a>\n",
    "#### 🧻 Randomized placebo treatments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e7d03",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Placebo tests inject \"fake\" treatments to validate your method.</p>\n",
    "\n",
    "<p><strong>Idea:</strong></p>\n",
    "<ul>\n",
    "  <li>Randomly assign a placebo treatment.</li>\n",
    "  <li>Re-estimate the treatment effect.</li>\n",
    "  <li>Expect <strong>no significant effect</strong> if your method is honest.</li>\n",
    "</ul>\n",
    "\n",
    "<p>If your model finds strong effects even when treatment is randomized, your pipeline is leaking bias or overfitting.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>Placebo Tests Are Critical:</strong></p>\n",
    "<ul>\n",
    "  <li>They detect specification errors.</li>\n",
    "  <li>They detect uncontrolled confounding.</li>\n",
    "  <li>They expose overfitting to noise.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Placebo tests are a basic but powerful check — always worth doing.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b0287d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placebo test: naive difference in means = 7.79\n"
     ]
    }
   ],
   "source": [
    "# Create a random placebo treatment\n",
    "np.random.seed(123)\n",
    "df['placebo_T'] = np.random.binomial(1, 0.5, size=len(df))\n",
    "\n",
    "# Estimate naive difference for placebo treatment\n",
    "placebo_treated_mean = df.loc[df['placebo_T'] == 1, 'Y_obs'].mean()\n",
    "placebo_control_mean = df.loc[df['placebo_T'] == 0, 'Y_obs'].mean()\n",
    "\n",
    "placebo_naive_diff = placebo_treated_mean - placebo_control_mean\n",
    "\n",
    "print(f\"Placebo test: naive difference in means = {placebo_naive_diff:.2f}\")\n",
    "\n",
    "# Ideally close to zero if model is unbiased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef2135",
   "metadata": {},
   "source": [
    "<a id=\"robustness\"></a>\n",
    "#### ⚗️ Sensitivity to unobserved confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb34b3db",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Even after adjusting for observed confounders, <strong>unobserved variables</strong> can still bias causal estimates.</p>\n",
    "\n",
    "<p><strong>Sensitivity analysis</strong> asks:</p>\n",
    "<ul>\n",
    "  <li>How strong would hidden confounding have to be to overturn my results?</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>Typical approaches:</strong></p>\n",
    "<ul>\n",
    "  <li>Simulate hidden confounders and see effect size shifts.</li>\n",
    "  <li>Use formulas (like Rosenbaum bounds) to quantify robustness.</li>\n",
    "</ul>\n",
    "\n",
    "<p>In practical data science:</p>\n",
    "<ul>\n",
    "  <li>Simulate scenarios with added fake bias.</li>\n",
    "  <li>Stress test conclusions under \"worst plausible\" hidden biases.</li>\n",
    "</ul>\n",
    "\n",
    "<p>If your conclusions survive plausible levels of unobserved bias, they are more credible.</p>\n",
    "\n",
    "<p><strong>Important mindset:</strong><br>\n",
    "No analysis is perfect — the goal is to <strong>understand limits, not pretend away uncertainty</strong>.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0444449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive difference in means (with hidden confounding): 250.11\n",
      "Inflation in estimate due to hidden confounder: -0.42\n"
     ]
    }
   ],
   "source": [
    "# Simulate a hidden confounder correlated with treatment and outcome\n",
    "np.random.seed(42)\n",
    "df['hidden_confounder'] = np.random.normal(0, 1, size=len(df))\n",
    "\n",
    "# Make the outcome depend slightly on this hidden confounder\n",
    "df['Y_obs_biased'] = df['Y_obs'] + 2 * df['hidden_confounder']\n",
    "\n",
    "# Re-run naive difference with biased outcome\n",
    "treated_mean_biased = df.loc[df['T'] == 1, 'Y_obs_biased'].mean()\n",
    "control_mean_biased = df.loc[df['T'] == 0, 'Y_obs_biased'].mean()\n",
    "\n",
    "biased_naive_diff = treated_mean_biased - control_mean_biased\n",
    "\n",
    "print(f\"Naive difference in means (with hidden confounding): {biased_naive_diff:.2f}\")\n",
    "\n",
    "# See how much bias was introduced\n",
    "bias_inflation = biased_naive_diff - naive_diff\n",
    "print(f\"Inflation in estimate due to hidden confounder: {bias_inflation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43860c2",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a9b11",
   "metadata": {},
   "source": [
    "<a id=\"counterfactuals\"></a>\n",
    "# 🧬 Counterfactual Thinking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51896a85",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Counterfactual thinking</strong> is the backbone of causal inference.</p>\n",
    "\n",
    "<p>Instead of asking:</p>\n",
    "<blockquote>\"What happened?\"</blockquote>\n",
    "\n",
    "<p>We ask:</p>\n",
    "<blockquote>\"What <em>would have</em> happened if things were different?\"</blockquote>\n",
    "\n",
    "<p>In causal inference:</p>\n",
    "<ul>\n",
    "  <li>Each unit (user, patient, item) has two potential outcomes.</li>\n",
    "  <li>Only one is observed.</li>\n",
    "  <li>The other — the counterfactual — must be predicted or estimated.</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>Counterfactual reasoning enables:</strong></p>\n",
    "<ul>\n",
    "  <li>Simulating user behavior under alternate scenarios.</li>\n",
    "  <li>Personalizing interventions based on predicted outcomes.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Without counterfactuals, causal inference is blind.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4f6b0",
   "metadata": {},
   "source": [
    "<a id=\"what-if\"></a>\n",
    "#### 🤖 Predicting what would’ve happened\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32b2ad",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Predicting counterfactuals means estimating:</p>\n",
    "<ul>\n",
    "  <li><code>Y(1)</code> for untreated units.</li>\n",
    "  <li><code>Y(0)</code> for treated units.</li>\n",
    "</ul>\n",
    "\n",
    "<p>We use:</p>\n",
    "<ul>\n",
    "  <li>Machine learning models trained on observed data.</li>\n",
    "  <li>Causal forests, meta-learners, and other counterfactual predictors.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Goal:</strong></p>\n",
    "<ul>\n",
    "  <li>Recover the missing potential outcome.</li>\n",
    "  <li>Estimate <strong>individual treatment effects (ITEs)</strong>.</li>\n",
    "</ul>\n",
    "\n",
    "<p>This enables granular interventions — not just average effects across a population.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>Important to remember:</strong><br>\n",
    "Predicted counterfactuals are <strong>estimates</strong>, not direct observations — uncertainty always exists.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99646aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Counterfactual Predictions:\n",
      "   T        Y_obs  counterfactual_outcome\n",
      "0  0  1114.502287             1127.868133\n",
      "1  0  1099.893323             1119.847270\n",
      "2  0   704.133035              697.394845\n",
      "3  0  1139.203509             1151.640784\n",
      "4  0  1464.308234             1475.218807\n"
     ]
    }
   ],
   "source": [
    "# Predict counterfactual outcomes using Causal Forest\n",
    "# (Already trained earlier, we use forest)\n",
    "\n",
    "# Predict Y(1) and Y(0) separately\n",
    "cate_preds = df['CATE_predicted'].values\n",
    "baseline_preds = df['y_hat'].values  # From earlier outcome model\n",
    "\n",
    "# Predict counterfactual outcomes\n",
    "df['Y_cf_T1'] = baseline_preds + cate_preds  # Predicted outcome if treated\n",
    "df['Y_cf_T0'] = baseline_preds  # Predicted outcome if untreated (baseline)\n",
    "\n",
    "# Now simulate what would happen if treatment status flipped\n",
    "df['counterfactual_outcome'] = np.where(\n",
    "    df['T'] == 1,\n",
    "    df['Y_cf_T0'],  # If treated, counterfactual is untreated\n",
    "    df['Y_cf_T1']   # If untreated, counterfactual is treated\n",
    ")\n",
    "\n",
    "print(\"\\nSample Counterfactual Predictions:\")\n",
    "print(df[['T', 'Y_obs', 'counterfactual_outcome']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd5c38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<a id=\"personalization\"></a>\n",
    "#### 🔁 Usage in recommendation & personalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3ae63",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Counterfactual predictions unlock personalization:</strong></p>\n",
    "\n",
    "<p>Instead of treating everyone the same, you can:</p>\n",
    "<ul>\n",
    "  <li>Target users where treatment has highest predicted uplift.</li>\n",
    "  <li>De-prioritize users who won't respond.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Examples:</p>\n",
    "<ul>\n",
    "  <li><strong>Marketing</strong>: Show ads only to users likely to convert if nudged.</li>\n",
    "  <li><strong>Healthcare</strong>: Prioritize interventions for patients who benefit most.</li>\n",
    "  <li><strong>Products</strong>: Recommend features or promotions to maximize lift per user.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Strategic mindshift:</strong><br>\n",
    "Focus on <strong>marginally persuadable users</strong>, not just overall averages.</p>\n",
    "\n",
    "<p>Real-world use cases often combine:</p>\n",
    "<ul>\n",
    "  <li>Causal effect estimation (CATE/ITE)</li>\n",
    "  <li>Ranking users by expected benefit</li>\n",
    "  <li>Action prioritization based on counterfactuals</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e8c9fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top users to prioritize based on CATE:\n",
      "            age        income  prior_engagement  CATE_predicted\n",
      "2841  21.800289  53281.835326          0.350447       20.543173\n",
      "724   42.050385  53280.579923          0.403388       20.443580\n",
      "3205  31.876058  53300.354298          0.420334       20.411161\n",
      "4614  40.670367  53244.477131          0.632127       20.275141\n",
      "3711  24.210210  53209.647772          0.335915       20.259483\n"
     ]
    }
   ],
   "source": [
    "# Rank users by predicted CATE\n",
    "df['priority_score'] = df['CATE_predicted']\n",
    "\n",
    "# Top 5 users we should prioritize for treatment\n",
    "top_users = df.sort_values('priority_score', ascending=False).head(5)\n",
    "\n",
    "print(\"\\nTop users to prioritize based on CATE:\")\n",
    "print(top_users[['age', 'income', 'prior_engagement', 'CATE_predicted']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98552806",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cfc25e",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# 📌 Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a40be",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>You now have a practical understanding of core causal inference techniques.</p>\n",
    "\n",
    "<p>You should be able to:</p>\n",
    "<ul>\n",
    "  <li>Simulate data with confounding</li>\n",
    "  <li>Estimate naive effects and detect bias</li>\n",
    "  <li>Adjust using regression, matching, stratification</li>\n",
    "  <li>Apply modern tools like DML and Causal Forests</li>\n",
    "  <li>Think in terms of counterfactuals, not just correlations</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>Remember:</strong><br>\n",
    "Causal thinking is not just a technique — it’s a lens to see decision-making clearly.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ea89f",
   "metadata": {},
   "source": [
    "<a id=\"summary-table\"></a>\n",
    "#### 📝 Summary table of methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62794b76",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Method</th><th>When Useful</th><th>Strengths</th><th>Weaknesses</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td><strong>Simple Diff-in-Means</strong></td><td>Randomized experiments</td><td>Easy, unbiased</td><td>Useless with confounding</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Regression Adjustment</strong></td><td>Observational data with measured confounders</td><td>Easy to implement</td><td>Model misspecification risk</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Stratification</strong></td><td>Small number of discrete confounders</td><td>Transparent</td><td>Breaks down in high dimensions</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Propensity Score Matching (PSM)</strong></td><td>Observational data with many confounders</td><td>Balances groups</td><td>Sensitive to model of treatment</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Instrumental Variables (IV)</strong></td><td>Unobserved confounders exist</td><td>Bypasses confounding</td><td>Hard to find good instruments</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Double Machine Learning (DML)</strong></td><td>High-dimensional nonlinear confounders</td><td>ML flexibility + debiasing</td><td>Needs lots of data, honest splits</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><strong>Causal Forests</strong></td><td>Heterogeneous treatment effects</td><td>Flexible CATE estimation</td><td>Complex, less interpretable</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27428737",
   "metadata": {},
   "source": [
    "<a id=\"method-choice\"></a>\n",
    "#### 📋 When to use what\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca88bf3",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Choosing a method depends on:</strong></p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Randomization present?</strong>\n",
    "    <ul>\n",
    "      <li>Yes → Simple difference in means is fine.</li>\n",
    "      <li>No → Need adjustment.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "  \n",
    "  <li><strong>Are confounders observed?</strong>\n",
    "    <ul>\n",
    "      <li>Yes → Regression, PSM, DML are options.</li>\n",
    "      <li>No → Need IV or natural experiments.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "\n",
    "  <li><strong>Do you expect heterogeneous effects?</strong>\n",
    "    <ul>\n",
    "      <li>Yes → Causal Trees, Causal Forests, Meta-learners.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "\n",
    "  <li><strong>Is high-dimensional data involved?</strong>\n",
    "    <ul>\n",
    "      <li>Yes → Prefer DML over simple regression.</li>\n",
    "    </ul>\n",
    "  </li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p>Choosing the right method = matching the method to the bias and complexity in your data.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e590a5",
   "metadata": {},
   "source": [
    "<a id=\"causal-vs-predictive\"></a>\n",
    "#### 📎 Causal vs Predictive mindset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7955a8db",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Predictive modeling mindset:</strong></p>\n",
    "<ul>\n",
    "  <li>Focuses on fitting observed outcomes.</li>\n",
    "  <li>Good for forecasts, risk scores, recommendation engines.</li>\n",
    "  <li>Does not care about interventions.</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Causal inference mindset:</strong></p>\n",
    "<ul>\n",
    "  <li>Focuses on <em>what would happen if we intervened</em>.</li>\n",
    "  <li>Good for making decisions (policies, treatments, products).</li>\n",
    "  <li>Requires stronger assumptions, careful design.</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>Key difference:</strong><br>\n",
    "Predictive models can be accurate yet useless for interventions.<br>\n",
    "Causal models are harder but necessary to make confident decisions.</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>Quote to remember:</strong></p>\n",
    "<blockquote>\"All models are wrong. Some models are useful.  \n",
    "Only causal models are useful for actions.\"</blockquote>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f102463",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
