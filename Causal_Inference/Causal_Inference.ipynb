{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0300ea",
   "metadata": {},
   "source": [
    "![Status: In Progress](https://img.shields.io/badge/status-in--progress-yellow)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-70%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green)\n",
    "\n",
    "<!-- ![Status: Complete](https://img.shields.io/badge/status-complete-brightgreen)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-95%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green) -->\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# 🧭 Causal Inference\n",
    "\n",
    "- [🎯 Introduction to Causal Inference](#intro)\n",
    "  - [🎓 What is Causal Inference?](#what-is-causal)\n",
    "  - [📌 Why go beyond Correlation?](#why-correlation)\n",
    "  - [🧭 Real-world problems that need causality](#real-world-examples)\n",
    "\n",
    "- [🧠 Core Concepts & Notation](#notation-assumptions)\n",
    "  - [🧮 Treatment, Outcome, Units](#treatment-outcome-units)\n",
    "  - [📐 Potential Outcomes (Rubin Causal Model)](#potential-outcomes)\n",
    "  - [🧵 Fundamental Problem of Causal Inference](#fundamental-problem)\n",
    "  - [🧠 Assumptions (SUTVA, Ignorability, Overlap)](#core-assumptions)\n",
    "\n",
    "- [🧪 Simulated Dataset Setup](#simulated-data)\n",
    "  - [🧬 Define treatment assignment logic](#treatment-logic)\n",
    "  - [🔬 Inject confounding intentionally](#inject-confounding)\n",
    "  - [🧊 Simulate potential outcomes + observed data](#simulate-outcomes)\n",
    "\n",
    "- [🚫 Naive Estimation](#naive-estimation)\n",
    "  - [❌ Simple difference in means](#diff-in-means)\n",
    "  - [⚠️ Bias due to confounding](#bias-confounding)\n",
    "\n",
    "- [🕸️ Causal Diagrams (DAGs)](#causal-diagrams)\n",
    "  - [🧿 Quick primer on DAGs](#primer-dags)\n",
    "  - [🕷️ Confounding vs. colliders vs. mediators](#confounder-collider-mediator)\n",
    "  - [🔗 What can/can’t be estimated just from data](#estimability-from-dags)\n",
    "\n",
    "- [🔍 Backdoor Adjustment Methods](#backdoor-adjustment)\n",
    "  - [🧾 Conditioning on confounders](#conditioning)\n",
    "  - [🕵️‍♂️ Stratification / Subgroup analysis](#stratification)\n",
    "  - [📊 Regression Adjustment](#regression-adjustment)\n",
    "  - [📌 Propensity Score Matching (PSM)](#psm)\n",
    "\n",
    "- [🎯 Instrumental Variables (IV)](#iv-methods)\n",
    "  - [🪝 When backdoor paths can’t be blocked](#when-use-iv)\n",
    "  - [🎯 Valid instrument conditions](#iv-conditions)\n",
    "  - [🧩 2-Stage Least Squares (2SLS)](#2sls)\n",
    "\n",
    "- [🧰 Double Machine Learning (DML)](#dml-methods)\n",
    "  - [🪛 Use ML models for nuisance functions](#ml-nuisance)\n",
    "  - [🧱 Residualization + orthogonalization logic](#residualization)\n",
    "  - [🧲 When to prefer over traditional regression](#dml-vs-regression)\n",
    "\n",
    "- [🌈 Heterogeneous Treatment Effects](#heterogeneous-effects)\n",
    "  - [🎨 ATE vs. CATE vs. ITE](#ate-cate-ite)\n",
    "  - [🌟 Uplift models and use cases](#uplift-usecases)\n",
    "  - [🧩 Tree-based methods (Causal Trees, Causal Forests)](#causal-forests)\n",
    "\n",
    "- [🧪 Placebo Tests & Robustness Checks](#placebo-robustness)\n",
    "  - [🧻 Randomized placebo treatments](#placebo)\n",
    "  - [⚗️ Sensitivity to unobserved confounding](#robustness)\n",
    "\n",
    "- [🧬 Counterfactual Thinking](#counterfactuals)\n",
    "  - [🤖 Predicting what would’ve happened](#what-if)\n",
    "  - [🔁 Usage in recommendation & personalization](#personalization)\n",
    "\n",
    "- [📌 Closing Notes](#closing-notes)\n",
    "  - [📝 Summary table of methods](#summary-table)\n",
    "  - [📋 When to use what](#method-choice)\n",
    "  - [📎 Causal vs Predictive mindset](#causal-vs-predictive)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65903c57",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# 🎯 Introduction to Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd39d98",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>🧠 Why this Notebook</h5>\n",
    "\n",
    "<p>Causal inference gives us the tools to answer \"what if\" questions — not just \"what is.\" In product, policy, medicine, and science, we often need to <strong>act</strong>, and actions require understanding their consequences.</p>\n",
    "\n",
    "<p>This field helps us:</p>\n",
    "<ul>\n",
    "  <li>Understand <strong>how</strong> and <strong>why</strong> outcomes change.</li>\n",
    "  <li>Move from data <em>descriptions</em> to data-<em>driven interventions</em>.</li>\n",
    "  <li>Avoid the trap of chasing noisy correlations.</li>\n",
    "</ul>\n",
    "\n",
    "<p>This notebook is a build-up from first principles to practical methods — with enough grounding to reason about experiments, models, and their assumptions clearly.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd6e5a",
   "metadata": {},
   "source": [
    "<a id=\"what-is-causal\"></a>\n",
    "#### 🎓 What is Causal Inference?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddec552",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>🎓 Causal inference is the process of estimating the <strong>effect</strong> of one variable (the treatment) on another (the outcome), holding all else constant.</h5>\n",
    "\n",
    "<p>The core idea is to estimate:</p>\n",
    "<blockquote>What would the outcome have been if the treatment had (or had not) occurred?</blockquote>\n",
    "\n",
    "<p>Unlike correlation or predictive modeling:</p>\n",
    "<ul>\n",
    "  <li>It asks <strong>counterfactual</strong> questions — what <em>would</em> have happened under different scenarios.</li>\n",
    "  <li>It requires <strong>assumptions</strong>, <strong>design</strong>, and often <strong>randomization</strong> or clever statistical tricks.</li>\n",
    "</ul>\n",
    "\n",
    "<p>At its heart, causal inference is about:</p>\n",
    "<ul>\n",
    "  <li>Designing better <strong>interventions</strong></li>\n",
    "  <li>Estimating <strong>treatment effects</strong></li>\n",
    "  <li>Avoiding misleading <strong>associational patterns</strong></li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e04cf",
   "metadata": {},
   "source": [
    "<a id=\"why-correlation\"></a>\n",
    "#### 📌 Why go beyond Correlation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7aa8cf",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>📌 Correlation can be dangerous when used as a proxy for causation.</h5>\n",
    "\n",
    "<p>Example: Ice cream sales are correlated with shark attacks. Should we ban dessert?  \n",
    "Clearly not — they’re both caused by heatwaves (a confounder).</p>\n",
    "\n",
    "<p>Correlation fails because it:</p>\n",
    "<ul>\n",
    "  <li>Ignores <strong>confounders</strong> (common causes of both variables)</li>\n",
    "  <li>Misses <strong>directionality</strong> (what affects what)</li>\n",
    "  <li>Can be driven by <strong>reverse causation</strong> or <strong>coincidence</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>Causal inference gives tools to:</p>\n",
    "<ul>\n",
    "  <li><strong>Identify</strong> confounding</li>\n",
    "  <li><strong>Design</strong> better studies (randomized or observational)</li>\n",
    "  <li><strong>Interpret</strong> results in terms of actionable causes</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd9a45",
   "metadata": {},
   "source": [
    "<a id=\"real-world-examples\"></a>\n",
    "#### 🧭 Real-world problems that need causality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cdc369",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>🧭 Correlation might be fine for dashboards. But when making <strong>decisions</strong>, causality is non-negotiable.</h5>\n",
    "\n",
    "<p>Examples:</p>\n",
    "<ul>\n",
    "  <li><strong>Product</strong>: Did that new button placement increase checkout, or was it a seasonal effect?</li>\n",
    "  <li><strong>Marketing</strong>: Did the email nudge lead to purchases, or did loyal users open it anyway?</li>\n",
    "  <li><strong>Policy</strong>: Did a tax cut help the economy, or was it already improving?</li>\n",
    "  <li><strong>Health</strong>: Does a drug reduce disease, or do healthier people tend to take it?</li>\n",
    "</ul>\n",
    "\n",
    "<p>These questions involve <strong>interventions</strong>, and only causal methods can tell us what would’ve happened under a different choice.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d999e6",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972fc15",
   "metadata": {},
   "source": [
    "<a id=\"notation-assumptions\"></a>\n",
    "# 🧠 Core Concepts & Notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb9997",
   "metadata": {},
   "source": [
    "<a id=\"treatment-outcome-units\"></a>\n",
    "#### 🧮 Treatment, Outcome, Units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7deb6",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Treatment (<code>T</code>)</strong>: The intervention or condition being tested (e.g., new design, drug, policy).</li>\n",
    "  <li><strong>Outcome (<code>Y</code>)</strong>: The result or metric affected by the treatment (e.g., click, recovery, score).</li>\n",
    "  <li><strong>Units (<code>i</code>)</strong>: The entities receiving treatment and producing outcomes (e.g., users, patients, schools).</li>\n",
    "</ul>\n",
    "\n",
    "<p>Each unit can receive a treatment or control, and we observe only one outcome — not both.</p>\n",
    "\n",
    "<p>This framing is universal and applies whether you're testing emails, ads, or vaccines.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e705a",
   "metadata": {},
   "source": [
    "<a id=\"potential-outcomes\"></a>\n",
    "#### 📐 Potential Outcomes (Rubin Causal Model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1931ace",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>The <strong>Potential Outcomes framework</strong> (aka Rubin Causal Model) imagines two parallel worlds for each unit:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><code>Y(1)</code>: Outcome if treated</li>\n",
    "  <li><code>Y(0)</code>: Outcome if not treated</li>\n",
    "</ul>\n",
    "\n",
    "<p>We define <strong>Individual Treatment Effect (ITE)</strong> as:</p>\n",
    "\n",
    "<blockquote>ITE = Y(1) - Y(0)</blockquote>\n",
    "\n",
    "<p><strong>Key idea:</strong></p>\n",
    "\n",
    "<p>Each unit has both potential outcomes — but we can only observe one. The other is <strong>counterfactual</strong>.</p>\n",
    "\n",
    "<p>This framework allows us to define:</p>\n",
    "\n",
    "<ul>\n",
    "  <li>ATE (Average Treatment Effect)</li>\n",
    "  <li>CATE (Conditional ATE, for subgroups)</li>\n",
    "</ul>\n",
    "\n",
    "<p>And formalizes why causal inference is hard: we never see both outcomes.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d3fd",
   "metadata": {},
   "source": [
    "<a id=\"fundamental-problem\"></a>\n",
    "#### 🧵 Fundamental Problem of Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f145ea",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<h5>The <strong>Fundamental Problem of Causal Inference</strong>:</h5>\n",
    "\n",
    "<blockquote>For any individual, we can observe only one potential outcome — never both.</blockquote>\n",
    "\n",
    "<p>Example:</p>\n",
    "<ul>\n",
    "  <li>A user sees version A → you observe <code>Y(0)</code></li>\n",
    "  <li>You’ll never know what <code>Y(1)</code> would have been for that exact user</li>\n",
    "</ul>\n",
    "\n",
    "<p>This creates a missing data problem: the counterfactual is unobservable.</p>\n",
    "\n",
    "<p>To solve this, we rely on:</p>\n",
    "<ul>\n",
    "  <li><strong>Randomization</strong></li>\n",
    "  <li><strong>Modeling + assumptions</strong></li>\n",
    "  <li><strong>Matching or weighting approaches</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>All causal methods are, in some way, trying to <strong>approximate the missing counterfactual</strong>.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee05897",
   "metadata": {},
   "source": [
    "<a id=\"core-assumptions\"></a>\n",
    "#### 🧠 Assumptions (SUTVA, Ignorability, Overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed826353",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Causal inference relies heavily on assumptions — even when you don’t randomize.</p>\n",
    "\n",
    "<h5>Three core ones:</h5>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>SUTVA (Stable Unit Treatment Value Assumption)</strong><br>\n",
    "  → Your treatment doesn’t affect someone else’s outcome.<br>\n",
    "  → No interference across units.</li>\n",
    "\n",
    "  <li><strong>Ignorability (a.k.a. Unconfoundedness)</strong><br>\n",
    "  → Given the observed covariates, treatment assignment is as good as random.<br>\n",
    "  → This lets you use observed data for estimation.</li>\n",
    "\n",
    "  <li><strong>Overlap (a.k.a. Positivity)</strong><br>\n",
    "  → Every unit has a non-zero probability of receiving either treatment.<br>\n",
    "  → You can’t learn effects where there’s no variation.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Without these, causal estimates can be biased or undefined. Always question whether they hold before trusting results.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb1851",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361ddee",
   "metadata": {},
   "source": [
    "<a id=\"simulated-data\"></a>\n",
    "# 🧪 Simulated Dataset Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1f238",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Simulating data is the best way to <em>control the truth</em> when learning causal inference.</p>\n",
    "\n",
    "<p>Here’s why we simulate:</p>\n",
    "<ul>\n",
    "  <li>You get full knowledge of ground-truth treatment effects.</li>\n",
    "  <li>You can deliberately create <strong>confounding</strong>, <strong>bias</strong>, <strong>non-randomness</strong>.</li>\n",
    "  <li>You can practice recovering the true causal effect using different methods.</li>\n",
    "</ul>\n",
    "\n",
    "<p>In real-world observational data, the \"truth\" is hidden. Simulating lets you debug your causal intuition safely before dealing with messy production datasets.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cffe669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Dataset Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# We'll define features, treatment assignment, and outcomes step-by-step later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fe447",
   "metadata": {},
   "source": [
    "<a id=\"treatment-logic\"></a>\n",
    "#### 🧬 Define treatment assignment logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab191ac",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>To simulate treatment realistically:</p>\n",
    "<ul>\n",
    "  <li>Treatment should <strong>depend</strong> on observed features.</li>\n",
    "  <li>Treatment <strong>should not</strong> be random — otherwise, no confounding to deal with.</li>\n",
    "</ul>\n",
    "\n",
    "<p>For example:</p>\n",
    "<ul>\n",
    "  <li>Wealthier users might be more likely to receive a premium offer.</li>\n",
    "  <li>Healthier patients might be less likely to receive intensive care.</li>\n",
    "</ul>\n",
    "\n",
    "<p>We’ll simulate a <strong>non-random treatment assignment</strong> based on a few covariates to mimic real-world biases.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541b4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define covariates (features)\n",
    "n = 5000\n",
    "\n",
    "age = np.random.normal(40, 12, n)       # Age\n",
    "income = np.random.normal(60000, 15000, n)  # Annual income\n",
    "prior_engagement = np.random.beta(2, 5, n)  # Past engagement score [0,1]\n",
    "\n",
    "# Treatment assignment probability based on features\n",
    "treatment_prob = (\n",
    "    0.3 * (income > 70000).astype(float) +\n",
    "    0.2 * (prior_engagement > 0.5).astype(float) +\n",
    "    0.1 * (age < 30).astype(float) +\n",
    "    np.random.normal(0, 0.05, n)  # small noise\n",
    ")\n",
    "treatment_prob = np.clip(treatment_prob, 0, 1)\n",
    "\n",
    "# Assign treatment\n",
    "T = np.random.binomial(1, treatment_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66180170",
   "metadata": {},
   "source": [
    "<a id=\"inject-confounding\"></a>\n",
    "#### 🔬 Inject confounding intentionally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6cc19a",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>In real-world datasets, treatment assignment is <strong>not random</strong> — it’s confounded by covariates.</p>\n",
    "\n",
    "<p>We deliberately inject confounding so that:</p>\n",
    "<ul>\n",
    "  <li>Covariates (age, income, engagement) affect both <strong>treatment</strong> and <strong>outcome</strong>.</li>\n",
    "  <li>If we naively compare treated vs untreated, we'll get biased results.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Confounding creates the need for adjustment, which will be a major theme later.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5463b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a \"true\" baseline outcome based on the same covariates\n",
    "base_outcome = (\n",
    "    50 + \n",
    "    0.02 * income +\n",
    "    5 * prior_engagement -\n",
    "    0.3 * age +\n",
    "    np.random.normal(0, 5, n)  # random noise\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca43ff",
   "metadata": {},
   "source": [
    "<a id=\"simulate-outcomes\"></a>\n",
    "#### 🧊 Simulate potential outcomes + observed data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4104ea8f",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>In the Rubin Potential Outcomes framework, each unit has two outcomes:</p>\n",
    "<ul>\n",
    "  <li><code>Y(1)</code> → If treated</li>\n",
    "  <li><code>Y(0)</code> → If not treated</li>\n",
    "</ul>\n",
    "\n",
    "<p>We can simulate this by:</p>\n",
    "<ul>\n",
    "  <li>Applying a <strong>true treatment effect</strong> to <code>Y(1)</code></li>\n",
    "  <li>Leaving <code>Y(0)</code> as the base outcome</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Important:</strong> We observe only one of <code>Y(1)</code> or <code>Y(0)</code>, depending on treatment assignment (<code>T</code>).</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ae0cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>prior_engagement</th>\n",
       "      <th>T</th>\n",
       "      <th>Y_obs</th>\n",
       "      <th>Y_0</th>\n",
       "      <th>Y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.960570</td>\n",
       "      <td>53643.604770</td>\n",
       "      <td>0.188077</td>\n",
       "      <td>0</td>\n",
       "      <td>1114.502287</td>\n",
       "      <td>1114.502287</td>\n",
       "      <td>1124.502287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.340828</td>\n",
       "      <td>53198.788374</td>\n",
       "      <td>0.170389</td>\n",
       "      <td>0</td>\n",
       "      <td>1099.893323</td>\n",
       "      <td>1099.893323</td>\n",
       "      <td>1109.893323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.772262</td>\n",
       "      <td>33065.352411</td>\n",
       "      <td>0.511379</td>\n",
       "      <td>0</td>\n",
       "      <td>704.133035</td>\n",
       "      <td>704.133035</td>\n",
       "      <td>714.133035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.276358</td>\n",
       "      <td>55048.647124</td>\n",
       "      <td>0.318793</td>\n",
       "      <td>0</td>\n",
       "      <td>1139.203509</td>\n",
       "      <td>1139.203509</td>\n",
       "      <td>1149.203509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.190160</td>\n",
       "      <td>70992.436227</td>\n",
       "      <td>0.384439</td>\n",
       "      <td>0</td>\n",
       "      <td>1464.308234</td>\n",
       "      <td>1464.308234</td>\n",
       "      <td>1474.308234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age        income  prior_engagement  T        Y_obs          Y_0  \\\n",
       "0  45.960570  53643.604770          0.188077  0  1114.502287  1114.502287   \n",
       "1  38.340828  53198.788374          0.170389  0  1099.893323  1099.893323   \n",
       "2  47.772262  33065.352411          0.511379  0   704.133035   704.133035   \n",
       "3  58.276358  55048.647124          0.318793  0  1139.203509  1139.203509   \n",
       "4  37.190160  70992.436227          0.384439  0  1464.308234  1464.308234   \n",
       "\n",
       "           Y_1  \n",
       "0  1124.502287  \n",
       "1  1109.893323  \n",
       "2   714.133035  \n",
       "3  1149.203509  \n",
       "4  1474.308234  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a true treatment effect (could vary by subgroup later)\n",
    "true_treatment_effect = 10  # a flat +10 effect for everyone\n",
    "\n",
    "# Simulate potential outcomes\n",
    "Y_0 = base_outcome\n",
    "Y_1 = base_outcome + true_treatment_effect\n",
    "\n",
    "# Observed outcome based on treatment assignment\n",
    "Y_obs = T * Y_1 + (1 - T) * Y_0\n",
    "\n",
    "# Assemble into a dataframe\n",
    "df = pd.DataFrame({\n",
    "    'age': age,\n",
    "    'income': income,\n",
    "    'prior_engagement': prior_engagement,\n",
    "    'T': T,\n",
    "    'Y_obs': Y_obs,\n",
    "    'Y_0': Y_0,\n",
    "    'Y_1': Y_1,\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49e27e",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dde548",
   "metadata": {},
   "source": [
    "<a id=\"naive-estimation\"></a>\n",
    "# 🚫 Naive Estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4860605",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>Many causal questions are first attacked by simply comparing the treated vs. untreated groups.</p>\n",
    "\n",
    "<p><strong>Naive Approach:</strong></p>\n",
    "<blockquote>Average outcome of treated - Average outcome of untreated.</blockquote>\n",
    "\n",
    "<p>This looks simple, but in observational data:</p>\n",
    "<ul>\n",
    "  <li>Treated and untreated units <strong>are not comparable</strong>.</li>\n",
    "  <li>Treatment assignment was <strong>not randomized</strong>.</li>\n",
    "  <li>Differences in baseline characteristics confound the simple difference.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Naive estimation <strong>almost always gives biased results</strong> unless you have perfect randomization.</p>\n",
    "\n",
    "<p>In this section, we'll see how bad the naive approach can get even on a simple synthetic dataset.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2c08e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive difference in means: 250.53\n",
      "True treatment effect (ground truth): 10\n"
     ]
    }
   ],
   "source": [
    "# Quick naive estimation\n",
    "treated_mean = df.loc[df['T'] == 1, 'Y_obs'].mean()\n",
    "control_mean = df.loc[df['T'] == 0, 'Y_obs'].mean()\n",
    "\n",
    "naive_diff = treated_mean - control_mean\n",
    "\n",
    "print(f\"Naive difference in means: {naive_diff:.2f}\")\n",
    "print(f\"True treatment effect (ground truth): {true_treatment_effect}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc35de",
   "metadata": {},
   "source": [
    "<a id=\"diff-in-means\"></a>\n",
    "#### ❌ Simple difference in means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83c050",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p>A simple difference in means is mathematically:</p>\n",
    "<blockquote><code>E[Y | T=1] - E[Y | T=0]</code></blockquote>\n",
    "\n",
    "<p>If treatment assignment were random:</p>\n",
    "<ul>\n",
    "  <li>The two groups would be exchangeable.</li>\n",
    "  <li>Baseline covariates would balance on average.</li>\n",
    "  <li>The simple difference would be an unbiased estimator of ATE.</li>\n",
    "</ul>\n",
    "\n",
    "<p>But if treatment is <strong>confounded</strong>, then:</p>\n",
    "<ul>\n",
    "  <li><code>T=1</code> units may systematically differ from <code>T=0</code> units.</li>\n",
    "  <li>The naive estimator picks up both <strong>causal effect</strong> and <strong>selection bias</strong>.</li>\n",
    "</ul>\n",
    "\n",
    "<p>We’ll soon quantify how large this bias can be.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ccff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>prior_engagement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.389926</td>\n",
       "      <td>58304.201745</td>\n",
       "      <td>0.278891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.892227</td>\n",
       "      <td>70283.224987</td>\n",
       "      <td>0.330779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age        income  prior_engagement\n",
       "T                                           \n",
       "0  40.389926  58304.201745          0.278891\n",
       "1  37.892227  70283.224987          0.330779"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's quickly visualize how the treated vs control groups differ in covariates\n",
    "df.groupby('T')[['age', 'income', 'prior_engagement']].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c7490",
   "metadata": {},
   "source": [
    "<a id=\"bias-confounding\"></a>\n",
    "#### ⚠️ Bias due to confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d8ecd",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Bias from confounding</strong> happens when:</p>\n",
    "<ul>\n",
    "  <li>The treated group has systematically different baseline outcomes than the control group.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Mathematically:</p>\n",
    "<blockquote>Observed difference = True treatment effect + Bias from baseline differences</blockquote>\n",
    "\n",
    "<p>In our simulation:</p>\n",
    "<ul>\n",
    "  <li>Higher income users are more likely to be treated.</li>\n",
    "  <li>Income also directly influences outcome.</li>\n",
    "  <li>Therefore, the observed difference <strong>overstates</strong> the real effect.</li>\n",
    "</ul>\n",
    "\n",
    "<p>This is why adjusting for confounders is critical — naive methods can easily mislead interventions and business decisions.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff38189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Y_0) difference between treated and control: 240.53\n",
      "This baseline imbalance creates bias in naive estimation.\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate the *average baseline outcome* (Y_0) in treated vs untreated groups\n",
    "treated_baseline = df.loc[df['T'] == 1, 'Y_0'].mean()\n",
    "control_baseline = df.loc[df['T'] == 0, 'Y_0'].mean()\n",
    "\n",
    "baseline_diff = treated_baseline - control_baseline\n",
    "\n",
    "print(f\"Baseline (Y_0) difference between treated and control: {baseline_diff:.2f}\")\n",
    "print(\"This baseline imbalance creates bias in naive estimation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2f4dd",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaffce9",
   "metadata": {},
   "source": [
    "<a id=\"causal-diagrams\"></a>\n",
    "# 🕸️ Causal Diagrams (DAGs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84191e2",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "**Directed Acyclic Graphs (DAGs)** are a compact way to represent assumptions about the data generating process.\n",
    "\n",
    "- Nodes = variables\n",
    "- Edges (arrows) = direct causal influence\n",
    "\n",
    "DAGs are not learned from data. They are **drawn from domain knowledge** to help reason about:\n",
    "- Confounders\n",
    "- Biases\n",
    "- Valid adjustment strategies\n",
    "\n",
    "Almost every causal inference method implicitly or explicitly assumes a DAG about the world.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b06f1",
   "metadata": {},
   "source": [
    "<a id=\"primer-dags\"></a>\n",
    "#### 🧿 Quick primer on DAGs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66cfd3e",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "A **DAG (Directed Acyclic Graph)** encodes assumptions about how variables causally relate.\n",
    "\n",
    "- **Directed**: Arrows have direction (cause → effect).\n",
    "- **Acyclic**: No feedback loops allowed (you can’t return to a node).\n",
    "\n",
    "Example:\n",
    "> Age → Income → Health\n",
    "\n",
    "Means:\n",
    "- Age affects income.\n",
    "- Income affects health.\n",
    "- No reverse paths.\n",
    "\n",
    "DAGs help identify:\n",
    "- Which paths are confounded\n",
    "- Which variables to control for\n",
    "- Whether effects are identifiable\n",
    "\n",
    "They act like a **map** — letting you plan causal estimation strategies intelligently.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a48aa4",
   "metadata": {},
   "source": [
    "<a id=\"confounder-collider-mediator\"></a>\n",
    "#### 🕷️ Confounding vs. colliders vs. mediators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cccea1",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "**Confounders**:\n",
    "- Variables that influence both treatment and outcome.\n",
    "- Must be adjusted for to block bias.\n",
    "- Example: Age confounds the relationship between Exercise (T) and Health (Y).\n",
    "\n",
    "**Colliders**:\n",
    "- Variables caused by two other variables.\n",
    "- **Must NOT adjust for colliders** — doing so opens spurious associations.\n",
    "- Example: Adjusting for \"hospitalization\" might introduce bias when studying Smoking → Lung Disease.\n",
    "\n",
    "**Mediators**:\n",
    "- Variables on the causal pathway between treatment and outcome.\n",
    "- Adjusting for them **blocks part of the causal effect** you want to measure.\n",
    "- Example: Exercise → Fitness → Health (fitness is a mediator).\n",
    "\n",
    "👉 Correct adjustment requires distinguishing among these roles.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5353f4",
   "metadata": {},
   "source": [
    "<a id=\"estimability-from-dags\"></a>\n",
    "#### 🔗 What can/can’t be estimated just from data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3355a",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Not everything is identifiable from data alone — assumptions are unavoidable.\n",
    "\n",
    "**What can be estimated**:\n",
    "- Associations (correlations, patterns)\n",
    "- Conditional independence structures\n",
    "- Causal effects **if** the right covariates are controlled (based on DAG structure)\n",
    "\n",
    "**What cannot be estimated**:\n",
    "- Whether a relationship is causal (without assumptions)\n",
    "- The full structure of a DAG (unless randomized experiments are used)\n",
    "\n",
    "Data + assumptions → Causal conclusions.  \n",
    "Data alone → Only correlational findings.\n",
    "\n",
    "DAGs clarify where you need domain knowledge vs where data suffices.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6b2de",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef463393",
   "metadata": {},
   "source": [
    "<a id=\"backdoor-adjustment\"></a>\n",
    "# 🔍 Backdoor Adjustment Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7450c130",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Backdoor adjustment methods aim to block **backdoor paths** — non-causal paths that create bias between treatment and outcome.\n",
    "\n",
    "**Core idea**:\n",
    "- Identify variables (confounders) that open backdoor paths.\n",
    "- Condition on them — either by stratifying, modeling, or matching.\n",
    "\n",
    "Backdoor adjustment **simulates** what would happen if treatment assignment were random within levels of the confounders.\n",
    "\n",
    "It’s the foundational idea behind:\n",
    "- Regression\n",
    "- Matching\n",
    "- Stratification\n",
    "- Propensity scores\n",
    "\n",
    "If you can block all backdoor paths, you can estimate causal effects from observational data reliably.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7760664",
   "metadata": {},
   "source": [
    "<a id=\"conditioning\"></a>\n",
    "#### 🧾 Conditioning on confounders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1f903",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Conditioning means **holding confounders constant** when comparing treated vs untreated units.\n",
    "\n",
    "Examples:\n",
    "- Comparing treated vs untreated users **within each income band**.\n",
    "- Comparing recovery rates **within each age group**.\n",
    "\n",
    "By conditioning, you eliminate the variation due to confounders, isolating the causal effect.\n",
    "\n",
    "**Important:**  \n",
    "You should only condition on true confounders — not colliders or mediators.\n",
    "\n",
    "Conditioning can be implemented via:\n",
    "- Subgrouping\n",
    "- Regression\n",
    "- Matching\n",
    "- Weighting\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74217e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Conditional Difference by Income Group:\n",
      "T                 diff\n",
      "high_income           \n",
      "0            16.867043\n",
      "1            13.563878\n"
     ]
    }
   ],
   "source": [
    "# Simple conditioning by subgroup (example: income > 70k vs <= 70k)\n",
    "df['high_income'] = (df['income'] > 70000).astype(int)\n",
    "\n",
    "grouped = df.groupby(['high_income', 'T'])['Y_obs'].mean().unstack()\n",
    "grouped['diff'] = grouped[1] - grouped[0]\n",
    "\n",
    "print(\"Simple Conditional Difference by Income Group:\")\n",
    "print(grouped[['diff']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e16492",
   "metadata": {},
   "source": [
    "<a id=\"stratification\"></a>\n",
    "#### 🕵️‍♂️ Stratification / Subgroup analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93353a4f",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Stratification means **breaking the dataset into buckets** based on confounders and comparing treatment effects within each bucket.\n",
    "\n",
    "Typical steps:\n",
    "1. Divide data based on a confounder (e.g., low vs high engagement).\n",
    "2. Within each stratum, compute treated vs control differences.\n",
    "3. Aggregate across strata (weighted average).\n",
    "\n",
    "**When useful:**\n",
    "- When confounders are categorical or easily discretized.\n",
    "- When interpretability is important.\n",
    "\n",
    "**Limits:**\n",
    "- Doesn’t scale well with many confounders (curse of dimensionality).\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d78e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Difference by Engagement Group:\n",
      "T                      diff\n",
      "high_engagement            \n",
      "0                290.043114\n",
      "1                145.885304\n"
     ]
    }
   ],
   "source": [
    "# Stratify based on prior_engagement (simple high vs low)\n",
    "df['high_engagement'] = (df['prior_engagement'] > 0.5).astype(int)\n",
    "\n",
    "strat_grouped = df.groupby(['high_engagement', 'T'])['Y_obs'].mean().unstack()\n",
    "strat_grouped['diff'] = strat_grouped[1] - strat_grouped[0]\n",
    "\n",
    "print(\"Conditional Difference by Engagement Group:\")\n",
    "print(strat_grouped[['diff']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00bc7ca",
   "metadata": {},
   "source": [
    "<a id=\"regression-adjustment\"></a>\n",
    "#### 📊 Regression Adjustment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6549d05",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Regression adjustment estimates causal effects by **controlling for confounders via regression**.\n",
    "\n",
    "Simple linear model:\n",
    "> `Y = β₀ + β₁·T + β₂·(confounder1) + β₃·(confounder2) + ... + ε`\n",
    "\n",
    "- `β₁` captures the **adjusted** effect of treatment, controlling for confounders.\n",
    "- It removes bias from observable confounders (under correct model specification).\n",
    "\n",
    "**Advantages:**\n",
    "- Easy to use.\n",
    "- Scales to many covariates.\n",
    "\n",
    "**Risks:**\n",
    "- Sensitive to model misspecification.\n",
    "- Wrong functional forms (nonlinearities, interactions) can bias estimates.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a2f4b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Y_obs   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 4.652e+06\n",
      "Date:                Sat, 26 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        17:22:58   Log-Likelihood:                -15122.\n",
      "No. Observations:                5000   AIC:                         3.025e+04\n",
      "Df Residuals:                    4995   BIC:                         3.029e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const               50.3660      0.398    126.398      0.000      49.585      51.147\n",
      "T                   10.0641      0.220     45.761      0.000       9.633      10.495\n",
      "age                 -0.2942      0.006    -49.784      0.000      -0.306      -0.283\n",
      "income               0.0200   4.83e-06   4142.593      0.000       0.020       0.020\n",
      "prior_engagement     4.3802      0.452      9.681      0.000       3.493       5.267\n",
      "==============================================================================\n",
      "Omnibus:                        5.657   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.059   Jarque-Bera (JB):                5.136\n",
      "Skew:                          -0.029   Prob(JB):                       0.0767\n",
      "Kurtosis:                       2.854   Cond. No.                     4.38e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.38e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Estimated treatment effect (β₁) after adjustment: 10.06\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = df[['T', 'age', 'income', 'prior_engagement']]\n",
    "X = sm.add_constant(X)\n",
    "y = df['Y_obs']\n",
    "\n",
    "reg_model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(reg_model.summary())\n",
    "\n",
    "print(f\"\\nEstimated treatment effect (β₁) after adjustment: {reg_model.params['T']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5906e36",
   "metadata": {},
   "source": [
    "<a id=\"psm\"></a>\n",
    "#### 📌 Propensity Score Matching (PSM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f267aa",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Propensity Score Matching (PSM) is a two-step procedure:\n",
    "1. Model the **probability of receiving treatment** (`P(T=1 | X)`) using observed covariates.\n",
    "2. Match treated and control units with **similar propensity scores**.\n",
    "\n",
    "**Why PSM?**\n",
    "- Instead of adjusting for many covariates separately, you balance treated and control groups on a single dimension (the propensity score).\n",
    "\n",
    "**When useful:**\n",
    "- When covariate space is high-dimensional.\n",
    "- When you want a matched sample that resembles randomized data.\n",
    "\n",
    "**Limitations:**\n",
    "- Requires good overlap (common support).\n",
    "- Still relies on unconfoundedness assumption.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e0ce90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propensity Score Matched Estimate of Treatment Effect: 197.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Step 1: Estimate propensity scores\n",
    "ps_model = LogisticRegression()\n",
    "ps_model.fit(df[['age', 'income', 'prior_engagement']], df['T'])\n",
    "df['propensity_score'] = ps_model.predict_proba(df[['age', 'income', 'prior_engagement']])[:,1]\n",
    "\n",
    "# Step 2: Nearest neighbor matching\n",
    "treated = df[df['T'] == 1]\n",
    "control = df[df['T'] == 0]\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(control[['propensity_score']])\n",
    "\n",
    "distances, indices = nn.kneighbors(treated[['propensity_score']])\n",
    "matched_control = control.iloc[indices.flatten()]\n",
    "\n",
    "# Calculate matched difference\n",
    "matched_diff = (treated['Y_obs'].values - matched_control['Y_obs'].values).mean()\n",
    "\n",
    "print(f\"Propensity Score Matched Estimate of Treatment Effect: {matched_diff:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b259b1",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229aa095",
   "metadata": {},
   "source": [
    "<a id=\"iv-methods\"></a>\n",
    "# 🎯 Instrumental Variables (IV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416579ed",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Instrumental Variables (IV) methods are used **when simple adjustment for confounders is impossible** or **not credible**.\n",
    "\n",
    "When treatment is **endogenous** (affected by unobserved factors also affecting outcome), traditional methods like regression fail.\n",
    "\n",
    "**IV solves this by:**\n",
    "- Using a \"proxy\" (instrument) that affects treatment but is otherwise unrelated to the outcome except through treatment.\n",
    "- \"Re-randomizing\" variation in treatment based on the instrument.\n",
    "\n",
    "You create **quasi-randomization** even in observational data.\n",
    "\n",
    "Classic examples:\n",
    "- Distance to hospital → instrument for getting surgery.\n",
    "- Random assignment of judges → instrument for harsher sentencing.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b63f1d",
   "metadata": {},
   "source": [
    "<a id=\"when-use-iv\"></a>\n",
    "#### 🪝 When backdoor paths can’t be blocked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71bc02",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "You need IV methods when:\n",
    "- There are **unobserved confounders** you can’t measure.\n",
    "- No set of observed covariates satisfies ignorability.\n",
    "- Standard backdoor adjustment will be biased.\n",
    "\n",
    "Example:\n",
    "- Studying the effect of education on income: natural intelligence is a hidden confounder (affects both education and income).\n",
    "- You can't just regress income ~ education — bias remains.\n",
    "\n",
    "**Key realization:**\n",
    "If **backdoor paths exist** through unobserved variables, IV becomes necessary.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0322fe",
   "metadata": {},
   "source": [
    "<a id=\"iv-conditions\"></a>\n",
    "#### 🎯 Valid instrument conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe6d3a",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "For an instrument (`Z`) to be valid, it must satisfy:\n",
    "\n",
    "1. **Relevance**:  \n",
    "   - `Z` must affect treatment `T`.  \n",
    "   (There must be a first-stage effect.)\n",
    "\n",
    "2. **Exclusion Restriction**:  \n",
    "   - `Z` must affect the outcome `Y` **only** through `T`.  \n",
    "   (No direct path from `Z` to `Y`.)\n",
    "\n",
    "3. **Independence (As-if Randomness)**:  \n",
    "   - `Z` must be independent of unobserved confounders affecting `Y`.\n",
    "\n",
    "---\n",
    "\n",
    "If any of these fail:\n",
    "- IV estimates are biased or meaningless.\n",
    "- You can’t fix bad instruments with bigger sample sizes.\n",
    "\n",
    "**Choosing or arguing a valid instrument is 90% of the IV battle.**\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fff624",
   "metadata": {},
   "source": [
    "<a id=\"2sls\"></a>\n",
    "#### 🧩 2-Stage Least Squares (2SLS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091cb2e9",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "**2SLS (Two-Stage Least Squares)** is the classic estimation procedure for IV:\n",
    "\n",
    "- **Stage 1**:  \n",
    "  Regress treatment `T` on instrument `Z` (and any controls)  \n",
    "  → get predicted treatment (`T̂`)\n",
    "\n",
    "- **Stage 2**:  \n",
    "  Regress outcome `Y` on predicted treatment (`T̂`)\n",
    "\n",
    "The second-stage coefficient gives the **causal effect** of treatment on outcome, isolating variation driven by the instrument.\n",
    "\n",
    "**Warning:**  \n",
    "- Standard regression software doesn't correct standard errors properly when doing 2SLS manually.  \n",
    "- Later packages like `linearmodels` automate this.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd70c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Y_obs   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 3.278e+06\n",
      "Date:                Sat, 26 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        17:24:24   Log-Likelihood:                -15996.\n",
      "No. Observations:                5000   AIC:                         3.200e+04\n",
      "Df Residuals:                    4995   BIC:                         3.203e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const               48.1296      0.474    101.498      0.000      47.200      49.059\n",
      "T_hat                0.2548      0.197      1.296      0.195      -0.131       0.640\n",
      "age                 -0.3133      0.007    -44.628      0.000      -0.327      -0.300\n",
      "income               0.0201   5.54e-06   3619.407      0.000       0.020       0.020\n",
      "prior_engagement     6.6954      0.540     12.391      0.000       5.636       7.755\n",
      "==============================================================================\n",
      "Omnibus:                       71.333   Durbin-Watson:                   1.970\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               74.381\n",
      "Skew:                           0.287   Prob(JB):                     7.05e-17\n",
      "Kurtosis:                       3.169   Cond. No.                     4.33e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.33e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Estimated causal effect (via 2SLS): 0.25\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "# Simulate an instrument Z (let's assume it's random and satisfies conditions)\n",
    "np.random.seed(42)\n",
    "df['Z'] = np.random.binomial(1, 0.5, size=len(df))\n",
    "\n",
    "# Make treatment depend partly on Z\n",
    "df['T_iv'] = (0.5 * df['Z'] + 0.5 * df['prior_engagement'] + np.random.normal(0, 0.1, len(df))) > 0.5\n",
    "df['T_iv'] = df['T_iv'].astype(int)\n",
    "\n",
    "# Stage 1: Predict treatment from instrument\n",
    "X_stage1 = add_constant(df[['Z', 'age', 'income', 'prior_engagement']])\n",
    "stage1_model = OLS(df['T_iv'], X_stage1).fit()\n",
    "df['T_hat'] = stage1_model.predict(X_stage1)\n",
    "\n",
    "# Stage 2: Predict outcome from predicted treatment\n",
    "X_stage2 = add_constant(df[['T_hat', 'age', 'income', 'prior_engagement']])\n",
    "stage2_model = OLS(df['Y_obs'], X_stage2).fit()\n",
    "\n",
    "print(stage2_model.summary())\n",
    "\n",
    "print(f\"\\nEstimated causal effect (via 2SLS): {stage2_model.params['T_hat']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1dff19",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff962ca0",
   "metadata": {},
   "source": [
    "<a id=\"dml-methods\"></a>\n",
    "# 🧰 Double Machine Learning (DML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddef79",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Double Machine Learning (DML) is a modern causal estimation technique that:\n",
    "\n",
    "- **Separates** the modeling of treatment and outcome.\n",
    "- **Uses flexible machine learning models** to control for complex confounders.\n",
    "- **Debiases** the final treatment effect estimation by orthogonalization.\n",
    "\n",
    "**Why DML matters:**\n",
    "- Traditional linear regression forces linearity.\n",
    "- DML allows for nonlinear, high-dimensional adjustment without overfitting causal estimates.\n",
    "\n",
    "It builds robust treatment effect estimators even when you use ML methods like Random Forests, XGBoost, or Neural Nets for intermediate steps.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9754c",
   "metadata": {},
   "source": [
    "<a id=\"ml-nuisance\"></a>\n",
    "#### 🪛 Use ML models for nuisance functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5116cb2",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "In DML, you model two \"nuisance functions\" first:\n",
    "1. **Outcome model**: `Y ~ X`\n",
    "2. **Treatment model**: `T ~ X`\n",
    "\n",
    "You can use **any ML model** (linear regression, random forest, gradient boosting, etc.) for these.\n",
    "\n",
    "**Key point:**  \n",
    "The goal is **accurate prediction**, not causal interpretation, at this stage.\n",
    "\n",
    "Later, DML uses the residuals from these models to isolate the causal effect of `T` on `Y`.\n",
    "\n",
    "This two-step process protects the final estimate from overfitting to noisy high-dimensional features.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e237a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features\n",
    "features = ['age', 'income', 'prior_engagement']\n",
    "\n",
    "# Split into train/test for honest estimation\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df['Y_obs'], test_size=0.3, random_state=42)\n",
    "T_train, T_test = train_test_split(df['T'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Outcome model: Y ~ X\n",
    "y_model = RandomForestRegressor()\n",
    "y_model.fit(X_train, y_train)\n",
    "df['y_hat'] = y_model.predict(df[features])\n",
    "\n",
    "# Treatment model: T ~ X\n",
    "t_model = RandomForestRegressor()\n",
    "t_model.fit(X_train, T_train)\n",
    "df['t_hat'] = t_model.predict(df[features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000b403",
   "metadata": {},
   "source": [
    "<a id=\"residualization\"></a>\n",
    "#### 🧱 Residualization + orthogonalization logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77758e",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "After fitting nuisance models:\n",
    "\n",
    "- Calculate **residuals**:\n",
    "  - `Residual_Y = Y - Ŷ`\n",
    "  - `Residual_T = T - T̂`\n",
    "\n",
    "- Then regress **Residual_Y ~ Residual_T**.\n",
    "\n",
    "Why?\n",
    "- This removes the part of `Y` and `T` that is predictable from `X`.\n",
    "- What remains captures the **\"clean\" causal variation** of `T` on `Y`, orthogonal to confounders.\n",
    "\n",
    "This two-stage process is called **orthogonalization** — it minimizes bias from overfitting nuisance functions.\n",
    "\n",
    "It’s a key innovation that separates DML from naive ML-based adjustment.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df536cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             residual_Y   R-squared:                       0.127\n",
      "Model:                            OLS   Adj. R-squared:                  0.127\n",
      "Method:                 Least Squares   F-statistic:                     726.5\n",
      "Date:                Sat, 26 Apr 2025   Prob (F-statistic):          1.62e-149\n",
      "Time:                        17:25:33   Log-Likelihood:                -14928.\n",
      "No. Observations:                5000   AIC:                         2.986e+04\n",
      "Df Residuals:                    4998   BIC:                         2.987e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0842      0.068      1.243      0.214      -0.049       0.217\n",
      "residual_T     8.9188      0.331     26.953      0.000       8.270       9.567\n",
      "==============================================================================\n",
      "Omnibus:                     7090.850   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          9991352.741\n",
      "Skew:                           7.694   Prob(JB):                         0.00\n",
      "Kurtosis:                     221.453   Cond. No.                         4.88\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Estimated causal effect via DML: 8.92\n"
     ]
    }
   ],
   "source": [
    "# Calculate residuals\n",
    "df['residual_Y'] = df['Y_obs'] - df['y_hat']\n",
    "df['residual_T'] = df['T'] - df['t_hat']\n",
    "\n",
    "# Final stage: regress residual_Y ~ residual_T\n",
    "X_resid = sm.add_constant(df['residual_T'])\n",
    "y_resid = df['residual_Y']\n",
    "\n",
    "residual_model = sm.OLS(y_resid, X_resid).fit()\n",
    "\n",
    "print(residual_model.summary())\n",
    "\n",
    "print(f\"\\nEstimated causal effect via DML: {residual_model.params['residual_T']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd36b53",
   "metadata": {},
   "source": [
    "<a id=\"dml-vs-regression\"></a>\n",
    "#### 🧲 When to prefer over traditional regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde7c45",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "You should prefer DML over traditional regression when:\n",
    "\n",
    "- **High-dimensional confounders** (lots of features) exist.\n",
    "- **Nonlinear relationships** are likely between covariates and treatment/outcome.\n",
    "- **Flexible modeling** is important (tree-based, neural nets, etc.)\n",
    "- **Concern about model misspecification** in simple linear regression.\n",
    "\n",
    "Traditional regression assumes:\n",
    "- Linear relationships\n",
    "- No complex interactions unless explicitly modeled\n",
    "\n",
    "DML frees you from strict parametric forms, allowing modern ML models while still aiming for valid causal estimates.\n",
    "\n",
    "✅ DML shines in modern settings: tech products, healthcare, online platforms — where datasets are messy, rich, and big.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14a213",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15edb2",
   "metadata": {},
   "source": [
    "<a id=\"heterogeneous-effects\"></a>\n",
    "# 🌈 Heterogeneous Treatment Effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb6bb3",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Until now, we've talked about the **average** effect of treatment across the entire population (ATE).\n",
    "\n",
    "But in reality:\n",
    "- Different users respond differently.\n",
    "- Treatment effects **vary** by user characteristics.\n",
    "\n",
    "**Heterogeneous Treatment Effects** (HTE) study how effects vary:\n",
    "- Across groups (e.g., high engagement vs low engagement)\n",
    "- Across individuals (personalized effects)\n",
    "\n",
    "Estimating HTE is critical for:\n",
    "- Personalized recommendations\n",
    "- Smart targeting (marketing, healthcare, product launches)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ad0cd",
   "metadata": {},
   "source": [
    "<a id=\"ate-cate-ite\"></a>\n",
    "#### 🎨 ATE vs. CATE vs. ITE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba90ea5",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Different layers of treatment effect granularity:\n",
    "\n",
    "- **ATE (Average Treatment Effect)**:  \n",
    "  - Average effect across everyone.\n",
    "\n",
    "- **CATE (Conditional Average Treatment Effect)**:  \n",
    "  - Average effect **given some subgroup** (e.g., CATE for users <30 years old).\n",
    "\n",
    "- **ITE (Individual Treatment Effect)**:  \n",
    "  - Effect for a **specific user**.\n",
    "\n",
    "---\n",
    "\n",
    "**In practice:**\n",
    "- ATE is easiest to estimate.\n",
    "- CATEs are often actionable (targeted marketing).\n",
    "- ITEs are the hardest — noisy and high-variance.\n",
    "\n",
    "Good causal inference methods can recover CATEs/ITEs **if** enough data and signal exist.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1385a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ATE: 10.00\n",
      "CATE for high engagement users: 10.00\n",
      "\n",
      "Sample ITEs:\n",
      "         age        income  prior_engagement  ITE_true\n",
      "0  45.960570  53643.604770          0.188077      10.0\n",
      "1  38.340828  53198.788374          0.170389      10.0\n",
      "2  47.772262  33065.352411          0.511379      10.0\n",
      "3  58.276358  55048.647124          0.318793      10.0\n",
      "4  37.190160  70992.436227          0.384439      10.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate ATE (simple diff from simulation ground truth)\n",
    "ate = (df['Y_1'] - df['Y_0']).mean()\n",
    "print(f\"True ATE: {ate:.2f}\")\n",
    "\n",
    "# Calculate CATE for high engagement group\n",
    "cate_high_engagement = (df[df['prior_engagement'] > 0.5]['Y_1'] - df[df['prior_engagement'] > 0.5]['Y_0']).mean()\n",
    "print(f\"CATE for high engagement users: {cate_high_engagement:.2f}\")\n",
    "\n",
    "# Show a few ITEs\n",
    "df['ITE_true'] = df['Y_1'] - df['Y_0']\n",
    "print(\"\\nSample ITEs:\")\n",
    "print(df[['age', 'income', 'prior_engagement', 'ITE_true']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26833b",
   "metadata": {},
   "source": [
    "<a id=\"uplift-usecases\"></a>\n",
    "#### 🌟 Uplift models and use cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565df4a8",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "**Uplift modeling** directly models the **difference in probability** of a positive outcome between treated and untreated users.\n",
    "\n",
    "Instead of modeling outcome probabilities separately, uplift models focus on:\n",
    "- Who is **most persuadable**?\n",
    "- Who would change behavior because of treatment?\n",
    "\n",
    "**Where uplift models shine:**\n",
    "- Marketing campaigns (maximize conversions per dollar)\n",
    "- Customer retention (target save offers only to those who would churn)\n",
    "- Medical interventions (target high-risk patients)\n",
    "\n",
    "---\n",
    "\n",
    "**Typical techniques:**\n",
    "- Uplift Decision Trees\n",
    "- Two-model approach (predict Y|T=1 and Y|T=0 separately, then subtract)\n",
    "- Causal Forests\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5969183",
   "metadata": {},
   "source": [
    "<a id=\"causal-forests\"></a>\n",
    "#### 🧩 Tree-based methods (Causal Trees, Causal Forests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a7811",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Tree-based methods are powerful for discovering treatment effect heterogeneity:\n",
    "\n",
    "- **Causal Trees**:\n",
    "  - Split data to maximize treatment effect differences between branches.\n",
    "  - One tree trained specifically for causal splits.\n",
    "\n",
    "- **Causal Forests**:\n",
    "  - Ensemble of causal trees.\n",
    "  - Averages treatment effect estimates across trees.\n",
    "  - Reduces variance compared to a single tree.\n",
    "\n",
    "They can estimate **CATEs** reliably across different subgroups without manually specifying interactions.\n",
    "\n",
    "---\n",
    "\n",
    "**When useful:**\n",
    "- You expect heterogeneity but don't know in advance how to segment.\n",
    "- You want flexible, interpretable treatment effect estimation.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2a80046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting econml\n",
      "  Downloading econml-0.15.1-cp311-cp311-macosx_11_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.24.3)\n",
      "Requirement already satisfied: scipy>1.4.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn<1.6,>=1.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.2.2)\n",
      "Collecting sparse (from econml)\n",
      "  Downloading sparse-0.16.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.10 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (0.13.5)\n",
      "Requirement already satisfied: pandas>1.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.5.3)\n",
      "Collecting shap<0.44.0,>=0.38.1 (from econml)\n",
      "  Downloading shap-0.43.0-cp311-cp311-macosx_11_0_arm64.whl (445 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.4/445.4 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lightgbm in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (4.3.0)\n",
      "Requirement already satisfied: packaging in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from pandas>1.0->econml) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from pandas>1.0->econml) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from scikit-learn<1.6,>=1.0->econml) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (4.65.0)\n",
      "Collecting slicer==0.0.7 (from shap<0.44.0,>=0.38.1->econml)\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (0.57.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (2.2.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.10->econml) (0.5.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from numba->shap<0.44.0,>=0.38.1->econml) (0.40.0)\n",
      "Requirement already satisfied: six in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels>=0.10->econml) (1.16.0)\n",
      "Installing collected packages: slicer, sparse, shap, econml\n",
      "Successfully installed econml-0.15.1 shap-0.43.0 slicer-0.0.7 sparse-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd33d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predicted CATEs:\n",
      "         age        income  prior_engagement  CATE_predicted\n",
      "0  45.960570  53643.604770          0.188077       15.767683\n",
      "1  38.340828  53198.788374          0.170389       18.062330\n",
      "2  47.772262  33065.352411          0.511379       -4.625701\n",
      "3  58.276358  55048.647124          0.318793       14.400047\n",
      "4  37.190160  70992.436227          0.384439       11.047467\n"
     ]
    }
   ],
   "source": [
    "# Causal Forest: Full Correct Code\n",
    "\n",
    "from econml.grf import CausalForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features and outcome\n",
    "X = df[['age', 'income', 'prior_engagement']].values  # Features (2D)\n",
    "T = df['T'].values  # Treatment (1D)\n",
    "Y = df['Y_obs'].values  # Observed outcome (1D)\n",
    "\n",
    "# Fit causal forest\n",
    "forest = CausalForest(n_estimators=100, random_state=42)\n",
    "forest.fit(X, T, Y)  # Correct order: X, T, Y\n",
    "\n",
    "# Predict treatment effects (CATEs)\n",
    "cate_preds = forest.predict(X)\n",
    "\n",
    "# Store predictions\n",
    "df['CATE_predicted'] = cate_preds\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample predicted CATEs:\")\n",
    "print(df[['age', 'income', 'prior_engagement', 'CATE_predicted']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296df001",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291ba4e",
   "metadata": {},
   "source": [
    "<a id=\"placebo-robustness\"></a>\n",
    "# 🧪 Placebo Tests & Robustness Checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfbd97b",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Even after careful causal estimation, you must ask:\n",
    "- Was it a real effect?\n",
    "- Could hidden bias still exist?\n",
    "\n",
    "**Robustness checks** build confidence that your findings are not artifacts of modeling choices, random noise, or hidden confounders.\n",
    "\n",
    "**Placebo tests** simulate situations where you expect **no effect** — if you detect an effect there, something's wrong.\n",
    "\n",
    "Robust causal analysis is not just about point estimates — it’s about **proving to yourself that you aren't fooling yourself**.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec13654",
   "metadata": {},
   "source": [
    "<a id=\"placebo\"></a>\n",
    "#### 🧻 Randomized placebo treatments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e7d03",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Placebo tests inject \"fake\" treatments to validate your method.\n",
    "\n",
    "**Idea:**\n",
    "- Randomly assign a placebo treatment.\n",
    "- Re-estimate the treatment effect.\n",
    "- Expect **no significant effect** if your method is honest.\n",
    "\n",
    "If your model finds strong effects even when treatment is randomized, your pipeline is leaking bias or overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "**Placebo Tests Are Critical:**\n",
    "- They detect specification errors.\n",
    "- They detect uncontrolled confounding.\n",
    "- They expose overfitting to noise.\n",
    "\n",
    "Placebo tests are a basic but powerful check — always worth doing.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b0287d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placebo test: naive difference in means = 7.79\n"
     ]
    }
   ],
   "source": [
    "# Create a random placebo treatment\n",
    "np.random.seed(123)\n",
    "df['placebo_T'] = np.random.binomial(1, 0.5, size=len(df))\n",
    "\n",
    "# Estimate naive difference for placebo treatment\n",
    "placebo_treated_mean = df.loc[df['placebo_T'] == 1, 'Y_obs'].mean()\n",
    "placebo_control_mean = df.loc[df['placebo_T'] == 0, 'Y_obs'].mean()\n",
    "\n",
    "placebo_naive_diff = placebo_treated_mean - placebo_control_mean\n",
    "\n",
    "print(f\"Placebo test: naive difference in means = {placebo_naive_diff:.2f}\")\n",
    "\n",
    "# Ideally close to zero if model is unbiased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef2135",
   "metadata": {},
   "source": [
    "<a id=\"robustness\"></a>\n",
    "#### ⚗️ Sensitivity to unobserved confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb34b3db",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Even after adjusting for observed confounders, **unobserved variables** can still bias causal estimates.\n",
    "\n",
    "**Sensitivity analysis** asks:\n",
    "- How strong would hidden confounding have to be to overturn my results?\n",
    "\n",
    "---\n",
    "\n",
    "**Typical approaches:**\n",
    "- Simulate hidden confounders and see effect size shifts.\n",
    "- Use formulas (like Rosenbaum bounds) to quantify robustness.\n",
    "\n",
    "In practical data science:\n",
    "- Simulate scenarios with added fake bias.\n",
    "- Stress test conclusions under \"worst plausible\" hidden biases.\n",
    "\n",
    "If your conclusions survive plausible levels of unobserved bias, they are more credible.\n",
    "\n",
    "**Important mindset:**  \n",
    "No analysis is perfect — the goal is to **understand limits, not pretend away uncertainty**.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0444449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive difference in means (with hidden confounding): 250.11\n",
      "Inflation in estimate due to hidden confounder: -0.42\n"
     ]
    }
   ],
   "source": [
    "# Simulate a hidden confounder correlated with treatment and outcome\n",
    "np.random.seed(42)\n",
    "df['hidden_confounder'] = np.random.normal(0, 1, size=len(df))\n",
    "\n",
    "# Make the outcome depend slightly on this hidden confounder\n",
    "df['Y_obs_biased'] = df['Y_obs'] + 2 * df['hidden_confounder']\n",
    "\n",
    "# Re-run naive difference with biased outcome\n",
    "treated_mean_biased = df.loc[df['T'] == 1, 'Y_obs_biased'].mean()\n",
    "control_mean_biased = df.loc[df['T'] == 0, 'Y_obs_biased'].mean()\n",
    "\n",
    "biased_naive_diff = treated_mean_biased - control_mean_biased\n",
    "\n",
    "print(f\"Naive difference in means (with hidden confounding): {biased_naive_diff:.2f}\")\n",
    "\n",
    "# See how much bias was introduced\n",
    "bias_inflation = biased_naive_diff - naive_diff\n",
    "print(f\"Inflation in estimate due to hidden confounder: {bias_inflation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43860c2",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a9b11",
   "metadata": {},
   "source": [
    "<a id=\"counterfactuals\"></a>\n",
    "# 🧬 Counterfactual Thinking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51896a85",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "**Counterfactual thinking** is the backbone of causal inference.\n",
    "\n",
    "Instead of asking:\n",
    "> \"What happened?\"\n",
    "\n",
    "We ask:\n",
    "> \"What *would have* happened if things were different?\"\n",
    "\n",
    "In causal inference:\n",
    "- Each unit (user, patient, item) has two potential outcomes.\n",
    "- Only one is observed.\n",
    "- The other — the counterfactual — must be predicted or estimated.\n",
    "\n",
    "---\n",
    "\n",
    "**Counterfactual reasoning enables:**\n",
    "- Simulating user behavior under alternate scenarios.\n",
    "- Personalizing interventions based on predicted outcomes.\n",
    "\n",
    "Without counterfactuals, causal inference is blind.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4f6b0",
   "metadata": {},
   "source": [
    "<a id=\"what-if\"></a>\n",
    "#### 🤖 Predicting what would’ve happened\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32b2ad",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Predicting counterfactuals means estimating:\n",
    "- `Y(1)` for untreated units.\n",
    "- `Y(0)` for treated units.\n",
    "\n",
    "We use:\n",
    "- Machine learning models trained on observed data.\n",
    "- Causal forests, meta-learners, and other counterfactual predictors.\n",
    "\n",
    "**Goal:**\n",
    "- Recover the missing potential outcome.\n",
    "- Estimate **individual treatment effects (ITEs)**.\n",
    "\n",
    "This enables granular interventions — not just average effects across a population.\n",
    "\n",
    "---\n",
    "\n",
    "**Important to remember:**  \n",
    "Predicted counterfactuals are **estimates**, not direct observations — uncertainty always exists.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99646aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Counterfactual Predictions:\n",
      "   T        Y_obs  counterfactual_outcome\n",
      "0  0  1114.502287             1127.868133\n",
      "1  0  1099.893323             1119.847270\n",
      "2  0   704.133035              697.394845\n",
      "3  0  1139.203509             1151.640784\n",
      "4  0  1464.308234             1475.218807\n"
     ]
    }
   ],
   "source": [
    "# Predict counterfactual outcomes using Causal Forest\n",
    "# (Already trained earlier, we use forest)\n",
    "\n",
    "# Predict Y(1) and Y(0) separately\n",
    "cate_preds = df['CATE_predicted'].values\n",
    "baseline_preds = df['y_hat'].values  # From earlier outcome model\n",
    "\n",
    "# Predict counterfactual outcomes\n",
    "df['Y_cf_T1'] = baseline_preds + cate_preds  # Predicted outcome if treated\n",
    "df['Y_cf_T0'] = baseline_preds  # Predicted outcome if untreated (baseline)\n",
    "\n",
    "# Now simulate what would happen if treatment status flipped\n",
    "df['counterfactual_outcome'] = np.where(\n",
    "    df['T'] == 1,\n",
    "    df['Y_cf_T0'],  # If treated, counterfactual is untreated\n",
    "    df['Y_cf_T1']   # If untreated, counterfactual is treated\n",
    ")\n",
    "\n",
    "print(\"\\nSample Counterfactual Predictions:\")\n",
    "print(df[['T', 'Y_obs', 'counterfactual_outcome']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd5c38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<a id=\"personalization\"></a>\n",
    "#### 🔁 Usage in recommendation & personalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3ae63",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "**Counterfactual predictions unlock personalization:**\n",
    "\n",
    "Instead of treating everyone the same, you can:\n",
    "- Target users where treatment has highest predicted uplift.\n",
    "- De-prioritize users who won't respond.\n",
    "\n",
    "Examples:\n",
    "- **Marketing**: Show ads only to users likely to convert if nudged.\n",
    "- **Healthcare**: Prioritize interventions for patients who benefit most.\n",
    "- **Products**: Recommend features or promotions to maximize lift per user.\n",
    "\n",
    "---\n",
    "\n",
    "**Strategic mindshift:**  \n",
    "Focus on **marginally persuadable users**, not just overall averages.\n",
    "\n",
    "---\n",
    "\n",
    "Real-world use cases often combine:\n",
    "- Causal effect estimation (CATE/ITE)\n",
    "- Ranking users by expected benefit\n",
    "- Action prioritization based on counterfactuals\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e8c9fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top users to prioritize based on CATE:\n",
      "            age        income  prior_engagement  CATE_predicted\n",
      "2841  21.800289  53281.835326          0.350447       20.543173\n",
      "724   42.050385  53280.579923          0.403388       20.443580\n",
      "3205  31.876058  53300.354298          0.420334       20.411161\n",
      "4614  40.670367  53244.477131          0.632127       20.275141\n",
      "3711  24.210210  53209.647772          0.335915       20.259483\n"
     ]
    }
   ],
   "source": [
    "# Rank users by predicted CATE\n",
    "df['priority_score'] = df['CATE_predicted']\n",
    "\n",
    "# Top 5 users we should prioritize for treatment\n",
    "top_users = df.sort_values('priority_score', ascending=False).head(5)\n",
    "\n",
    "print(\"\\nTop users to prioritize based on CATE:\")\n",
    "print(top_users[['age', 'income', 'prior_engagement', 'CATE_predicted']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98552806",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cfc25e",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# 📌 Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a40be",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "You now have a practical understanding of core causal inference techniques.\n",
    "\n",
    "You should be able to:\n",
    "- Simulate data with confounding\n",
    "- Estimate naive effects and detect bias\n",
    "- Adjust using regression, matching, stratification\n",
    "- Apply modern tools like DML and Causal Forests\n",
    "- Think in terms of counterfactuals, not just correlations\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:**  \n",
    "Causal thinking is not just a technique — it’s a lens to see decision-making clearly.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ea89f",
   "metadata": {},
   "source": [
    "<a id=\"summary-table\"></a>\n",
    "#### 📝 Summary table of methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62794b76",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "| Method | When Useful | Strengths | Weaknesses |\n",
    "|:---|:---|:---|:---|\n",
    "| **Simple Diff-in-Means** | Randomized experiments | Easy, unbiased | Useless with confounding |\n",
    "| **Regression Adjustment** | Observational data with measured confounders | Easy to implement | Model misspecification risk |\n",
    "| **Stratification** | Small number of discrete confounders | Transparent | Breaks down in high dimensions |\n",
    "| **Propensity Score Matching (PSM)** | Observational data with many confounders | Balances groups | Sensitive to model of treatment |\n",
    "| **Instrumental Variables (IV)** | Unobserved confounders exist | Bypasses confounding | Hard to find good instruments |\n",
    "| **Double Machine Learning (DML)** | High-dimensional nonlinear confounders | ML flexibility + debiasing | Needs lots of data, honest splits |\n",
    "| **Causal Forests** | Heterogeneous treatment effects | Flexible CATE estimation | Complex, less interpretable |\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27428737",
   "metadata": {},
   "source": [
    "<a id=\"method-choice\"></a>\n",
    "#### 📋 When to use what\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca88bf3",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "**Choosing a method depends on:**\n",
    "\n",
    "- **Randomization present?**\n",
    "  - Yes → Simple difference in means is fine.\n",
    "  - No → Need adjustment.\n",
    "\n",
    "- **Are confounders observed?**\n",
    "  - Yes → Regression, PSM, DML are options.\n",
    "  - No → Need IV or natural experiments.\n",
    "\n",
    "- **Do you expect heterogeneous effects?**\n",
    "  - Yes → Causal Trees, Causal Forests, Meta-learners.\n",
    "\n",
    "- **Is high-dimensional data involved?**\n",
    "  - Yes → Prefer DML over simple regression.\n",
    "\n",
    "---\n",
    "\n",
    "Choosing the right method = matching the method to the bias and complexity in your data.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e590a5",
   "metadata": {},
   "source": [
    "<a id=\"causal-vs-predictive\"></a>\n",
    "#### 📎 Causal vs Predictive mindset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7955a8db",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "**Predictive modeling mindset:**\n",
    "- Focuses on fitting observed outcomes.\n",
    "- Good for forecasts, risk scores, recommendation engines.\n",
    "- Does not care about interventions.\n",
    "\n",
    "**Causal inference mindset:**\n",
    "- Focuses on *what would happen if we intervened*.\n",
    "- Good for making decisions (policies, treatments, products).\n",
    "- Requires stronger assumptions, careful design.\n",
    "\n",
    "---\n",
    "\n",
    "**Key difference:**  \n",
    "Predictive models can be accurate yet useless for interventions.  \n",
    "Causal models are harder but necessary to make confident decisions.\n",
    "\n",
    "---\n",
    "\n",
    "**Quote to remember:**  \n",
    "> \"All models are wrong. Some models are useful.  \n",
    "> Only causal models are useful for actions.\"\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f102463",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
