{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0300ea",
   "metadata": {},
   "source": [
    "![Status: In Progress](https://img.shields.io/badge/status-in--progress-yellow)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-70%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green)\n",
    "\n",
    "<!-- ![Status: Complete](https://img.shields.io/badge/status-complete-brightgreen)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-95%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green) -->\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# ğŸ§­ Causal Inference\n",
    "\n",
    "- [ğŸ¯ Introduction to Causal Inference](#intro)\n",
    "  - [ğŸ“ What is Causal Inference?](#what-is-causal)\n",
    "  - [ğŸ“Œ Why go beyond Correlation?](#why-correlation)\n",
    "  - [ğŸ§­ Real-world problems that need causality](#real-world-examples)\n",
    "\n",
    "- [ğŸ§  Core Concepts & Notation](#notation-assumptions)\n",
    "  - [ğŸ§® Treatment, Outcome, Units](#treatment-outcome-units)\n",
    "  - [ğŸ“ Potential Outcomes (Rubin Causal Model)](#potential-outcomes)\n",
    "  - [ğŸ§µ Fundamental Problem of Causal Inference](#fundamental-problem)\n",
    "  - [ğŸ§  Assumptions (SUTVA, Ignorability, Overlap)](#core-assumptions)\n",
    "\n",
    "- [ğŸ§ª Simulated Dataset Setup](#simulated-data)\n",
    "  - [ğŸ§¬ Define treatment assignment logic](#treatment-logic)\n",
    "  - [ğŸ”¬ Inject confounding intentionally](#inject-confounding)\n",
    "  - [ğŸ§Š Simulate potential outcomes + observed data](#simulate-outcomes)\n",
    "\n",
    "- [ğŸš« Naive Estimation](#naive-estimation)\n",
    "  - [âŒ Simple difference in means](#diff-in-means)\n",
    "  - [âš ï¸ Bias due to confounding](#bias-confounding)\n",
    "\n",
    "- [ğŸ•¸ï¸ Causal Diagrams (DAGs)](#causal-diagrams)\n",
    "  - [ğŸ§¿ Quick primer on DAGs](#primer-dags)\n",
    "  - [ğŸ•·ï¸ Confounding vs. colliders vs. mediators](#confounder-collider-mediator)\n",
    "  - [ğŸ”— What can/canâ€™t be estimated just from data](#estimability-from-dags)\n",
    "\n",
    "- [ğŸ” Backdoor Adjustment Methods](#backdoor-adjustment)\n",
    "  - [ğŸ§¾ Conditioning on confounders](#conditioning)\n",
    "  - [ğŸ•µï¸â€â™‚ï¸ Stratification / Subgroup analysis](#stratification)\n",
    "  - [ğŸ“Š Regression Adjustment](#regression-adjustment)\n",
    "  - [ğŸ“Œ Propensity Score Matching (PSM)](#psm)\n",
    "\n",
    "- [ğŸ¯ Instrumental Variables (IV)](#iv-methods)\n",
    "  - [ğŸª When backdoor paths canâ€™t be blocked](#when-use-iv)\n",
    "  - [ğŸ¯ Valid instrument conditions](#iv-conditions)\n",
    "  - [ğŸ§© 2-Stage Least Squares (2SLS)](#2sls)\n",
    "\n",
    "- [ğŸ§° Double Machine Learning (DML)](#dml-methods)\n",
    "  - [ğŸª› Use ML models for nuisance functions](#ml-nuisance)\n",
    "  - [ğŸ§± Residualization + orthogonalization logic](#residualization)\n",
    "  - [ğŸ§² When to prefer over traditional regression](#dml-vs-regression)\n",
    "\n",
    "- [ğŸŒˆ Heterogeneous Treatment Effects](#heterogeneous-effects)\n",
    "  - [ğŸ¨ ATE vs. CATE vs. ITE](#ate-cate-ite)\n",
    "  - [ğŸŒŸ Uplift models and use cases](#uplift-usecases)\n",
    "  - [ğŸ§© Tree-based methods (Causal Trees, Causal Forests)](#causal-forests)\n",
    "\n",
    "- [ğŸ§ª Placebo Tests & Robustness Checks](#placebo-robustness)\n",
    "  - [ğŸ§» Randomized placebo treatments](#placebo)\n",
    "  - [âš—ï¸ Sensitivity to unobserved confounding](#robustness)\n",
    "\n",
    "- [ğŸ§¬ Counterfactual Thinking](#counterfactuals)\n",
    "  - [ğŸ¤– Predicting what wouldâ€™ve happened](#what-if)\n",
    "  - [ğŸ” Usage in recommendation & personalization](#personalization)\n",
    "\n",
    "- [ğŸ“Œ Closing Notes](#closing-notes)\n",
    "  - [ğŸ“ Summary table of methods](#summary-table)\n",
    "  - [ğŸ“‹ When to use what](#method-choice)\n",
    "  - [ğŸ“ Causal vs Predictive mindset](#causal-vs-predictive)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65903c57",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# ğŸ¯ Introduction to Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd39d98",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<h5>ğŸ§  Why this Notebook</h5>\n",
    "\n",
    "<p>Causal inference gives us the tools to answer \"what if\" questions â€” not just \"what is.\" In product, policy, medicine, and science, we often need to <strong>act</strong>, and actions require understanding their consequences.</p>\n",
    "\n",
    "<p>This field helps us:</p>\n",
    "<ul>\n",
    "  <li>Understand <strong>how</strong> and <strong>why</strong> outcomes change.</li>\n",
    "  <li>Move from data <em>descriptions</em> to data-<em>driven interventions</em>.</li>\n",
    "  <li>Avoid the trap of chasing noisy correlations.</li>\n",
    "</ul>\n",
    "\n",
    "<p>This notebook is a build-up from first principles to practical methods â€” with enough grounding to reason about experiments, models, and their assumptions clearly.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd6e5a",
   "metadata": {},
   "source": [
    "<a id=\"what-is-causal\"></a>\n",
    "#### ğŸ“ What is Causal Inference?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddec552",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<h5>ğŸ“ Causal inference is the process of estimating the <strong>effect</strong> of one variable (the treatment) on another (the outcome), holding all else constant.</h5>\n",
    "\n",
    "<p>The core idea is to estimate:</p>\n",
    "<blockquote>What would the outcome have been if the treatment had (or had not) occurred?</blockquote>\n",
    "\n",
    "<p>Unlike correlation or predictive modeling:</p>\n",
    "<ul>\n",
    "  <li>It asks <strong>counterfactual</strong> questions â€” what <em>would</em> have happened under different scenarios.</li>\n",
    "  <li>It requires <strong>assumptions</strong>, <strong>design</strong>, and often <strong>randomization</strong> or clever statistical tricks.</li>\n",
    "</ul>\n",
    "\n",
    "<p>At its heart, causal inference is about:</p>\n",
    "<ul>\n",
    "  <li>Designing better <strong>interventions</strong></li>\n",
    "  <li>Estimating <strong>treatment effects</strong></li>\n",
    "  <li>Avoiding misleading <strong>associational patterns</strong></li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e04cf",
   "metadata": {},
   "source": [
    "<a id=\"why-correlation\"></a>\n",
    "#### ğŸ“Œ Why go beyond Correlation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7aa8cf",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<h5>ğŸ“Œ Correlation can be dangerous when used as a proxy for causation.</h5>\n",
    "\n",
    "<p>Example: Ice cream sales are correlated with shark attacks. Should we ban dessert?  \n",
    "Clearly not â€” theyâ€™re both caused by heatwaves (a confounder).</p>\n",
    "\n",
    "<p>Correlation fails because it:</p>\n",
    "<ul>\n",
    "  <li>Ignores <strong>confounders</strong> (common causes of both variables)</li>\n",
    "  <li>Misses <strong>directionality</strong> (what affects what)</li>\n",
    "  <li>Can be driven by <strong>reverse causation</strong> or <strong>coincidence</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>Causal inference gives tools to:</p>\n",
    "<ul>\n",
    "  <li><strong>Identify</strong> confounding</li>\n",
    "  <li><strong>Design</strong> better studies (randomized or observational)</li>\n",
    "  <li><strong>Interpret</strong> results in terms of actionable causes</li>\n",
    "</ul>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd9a45",
   "metadata": {},
   "source": [
    "<a id=\"real-world-examples\"></a>\n",
    "#### ğŸ§­ Real-world problems that need causality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cdc369",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<h5>ğŸ§­ Correlation might be fine for dashboards. But when making <strong>decisions</strong>, causality is non-negotiable.</h5>\n",
    "\n",
    "<p>Examples:</p>\n",
    "<ul>\n",
    "  <li><strong>Product</strong>: Did that new button placement increase checkout, or was it a seasonal effect?</li>\n",
    "  <li><strong>Marketing</strong>: Did the email nudge lead to purchases, or did loyal users open it anyway?</li>\n",
    "  <li><strong>Policy</strong>: Did a tax cut help the economy, or was it already improving?</li>\n",
    "  <li><strong>Health</strong>: Does a drug reduce disease, or do healthier people tend to take it?</li>\n",
    "</ul>\n",
    "\n",
    "<p>These questions involve <strong>interventions</strong>, and only causal methods can tell us what wouldâ€™ve happened under a different choice.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d999e6",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972fc15",
   "metadata": {},
   "source": [
    "<a id=\"notation-assumptions\"></a>\n",
    "# ğŸ§  Core Concepts & Notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb9997",
   "metadata": {},
   "source": [
    "<a id=\"treatment-outcome-units\"></a>\n",
    "#### ğŸ§® Treatment, Outcome, Units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7deb6",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Treatment (<code>T</code>)</strong>: The intervention or condition being tested (e.g., new design, drug, policy).</li>\n",
    "  <li><strong>Outcome (<code>Y</code>)</strong>: The result or metric affected by the treatment (e.g., click, recovery, score).</li>\n",
    "  <li><strong>Units (<code>i</code>)</strong>: The entities receiving treatment and producing outcomes (e.g., users, patients, schools).</li>\n",
    "</ul>\n",
    "\n",
    "<p>Each unit can receive a treatment or control, and we observe only one outcome â€” not both.</p>\n",
    "\n",
    "<p>This framing is universal and applies whether you're testing emails, ads, or vaccines.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e705a",
   "metadata": {},
   "source": [
    "<a id=\"potential-outcomes\"></a>\n",
    "#### ğŸ“ Potential Outcomes (Rubin Causal Model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1931ace",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<p>The <strong>Potential Outcomes framework</strong> (aka Rubin Causal Model) imagines two parallel worlds for each unit:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><code>Y(1)</code>: Outcome if treated</li>\n",
    "  <li><code>Y(0)</code>: Outcome if not treated</li>\n",
    "</ul>\n",
    "\n",
    "<p>We define <strong>Individual Treatment Effect (ITE)</strong> as:</p>\n",
    "\n",
    "<blockquote>ITE = Y(1) - Y(0)</blockquote>\n",
    "\n",
    "<p><strong>Key idea:</strong></p>\n",
    "\n",
    "<p>Each unit has both potential outcomes â€” but we can only observe one. The other is <strong>counterfactual</strong>.</p>\n",
    "\n",
    "<p>This framework allows us to define:</p>\n",
    "\n",
    "<ul>\n",
    "  <li>ATE (Average Treatment Effect)</li>\n",
    "  <li>CATE (Conditional ATE, for subgroups)</li>\n",
    "</ul>\n",
    "\n",
    "<p>And formalizes why causal inference is hard: we never see both outcomes.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d3fd",
   "metadata": {},
   "source": [
    "<a id=\"fundamental-problem\"></a>\n",
    "#### ğŸ§µ Fundamental Problem of Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f145ea",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<h5>The <strong>Fundamental Problem of Causal Inference</strong>:</h5>\n",
    "\n",
    "<blockquote>For any individual, we can observe only one potential outcome â€” never both.</blockquote>\n",
    "\n",
    "<p>Example:</p>\n",
    "<ul>\n",
    "  <li>A user sees version A â†’ you observe <code>Y(0)</code></li>\n",
    "  <li>Youâ€™ll never know what <code>Y(1)</code> would have been for that exact user</li>\n",
    "</ul>\n",
    "\n",
    "<p>This creates a missing data problem: the counterfactual is unobservable.</p>\n",
    "\n",
    "<p>To solve this, we rely on:</p>\n",
    "<ul>\n",
    "  <li><strong>Randomization</strong></li>\n",
    "  <li><strong>Modeling + assumptions</strong></li>\n",
    "  <li><strong>Matching or weighting approaches</strong></li>\n",
    "</ul>\n",
    "\n",
    "<p>All causal methods are, in some way, trying to <strong>approximate the missing counterfactual</strong>.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee05897",
   "metadata": {},
   "source": [
    "<a id=\"core-assumptions\"></a>\n",
    "#### ğŸ§  Assumptions (SUTVA, Ignorability, Overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed826353",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<p>Causal inference relies heavily on assumptions â€” even when you donâ€™t randomize.</p>\n",
    "\n",
    "<h5>Three core ones:</h5>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>SUTVA (Stable Unit Treatment Value Assumption)</strong><br>\n",
    "  â†’ Your treatment doesnâ€™t affect someone elseâ€™s outcome.<br>\n",
    "  â†’ No interference across units.</li>\n",
    "\n",
    "  <li><strong>Ignorability (a.k.a. Unconfoundedness)</strong><br>\n",
    "  â†’ Given the observed covariates, treatment assignment is as good as random.<br>\n",
    "  â†’ This lets you use observed data for estimation.</li>\n",
    "\n",
    "  <li><strong>Overlap (a.k.a. Positivity)</strong><br>\n",
    "  â†’ Every unit has a non-zero probability of receiving either treatment.<br>\n",
    "  â†’ You canâ€™t learn effects where thereâ€™s no variation.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Without these, causal estimates can be biased or undefined. Always question whether they hold before trusting results.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb1851",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361ddee",
   "metadata": {},
   "source": [
    "<a id=\"simulated-data\"></a>\n",
    "# ğŸ§ª Simulated Dataset Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1f238",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<p>Simulating data is the best way to <em>control the truth</em> when learning causal inference.</p>\n",
    "\n",
    "<p>Hereâ€™s why we simulate:</p>\n",
    "<ul>\n",
    "  <li>You get full knowledge of ground-truth treatment effects.</li>\n",
    "  <li>You can deliberately create <strong>confounding</strong>, <strong>bias</strong>, <strong>non-randomness</strong>.</li>\n",
    "  <li>You can practice recovering the true causal effect using different methods.</li>\n",
    "</ul>\n",
    "\n",
    "<p>In real-world observational data, the \"truth\" is hidden. Simulating lets you debug your causal intuition safely before dealing with messy production datasets.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cffe669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Dataset Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# We'll define features, treatment assignment, and outcomes step-by-step later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fe447",
   "metadata": {},
   "source": [
    "<a id=\"treatment-logic\"></a>\n",
    "#### ğŸ§¬ Define treatment assignment logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab191ac",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<p>To simulate treatment realistically:</p>\n",
    "<ul>\n",
    "  <li>Treatment should <strong>depend</strong> on observed features.</li>\n",
    "  <li>Treatment <strong>should not</strong> be random â€” otherwise, no confounding to deal with.</li>\n",
    "</ul>\n",
    "\n",
    "<p>For example:</p>\n",
    "<ul>\n",
    "  <li>Wealthier users might be more likely to receive a premium offer.</li>\n",
    "  <li>Healthier patients might be less likely to receive intensive care.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Weâ€™ll simulate a <strong>non-random treatment assignment</strong> based on a few covariates to mimic real-world biases.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541b4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define covariates (features)\n",
    "n = 5000\n",
    "\n",
    "age = np.random.normal(40, 12, n)       # Age\n",
    "income = np.random.normal(60000, 15000, n)  # Annual income\n",
    "prior_engagement = np.random.beta(2, 5, n)  # Past engagement score [0,1]\n",
    "\n",
    "# Treatment assignment probability based on features\n",
    "treatment_prob = (\n",
    "    0.3 * (income > 70000).astype(float) +\n",
    "    0.2 * (prior_engagement > 0.5).astype(float) +\n",
    "    0.1 * (age < 30).astype(float) +\n",
    "    np.random.normal(0, 0.05, n)  # small noise\n",
    ")\n",
    "treatment_prob = np.clip(treatment_prob, 0, 1)\n",
    "\n",
    "# Assign treatment\n",
    "T = np.random.binomial(1, treatment_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66180170",
   "metadata": {},
   "source": [
    "<a id=\"inject-confounding\"></a>\n",
    "#### ğŸ”¬ Inject confounding intentionally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6cc19a",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<p>In real-world datasets, treatment assignment is <strong>not random</strong> â€” itâ€™s confounded by covariates.</p>\n",
    "\n",
    "<p>We deliberately inject confounding so that:</p>\n",
    "<ul>\n",
    "  <li>Covariates (age, income, engagement) affect both <strong>treatment</strong> and <strong>outcome</strong>.</li>\n",
    "  <li>If we naively compare treated vs untreated, we'll get biased results.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Confounding creates the need for adjustment, which will be a major theme later.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5463b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a \"true\" baseline outcome based on the same covariates\n",
    "base_outcome = (\n",
    "    50 + \n",
    "    0.02 * income +\n",
    "    5 * prior_engagement -\n",
    "    0.3 * age +\n",
    "    np.random.normal(0, 5, n)  # random noise\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca43ff",
   "metadata": {},
   "source": [
    "<a id=\"simulate-outcomes\"></a>\n",
    "#### ğŸ§Š Simulate potential outcomes + observed data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4104ea8f",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<p>In the Rubin Potential Outcomes framework, each unit has two outcomes:</p>\n",
    "<ul>\n",
    "  <li><code>Y(1)</code> â†’ If treated</li>\n",
    "  <li><code>Y(0)</code> â†’ If not treated</li>\n",
    "</ul>\n",
    "\n",
    "<p>We can simulate this by:</p>\n",
    "<ul>\n",
    "  <li>Applying a <strong>true treatment effect</strong> to <code>Y(1)</code></li>\n",
    "  <li>Leaving <code>Y(0)</code> as the base outcome</li>\n",
    "</ul>\n",
    "\n",
    "<p><strong>Important:</strong> We observe only one of <code>Y(1)</code> or <code>Y(0)</code>, depending on treatment assignment (<code>T</code>).</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79ae0cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>prior_engagement</th>\n",
       "      <th>T</th>\n",
       "      <th>Y_obs</th>\n",
       "      <th>Y_0</th>\n",
       "      <th>Y_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.960570</td>\n",
       "      <td>53643.604770</td>\n",
       "      <td>0.188077</td>\n",
       "      <td>0</td>\n",
       "      <td>1114.502287</td>\n",
       "      <td>1114.502287</td>\n",
       "      <td>1124.502287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.340828</td>\n",
       "      <td>53198.788374</td>\n",
       "      <td>0.170389</td>\n",
       "      <td>0</td>\n",
       "      <td>1099.893323</td>\n",
       "      <td>1099.893323</td>\n",
       "      <td>1109.893323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47.772262</td>\n",
       "      <td>33065.352411</td>\n",
       "      <td>0.511379</td>\n",
       "      <td>0</td>\n",
       "      <td>704.133035</td>\n",
       "      <td>704.133035</td>\n",
       "      <td>714.133035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.276358</td>\n",
       "      <td>55048.647124</td>\n",
       "      <td>0.318793</td>\n",
       "      <td>0</td>\n",
       "      <td>1139.203509</td>\n",
       "      <td>1139.203509</td>\n",
       "      <td>1149.203509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.190160</td>\n",
       "      <td>70992.436227</td>\n",
       "      <td>0.384439</td>\n",
       "      <td>0</td>\n",
       "      <td>1464.308234</td>\n",
       "      <td>1464.308234</td>\n",
       "      <td>1474.308234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age        income  prior_engagement  T        Y_obs          Y_0  \\\n",
       "0  45.960570  53643.604770          0.188077  0  1114.502287  1114.502287   \n",
       "1  38.340828  53198.788374          0.170389  0  1099.893323  1099.893323   \n",
       "2  47.772262  33065.352411          0.511379  0   704.133035   704.133035   \n",
       "3  58.276358  55048.647124          0.318793  0  1139.203509  1139.203509   \n",
       "4  37.190160  70992.436227          0.384439  0  1464.308234  1464.308234   \n",
       "\n",
       "           Y_1  \n",
       "0  1124.502287  \n",
       "1  1109.893323  \n",
       "2   714.133035  \n",
       "3  1149.203509  \n",
       "4  1474.308234  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a true treatment effect (could vary by subgroup later)\n",
    "true_treatment_effect = 10  # a flat +10 effect for everyone\n",
    "\n",
    "# Simulate potential outcomes\n",
    "Y_0 = base_outcome\n",
    "Y_1 = base_outcome + true_treatment_effect\n",
    "\n",
    "# Observed outcome based on treatment assignment\n",
    "Y_obs = T * Y_1 + (1 - T) * Y_0\n",
    "\n",
    "# Assemble into a dataframe\n",
    "df = pd.DataFrame({\n",
    "    'age': age,\n",
    "    'income': income,\n",
    "    'prior_engagement': prior_engagement,\n",
    "    'T': T,\n",
    "    'Y_obs': Y_obs,\n",
    "    'Y_0': Y_0,\n",
    "    'Y_1': Y_1,\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49e27e",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dde548",
   "metadata": {},
   "source": [
    "<a id=\"naive-estimation\"></a>\n",
    "# ğŸš« Naive Estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4860605",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<p>Many causal questions are first attacked by simply comparing the treated vs. untreated groups.</p>\n",
    "\n",
    "<p><strong>Naive Approach:</strong></p>\n",
    "<blockquote>Average outcome of treated - Average outcome of untreated.</blockquote>\n",
    "\n",
    "<p>This looks simple, but in observational data:</p>\n",
    "<ul>\n",
    "  <li>Treated and untreated units <strong>are not comparable</strong>.</li>\n",
    "  <li>Treatment assignment was <strong>not randomized</strong>.</li>\n",
    "  <li>Differences in baseline characteristics confound the simple difference.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Naive estimation <strong>almost always gives biased results</strong> unless you have perfect randomization.</p>\n",
    "\n",
    "<p>In this section, we'll see how bad the naive approach can get even on a simple synthetic dataset.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2c08e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive difference in means: 250.53\n",
      "True treatment effect (ground truth): 10\n"
     ]
    }
   ],
   "source": [
    "# Quick naive estimation\n",
    "treated_mean = df.loc[df['T'] == 1, 'Y_obs'].mean()\n",
    "control_mean = df.loc[df['T'] == 0, 'Y_obs'].mean()\n",
    "\n",
    "naive_diff = treated_mean - control_mean\n",
    "\n",
    "print(f\"Naive difference in means: {naive_diff:.2f}\")\n",
    "print(f\"True treatment effect (ground truth): {true_treatment_effect}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc35de",
   "metadata": {},
   "source": [
    "<a id=\"diff-in-means\"></a>\n",
    "#### âŒ Simple difference in means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e83c050",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<p>A simple difference in means is mathematically:</p>\n",
    "<blockquote><code>E[Y | T=1] - E[Y | T=0]</code></blockquote>\n",
    "\n",
    "<p>If treatment assignment were random:</p>\n",
    "<ul>\n",
    "  <li>The two groups would be exchangeable.</li>\n",
    "  <li>Baseline covariates would balance on average.</li>\n",
    "  <li>The simple difference would be an unbiased estimator of ATE.</li>\n",
    "</ul>\n",
    "\n",
    "<p>But if treatment is <strong>confounded</strong>, then:</p>\n",
    "<ul>\n",
    "  <li><code>T=1</code> units may systematically differ from <code>T=0</code> units.</li>\n",
    "  <li>The naive estimator picks up both <strong>causal effect</strong> and <strong>selection bias</strong>.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Weâ€™ll soon quantify how large this bias can be.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ccff6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>prior_engagement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.389926</td>\n",
       "      <td>58304.201745</td>\n",
       "      <td>0.278891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.892227</td>\n",
       "      <td>70283.224987</td>\n",
       "      <td>0.330779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         age        income  prior_engagement\n",
       "T                                           \n",
       "0  40.389926  58304.201745          0.278891\n",
       "1  37.892227  70283.224987          0.330779"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's quickly visualize how the treated vs control groups differ in covariates\n",
    "df.groupby('T')[['age', 'income', 'prior_engagement']].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c7490",
   "metadata": {},
   "source": [
    "<a id=\"bias-confounding\"></a>\n",
    "#### âš ï¸ Bias due to confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d8ecd",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "<p><strong>Bias from confounding</strong> happens when:</p>\n",
    "<ul>\n",
    "  <li>The treated group has systematically different baseline outcomes than the control group.</li>\n",
    "</ul>\n",
    "\n",
    "<p>Mathematically:</p>\n",
    "<blockquote>Observed difference = True treatment effect + Bias from baseline differences</blockquote>\n",
    "\n",
    "<p>In our simulation:</p>\n",
    "<ul>\n",
    "  <li>Higher income users are more likely to be treated.</li>\n",
    "  <li>Income also directly influences outcome.</li>\n",
    "  <li>Therefore, the observed difference <strong>overstates</strong> the real effect.</li>\n",
    "</ul>\n",
    "\n",
    "<p>This is why adjusting for confounders is critical â€” naive methods can easily mislead interventions and business decisions.</p>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cff38189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (Y_0) difference between treated and control: 240.53\n",
      "This baseline imbalance creates bias in naive estimation.\n"
     ]
    }
   ],
   "source": [
    "# Let's calculate the *average baseline outcome* (Y_0) in treated vs untreated groups\n",
    "treated_baseline = df.loc[df['T'] == 1, 'Y_0'].mean()\n",
    "control_baseline = df.loc[df['T'] == 0, 'Y_0'].mean()\n",
    "\n",
    "baseline_diff = treated_baseline - control_baseline\n",
    "\n",
    "print(f\"Baseline (Y_0) difference between treated and control: {baseline_diff:.2f}\")\n",
    "print(\"This baseline imbalance creates bias in naive estimation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2f4dd",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaffce9",
   "metadata": {},
   "source": [
    "<a id=\"causal-diagrams\"></a>\n",
    "# ğŸ•¸ï¸ Causal Diagrams (DAGs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84191e2",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "**Directed Acyclic Graphs (DAGs)** are a compact way to represent assumptions about the data generating process.\n",
    "\n",
    "- Nodes = variables\n",
    "- Edges (arrows) = direct causal influence\n",
    "\n",
    "DAGs are not learned from data. They are **drawn from domain knowledge** to help reason about:\n",
    "- Confounders\n",
    "- Biases\n",
    "- Valid adjustment strategies\n",
    "\n",
    "Almost every causal inference method implicitly or explicitly assumes a DAG about the world.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b06f1",
   "metadata": {},
   "source": [
    "<a id=\"primer-dags\"></a>\n",
    "#### ğŸ§¿ Quick primer on DAGs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66cfd3e",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "A **DAG (Directed Acyclic Graph)** encodes assumptions about how variables causally relate.\n",
    "\n",
    "- **Directed**: Arrows have direction (cause â†’ effect).\n",
    "- **Acyclic**: No feedback loops allowed (you canâ€™t return to a node).\n",
    "\n",
    "Example:\n",
    "> Age â†’ Income â†’ Health\n",
    "\n",
    "Means:\n",
    "- Age affects income.\n",
    "- Income affects health.\n",
    "- No reverse paths.\n",
    "\n",
    "DAGs help identify:\n",
    "- Which paths are confounded\n",
    "- Which variables to control for\n",
    "- Whether effects are identifiable\n",
    "\n",
    "They act like a **map** â€” letting you plan causal estimation strategies intelligently.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a48aa4",
   "metadata": {},
   "source": [
    "<a id=\"confounder-collider-mediator\"></a>\n",
    "#### ğŸ•·ï¸ Confounding vs. colliders vs. mediators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cccea1",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "**Confounders**:\n",
    "- Variables that influence both treatment and outcome.\n",
    "- Must be adjusted for to block bias.\n",
    "- Example: Age confounds the relationship between Exercise (T) and Health (Y).\n",
    "\n",
    "**Colliders**:\n",
    "- Variables caused by two other variables.\n",
    "- **Must NOT adjust for colliders** â€” doing so opens spurious associations.\n",
    "- Example: Adjusting for \"hospitalization\" might introduce bias when studying Smoking â†’ Lung Disease.\n",
    "\n",
    "**Mediators**:\n",
    "- Variables on the causal pathway between treatment and outcome.\n",
    "- Adjusting for them **blocks part of the causal effect** you want to measure.\n",
    "- Example: Exercise â†’ Fitness â†’ Health (fitness is a mediator).\n",
    "\n",
    "ğŸ‘‰ Correct adjustment requires distinguishing among these roles.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5353f4",
   "metadata": {},
   "source": [
    "<a id=\"estimability-from-dags\"></a>\n",
    "#### ğŸ”— What can/canâ€™t be estimated just from data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3355a",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Not everything is identifiable from data alone â€” assumptions are unavoidable.\n",
    "\n",
    "**What can be estimated**:\n",
    "- Associations (correlations, patterns)\n",
    "- Conditional independence structures\n",
    "- Causal effects **if** the right covariates are controlled (based on DAG structure)\n",
    "\n",
    "**What cannot be estimated**:\n",
    "- Whether a relationship is causal (without assumptions)\n",
    "- The full structure of a DAG (unless randomized experiments are used)\n",
    "\n",
    "Data + assumptions â†’ Causal conclusions.  \n",
    "Data alone â†’ Only correlational findings.\n",
    "\n",
    "DAGs clarify where you need domain knowledge vs where data suffices.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6b2de",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef463393",
   "metadata": {},
   "source": [
    "<a id=\"backdoor-adjustment\"></a>\n",
    "# ğŸ” Backdoor Adjustment Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7450c130",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Backdoor adjustment methods aim to block **backdoor paths** â€” non-causal paths that create bias between treatment and outcome.\n",
    "\n",
    "**Core idea**:\n",
    "- Identify variables (confounders) that open backdoor paths.\n",
    "- Condition on them â€” either by stratifying, modeling, or matching.\n",
    "\n",
    "Backdoor adjustment **simulates** what would happen if treatment assignment were random within levels of the confounders.\n",
    "\n",
    "Itâ€™s the foundational idea behind:\n",
    "- Regression\n",
    "- Matching\n",
    "- Stratification\n",
    "- Propensity scores\n",
    "\n",
    "If you can block all backdoor paths, you can estimate causal effects from observational data reliably.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7760664",
   "metadata": {},
   "source": [
    "<a id=\"conditioning\"></a>\n",
    "#### ğŸ§¾ Conditioning on confounders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1f903",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Conditioning means **holding confounders constant** when comparing treated vs untreated units.\n",
    "\n",
    "Examples:\n",
    "- Comparing treated vs untreated users **within each income band**.\n",
    "- Comparing recovery rates **within each age group**.\n",
    "\n",
    "By conditioning, you eliminate the variation due to confounders, isolating the causal effect.\n",
    "\n",
    "**Important:**  \n",
    "You should only condition on true confounders â€” not colliders or mediators.\n",
    "\n",
    "Conditioning can be implemented via:\n",
    "- Subgrouping\n",
    "- Regression\n",
    "- Matching\n",
    "- Weighting\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74217e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Conditional Difference by Income Group:\n",
      "T                 diff\n",
      "high_income           \n",
      "0            16.867043\n",
      "1            13.563878\n"
     ]
    }
   ],
   "source": [
    "# Simple conditioning by subgroup (example: income > 70k vs <= 70k)\n",
    "df['high_income'] = (df['income'] > 70000).astype(int)\n",
    "\n",
    "grouped = df.groupby(['high_income', 'T'])['Y_obs'].mean().unstack()\n",
    "grouped['diff'] = grouped[1] - grouped[0]\n",
    "\n",
    "print(\"Simple Conditional Difference by Income Group:\")\n",
    "print(grouped[['diff']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e16492",
   "metadata": {},
   "source": [
    "<a id=\"stratification\"></a>\n",
    "#### ğŸ•µï¸â€â™‚ï¸ Stratification / Subgroup analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93353a4f",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Stratification means **breaking the dataset into buckets** based on confounders and comparing treatment effects within each bucket.\n",
    "\n",
    "Typical steps:\n",
    "1. Divide data based on a confounder (e.g., low vs high engagement).\n",
    "2. Within each stratum, compute treated vs control differences.\n",
    "3. Aggregate across strata (weighted average).\n",
    "\n",
    "**When useful:**\n",
    "- When confounders are categorical or easily discretized.\n",
    "- When interpretability is important.\n",
    "\n",
    "**Limits:**\n",
    "- Doesnâ€™t scale well with many confounders (curse of dimensionality).\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66d78e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Difference by Engagement Group:\n",
      "T                      diff\n",
      "high_engagement            \n",
      "0                290.043114\n",
      "1                145.885304\n"
     ]
    }
   ],
   "source": [
    "# Stratify based on prior_engagement (simple high vs low)\n",
    "df['high_engagement'] = (df['prior_engagement'] > 0.5).astype(int)\n",
    "\n",
    "strat_grouped = df.groupby(['high_engagement', 'T'])['Y_obs'].mean().unstack()\n",
    "strat_grouped['diff'] = strat_grouped[1] - strat_grouped[0]\n",
    "\n",
    "print(\"Conditional Difference by Engagement Group:\")\n",
    "print(strat_grouped[['diff']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00bc7ca",
   "metadata": {},
   "source": [
    "<a id=\"regression-adjustment\"></a>\n",
    "#### ğŸ“Š Regression Adjustment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6549d05",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Regression adjustment estimates causal effects by **controlling for confounders via regression**.\n",
    "\n",
    "Simple linear model:\n",
    "> `Y = Î²â‚€ + Î²â‚Â·T + Î²â‚‚Â·(confounder1) + Î²â‚ƒÂ·(confounder2) + ... + Îµ`\n",
    "\n",
    "- `Î²â‚` captures the **adjusted** effect of treatment, controlling for confounders.\n",
    "- It removes bias from observable confounders (under correct model specification).\n",
    "\n",
    "**Advantages:**\n",
    "- Easy to use.\n",
    "- Scales to many covariates.\n",
    "\n",
    "**Risks:**\n",
    "- Sensitive to model misspecification.\n",
    "- Wrong functional forms (nonlinearities, interactions) can bias estimates.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a2f4b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Y_obs   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 4.652e+06\n",
      "Date:                Sat, 26 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        17:22:58   Log-Likelihood:                -15122.\n",
      "No. Observations:                5000   AIC:                         3.025e+04\n",
      "Df Residuals:                    4995   BIC:                         3.029e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const               50.3660      0.398    126.398      0.000      49.585      51.147\n",
      "T                   10.0641      0.220     45.761      0.000       9.633      10.495\n",
      "age                 -0.2942      0.006    -49.784      0.000      -0.306      -0.283\n",
      "income               0.0200   4.83e-06   4142.593      0.000       0.020       0.020\n",
      "prior_engagement     4.3802      0.452      9.681      0.000       3.493       5.267\n",
      "==============================================================================\n",
      "Omnibus:                        5.657   Durbin-Watson:                   1.967\n",
      "Prob(Omnibus):                  0.059   Jarque-Bera (JB):                5.136\n",
      "Skew:                          -0.029   Prob(JB):                       0.0767\n",
      "Kurtosis:                       2.854   Cond. No.                     4.38e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.38e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Estimated treatment effect (Î²â‚) after adjustment: 10.06\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = df[['T', 'age', 'income', 'prior_engagement']]\n",
    "X = sm.add_constant(X)\n",
    "y = df['Y_obs']\n",
    "\n",
    "reg_model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(reg_model.summary())\n",
    "\n",
    "print(f\"\\nEstimated treatment effect (Î²â‚) after adjustment: {reg_model.params['T']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5906e36",
   "metadata": {},
   "source": [
    "<a id=\"psm\"></a>\n",
    "#### ğŸ“Œ Propensity Score Matching (PSM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f267aa",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Propensity Score Matching (PSM) is a two-step procedure:\n",
    "1. Model the **probability of receiving treatment** (`P(T=1 | X)`) using observed covariates.\n",
    "2. Match treated and control units with **similar propensity scores**.\n",
    "\n",
    "**Why PSM?**\n",
    "- Instead of adjusting for many covariates separately, you balance treated and control groups on a single dimension (the propensity score).\n",
    "\n",
    "**When useful:**\n",
    "- When covariate space is high-dimensional.\n",
    "- When you want a matched sample that resembles randomized data.\n",
    "\n",
    "**Limitations:**\n",
    "- Requires good overlap (common support).\n",
    "- Still relies on unconfoundedness assumption.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e0ce90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propensity Score Matched Estimate of Treatment Effect: 197.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Step 1: Estimate propensity scores\n",
    "ps_model = LogisticRegression()\n",
    "ps_model.fit(df[['age', 'income', 'prior_engagement']], df['T'])\n",
    "df['propensity_score'] = ps_model.predict_proba(df[['age', 'income', 'prior_engagement']])[:,1]\n",
    "\n",
    "# Step 2: Nearest neighbor matching\n",
    "treated = df[df['T'] == 1]\n",
    "control = df[df['T'] == 0]\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=1)\n",
    "nn.fit(control[['propensity_score']])\n",
    "\n",
    "distances, indices = nn.kneighbors(treated[['propensity_score']])\n",
    "matched_control = control.iloc[indices.flatten()]\n",
    "\n",
    "# Calculate matched difference\n",
    "matched_diff = (treated['Y_obs'].values - matched_control['Y_obs'].values).mean()\n",
    "\n",
    "print(f\"Propensity Score Matched Estimate of Treatment Effect: {matched_diff:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b259b1",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229aa095",
   "metadata": {},
   "source": [
    "<a id=\"iv-methods\"></a>\n",
    "# ğŸ¯ Instrumental Variables (IV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416579ed",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Instrumental Variables (IV) methods are used **when simple adjustment for confounders is impossible** or **not credible**.\n",
    "\n",
    "When treatment is **endogenous** (affected by unobserved factors also affecting outcome), traditional methods like regression fail.\n",
    "\n",
    "**IV solves this by:**\n",
    "- Using a \"proxy\" (instrument) that affects treatment but is otherwise unrelated to the outcome except through treatment.\n",
    "- \"Re-randomizing\" variation in treatment based on the instrument.\n",
    "\n",
    "You create **quasi-randomization** even in observational data.\n",
    "\n",
    "Classic examples:\n",
    "- Distance to hospital â†’ instrument for getting surgery.\n",
    "- Random assignment of judges â†’ instrument for harsher sentencing.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b63f1d",
   "metadata": {},
   "source": [
    "<a id=\"when-use-iv\"></a>\n",
    "#### ğŸª When backdoor paths canâ€™t be blocked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71bc02",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "You need IV methods when:\n",
    "- There are **unobserved confounders** you canâ€™t measure.\n",
    "- No set of observed covariates satisfies ignorability.\n",
    "- Standard backdoor adjustment will be biased.\n",
    "\n",
    "Example:\n",
    "- Studying the effect of education on income: natural intelligence is a hidden confounder (affects both education and income).\n",
    "- You can't just regress income ~ education â€” bias remains.\n",
    "\n",
    "**Key realization:**\n",
    "If **backdoor paths exist** through unobserved variables, IV becomes necessary.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0322fe",
   "metadata": {},
   "source": [
    "<a id=\"iv-conditions\"></a>\n",
    "#### ğŸ¯ Valid instrument conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe6d3a",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "For an instrument (`Z`) to be valid, it must satisfy:\n",
    "\n",
    "1. **Relevance**:  \n",
    "   - `Z` must affect treatment `T`.  \n",
    "   (There must be a first-stage effect.)\n",
    "\n",
    "2. **Exclusion Restriction**:  \n",
    "   - `Z` must affect the outcome `Y` **only** through `T`.  \n",
    "   (No direct path from `Z` to `Y`.)\n",
    "\n",
    "3. **Independence (As-if Randomness)**:  \n",
    "   - `Z` must be independent of unobserved confounders affecting `Y`.\n",
    "\n",
    "---\n",
    "\n",
    "If any of these fail:\n",
    "- IV estimates are biased or meaningless.\n",
    "- You canâ€™t fix bad instruments with bigger sample sizes.\n",
    "\n",
    "**Choosing or arguing a valid instrument is 90% of the IV battle.**\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fff624",
   "metadata": {},
   "source": [
    "<a id=\"2sls\"></a>\n",
    "#### ğŸ§© 2-Stage Least Squares (2SLS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091cb2e9",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "**2SLS (Two-Stage Least Squares)** is the classic estimation procedure for IV:\n",
    "\n",
    "- **Stage 1**:  \n",
    "  Regress treatment `T` on instrument `Z` (and any controls)  \n",
    "  â†’ get predicted treatment (`TÌ‚`)\n",
    "\n",
    "- **Stage 2**:  \n",
    "  Regress outcome `Y` on predicted treatment (`TÌ‚`)\n",
    "\n",
    "The second-stage coefficient gives the **causal effect** of treatment on outcome, isolating variation driven by the instrument.\n",
    "\n",
    "**Warning:**  \n",
    "- Standard regression software doesn't correct standard errors properly when doing 2SLS manually.  \n",
    "- Later packages like `linearmodels` automate this.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd70c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  Y_obs   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 3.278e+06\n",
      "Date:                Sat, 26 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        17:24:24   Log-Likelihood:                -15996.\n",
      "No. Observations:                5000   AIC:                         3.200e+04\n",
      "Df Residuals:                    4995   BIC:                         3.203e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const               48.1296      0.474    101.498      0.000      47.200      49.059\n",
      "T_hat                0.2548      0.197      1.296      0.195      -0.131       0.640\n",
      "age                 -0.3133      0.007    -44.628      0.000      -0.327      -0.300\n",
      "income               0.0201   5.54e-06   3619.407      0.000       0.020       0.020\n",
      "prior_engagement     6.6954      0.540     12.391      0.000       5.636       7.755\n",
      "==============================================================================\n",
      "Omnibus:                       71.333   Durbin-Watson:                   1.970\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               74.381\n",
      "Skew:                           0.287   Prob(JB):                     7.05e-17\n",
      "Kurtosis:                       3.169   Cond. No.                     4.33e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.33e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Estimated causal effect (via 2SLS): 0.25\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "# Simulate an instrument Z (let's assume it's random and satisfies conditions)\n",
    "np.random.seed(42)\n",
    "df['Z'] = np.random.binomial(1, 0.5, size=len(df))\n",
    "\n",
    "# Make treatment depend partly on Z\n",
    "df['T_iv'] = (0.5 * df['Z'] + 0.5 * df['prior_engagement'] + np.random.normal(0, 0.1, len(df))) > 0.5\n",
    "df['T_iv'] = df['T_iv'].astype(int)\n",
    "\n",
    "# Stage 1: Predict treatment from instrument\n",
    "X_stage1 = add_constant(df[['Z', 'age', 'income', 'prior_engagement']])\n",
    "stage1_model = OLS(df['T_iv'], X_stage1).fit()\n",
    "df['T_hat'] = stage1_model.predict(X_stage1)\n",
    "\n",
    "# Stage 2: Predict outcome from predicted treatment\n",
    "X_stage2 = add_constant(df[['T_hat', 'age', 'income', 'prior_engagement']])\n",
    "stage2_model = OLS(df['Y_obs'], X_stage2).fit()\n",
    "\n",
    "print(stage2_model.summary())\n",
    "\n",
    "print(f\"\\nEstimated causal effect (via 2SLS): {stage2_model.params['T_hat']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1dff19",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff962ca0",
   "metadata": {},
   "source": [
    "<a id=\"dml-methods\"></a>\n",
    "# ğŸ§° Double Machine Learning (DML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bddef79",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Double Machine Learning (DML) is a modern causal estimation technique that:\n",
    "\n",
    "- **Separates** the modeling of treatment and outcome.\n",
    "- **Uses flexible machine learning models** to control for complex confounders.\n",
    "- **Debiases** the final treatment effect estimation by orthogonalization.\n",
    "\n",
    "**Why DML matters:**\n",
    "- Traditional linear regression forces linearity.\n",
    "- DML allows for nonlinear, high-dimensional adjustment without overfitting causal estimates.\n",
    "\n",
    "It builds robust treatment effect estimators even when you use ML methods like Random Forests, XGBoost, or Neural Nets for intermediate steps.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9754c",
   "metadata": {},
   "source": [
    "<a id=\"ml-nuisance\"></a>\n",
    "#### ğŸª› Use ML models for nuisance functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5116cb2",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "In DML, you model two \"nuisance functions\" first:\n",
    "1. **Outcome model**: `Y ~ X`\n",
    "2. **Treatment model**: `T ~ X`\n",
    "\n",
    "You can use **any ML model** (linear regression, random forest, gradient boosting, etc.) for these.\n",
    "\n",
    "**Key point:**  \n",
    "The goal is **accurate prediction**, not causal interpretation, at this stage.\n",
    "\n",
    "Later, DML uses the residuals from these models to isolate the causal effect of `T` on `Y`.\n",
    "\n",
    "This two-step process protects the final estimate from overfitting to noisy high-dimensional features.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e237a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features\n",
    "features = ['age', 'income', 'prior_engagement']\n",
    "\n",
    "# Split into train/test for honest estimation\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df['Y_obs'], test_size=0.3, random_state=42)\n",
    "T_train, T_test = train_test_split(df['T'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Outcome model: Y ~ X\n",
    "y_model = RandomForestRegressor()\n",
    "y_model.fit(X_train, y_train)\n",
    "df['y_hat'] = y_model.predict(df[features])\n",
    "\n",
    "# Treatment model: T ~ X\n",
    "t_model = RandomForestRegressor()\n",
    "t_model.fit(X_train, T_train)\n",
    "df['t_hat'] = t_model.predict(df[features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000b403",
   "metadata": {},
   "source": [
    "<a id=\"residualization\"></a>\n",
    "#### ğŸ§± Residualization + orthogonalization logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77758e",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "After fitting nuisance models:\n",
    "\n",
    "- Calculate **residuals**:\n",
    "  - `Residual_Y = Y - YÌ‚`\n",
    "  - `Residual_T = T - TÌ‚`\n",
    "\n",
    "- Then regress **Residual_Y ~ Residual_T**.\n",
    "\n",
    "Why?\n",
    "- This removes the part of `Y` and `T` that is predictable from `X`.\n",
    "- What remains captures the **\"clean\" causal variation** of `T` on `Y`, orthogonal to confounders.\n",
    "\n",
    "This two-stage process is called **orthogonalization** â€” it minimizes bias from overfitting nuisance functions.\n",
    "\n",
    "Itâ€™s a key innovation that separates DML from naive ML-based adjustment.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df536cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             residual_Y   R-squared:                       0.127\n",
      "Model:                            OLS   Adj. R-squared:                  0.127\n",
      "Method:                 Least Squares   F-statistic:                     726.5\n",
      "Date:                Sat, 26 Apr 2025   Prob (F-statistic):          1.62e-149\n",
      "Time:                        17:25:33   Log-Likelihood:                -14928.\n",
      "No. Observations:                5000   AIC:                         2.986e+04\n",
      "Df Residuals:                    4998   BIC:                         2.987e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0842      0.068      1.243      0.214      -0.049       0.217\n",
      "residual_T     8.9188      0.331     26.953      0.000       8.270       9.567\n",
      "==============================================================================\n",
      "Omnibus:                     7090.850   Durbin-Watson:                   1.998\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          9991352.741\n",
      "Skew:                           7.694   Prob(JB):                         0.00\n",
      "Kurtosis:                     221.453   Cond. No.                         4.88\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Estimated causal effect via DML: 8.92\n"
     ]
    }
   ],
   "source": [
    "# Calculate residuals\n",
    "df['residual_Y'] = df['Y_obs'] - df['y_hat']\n",
    "df['residual_T'] = df['T'] - df['t_hat']\n",
    "\n",
    "# Final stage: regress residual_Y ~ residual_T\n",
    "X_resid = sm.add_constant(df['residual_T'])\n",
    "y_resid = df['residual_Y']\n",
    "\n",
    "residual_model = sm.OLS(y_resid, X_resid).fit()\n",
    "\n",
    "print(residual_model.summary())\n",
    "\n",
    "print(f\"\\nEstimated causal effect via DML: {residual_model.params['residual_T']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd36b53",
   "metadata": {},
   "source": [
    "<a id=\"dml-vs-regression\"></a>\n",
    "#### ğŸ§² When to prefer over traditional regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fde7c45",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "You should prefer DML over traditional regression when:\n",
    "\n",
    "- **High-dimensional confounders** (lots of features) exist.\n",
    "- **Nonlinear relationships** are likely between covariates and treatment/outcome.\n",
    "- **Flexible modeling** is important (tree-based, neural nets, etc.)\n",
    "- **Concern about model misspecification** in simple linear regression.\n",
    "\n",
    "Traditional regression assumes:\n",
    "- Linear relationships\n",
    "- No complex interactions unless explicitly modeled\n",
    "\n",
    "DML frees you from strict parametric forms, allowing modern ML models while still aiming for valid causal estimates.\n",
    "\n",
    "âœ… DML shines in modern settings: tech products, healthcare, online platforms â€” where datasets are messy, rich, and big.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14a213",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15edb2",
   "metadata": {},
   "source": [
    "<a id=\"heterogeneous-effects\"></a>\n",
    "# ğŸŒˆ Heterogeneous Treatment Effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb6bb3",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Until now, we've talked about the **average** effect of treatment across the entire population (ATE).\n",
    "\n",
    "But in reality:\n",
    "- Different users respond differently.\n",
    "- Treatment effects **vary** by user characteristics.\n",
    "\n",
    "**Heterogeneous Treatment Effects** (HTE) study how effects vary:\n",
    "- Across groups (e.g., high engagement vs low engagement)\n",
    "- Across individuals (personalized effects)\n",
    "\n",
    "Estimating HTE is critical for:\n",
    "- Personalized recommendations\n",
    "- Smart targeting (marketing, healthcare, product launches)\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ad0cd",
   "metadata": {},
   "source": [
    "<a id=\"ate-cate-ite\"></a>\n",
    "#### ğŸ¨ ATE vs. CATE vs. ITE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba90ea5",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Different layers of treatment effect granularity:\n",
    "\n",
    "- **ATE (Average Treatment Effect)**:  \n",
    "  - Average effect across everyone.\n",
    "\n",
    "- **CATE (Conditional Average Treatment Effect)**:  \n",
    "  - Average effect **given some subgroup** (e.g., CATE for users <30 years old).\n",
    "\n",
    "- **ITE (Individual Treatment Effect)**:  \n",
    "  - Effect for a **specific user**.\n",
    "\n",
    "---\n",
    "\n",
    "**In practice:**\n",
    "- ATE is easiest to estimate.\n",
    "- CATEs are often actionable (targeted marketing).\n",
    "- ITEs are the hardest â€” noisy and high-variance.\n",
    "\n",
    "Good causal inference methods can recover CATEs/ITEs **if** enough data and signal exist.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1385a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True ATE: 10.00\n",
      "CATE for high engagement users: 10.00\n",
      "\n",
      "Sample ITEs:\n",
      "         age        income  prior_engagement  ITE_true\n",
      "0  45.960570  53643.604770          0.188077      10.0\n",
      "1  38.340828  53198.788374          0.170389      10.0\n",
      "2  47.772262  33065.352411          0.511379      10.0\n",
      "3  58.276358  55048.647124          0.318793      10.0\n",
      "4  37.190160  70992.436227          0.384439      10.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate ATE (simple diff from simulation ground truth)\n",
    "ate = (df['Y_1'] - df['Y_0']).mean()\n",
    "print(f\"True ATE: {ate:.2f}\")\n",
    "\n",
    "# Calculate CATE for high engagement group\n",
    "cate_high_engagement = (df[df['prior_engagement'] > 0.5]['Y_1'] - df[df['prior_engagement'] > 0.5]['Y_0']).mean()\n",
    "print(f\"CATE for high engagement users: {cate_high_engagement:.2f}\")\n",
    "\n",
    "# Show a few ITEs\n",
    "df['ITE_true'] = df['Y_1'] - df['Y_0']\n",
    "print(\"\\nSample ITEs:\")\n",
    "print(df[['age', 'income', 'prior_engagement', 'ITE_true']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26833b",
   "metadata": {},
   "source": [
    "<a id=\"uplift-usecases\"></a>\n",
    "#### ğŸŒŸ Uplift models and use cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565df4a8",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "**Uplift modeling** directly models the **difference in probability** of a positive outcome between treated and untreated users.\n",
    "\n",
    "Instead of modeling outcome probabilities separately, uplift models focus on:\n",
    "- Who is **most persuadable**?\n",
    "- Who would change behavior because of treatment?\n",
    "\n",
    "**Where uplift models shine:**\n",
    "- Marketing campaigns (maximize conversions per dollar)\n",
    "- Customer retention (target save offers only to those who would churn)\n",
    "- Medical interventions (target high-risk patients)\n",
    "\n",
    "---\n",
    "\n",
    "**Typical techniques:**\n",
    "- Uplift Decision Trees\n",
    "- Two-model approach (predict Y|T=1 and Y|T=0 separately, then subtract)\n",
    "- Causal Forests\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5969183",
   "metadata": {},
   "source": [
    "<a id=\"causal-forests\"></a>\n",
    "#### ğŸ§© Tree-based methods (Causal Trees, Causal Forests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909a7811",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Tree-based methods are powerful for discovering treatment effect heterogeneity:\n",
    "\n",
    "- **Causal Trees**:\n",
    "  - Split data to maximize treatment effect differences between branches.\n",
    "  - One tree trained specifically for causal splits.\n",
    "\n",
    "- **Causal Forests**:\n",
    "  - Ensemble of causal trees.\n",
    "  - Averages treatment effect estimates across trees.\n",
    "  - Reduces variance compared to a single tree.\n",
    "\n",
    "They can estimate **CATEs** reliably across different subgroups without manually specifying interactions.\n",
    "\n",
    "---\n",
    "\n",
    "**When useful:**\n",
    "- You expect heterogeneity but don't know in advance how to segment.\n",
    "- You want flexible, interpretable treatment effect estimation.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2a80046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting econml\n",
      "  Downloading econml-0.15.1-cp311-cp311-macosx_11_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.24.3)\n",
      "Requirement already satisfied: scipy>1.4.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn<1.6,>=1.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.2.2)\n",
      "Collecting sparse (from econml)\n",
      "  Downloading sparse-0.16.0-py2.py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.10 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (0.13.5)\n",
      "Requirement already satisfied: pandas>1.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (1.5.3)\n",
      "Collecting shap<0.44.0,>=0.38.1 (from econml)\n",
      "  Downloading shap-0.43.0-cp311-cp311-macosx_11_0_arm64.whl (445 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m445.4/445.4 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lightgbm in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (4.3.0)\n",
      "Requirement already satisfied: packaging in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from econml) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from pandas>1.0->econml) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from pandas>1.0->econml) (2022.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from scikit-learn<1.6,>=1.0->econml) (2.2.0)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (4.65.0)\n",
      "Collecting slicer==0.0.7 (from shap<0.44.0,>=0.38.1->econml)\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numba in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (0.57.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from shap<0.44.0,>=0.38.1->econml) (2.2.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.10->econml) (0.5.3)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from numba->shap<0.44.0,>=0.38.1->econml) (0.40.0)\n",
      "Requirement already satisfied: six in /Users/ashrithreddy/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.2->statsmodels>=0.10->econml) (1.16.0)\n",
      "Installing collected packages: slicer, sparse, shap, econml\n",
      "Successfully installed econml-0.15.1 shap-0.43.0 slicer-0.0.7 sparse-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd33d108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample predicted CATEs:\n",
      "         age        income  prior_engagement  CATE_predicted\n",
      "0  45.960570  53643.604770          0.188077       15.767683\n",
      "1  38.340828  53198.788374          0.170389       18.062330\n",
      "2  47.772262  33065.352411          0.511379       -4.625701\n",
      "3  58.276358  55048.647124          0.318793       14.400047\n",
      "4  37.190160  70992.436227          0.384439       11.047467\n"
     ]
    }
   ],
   "source": [
    "# Causal Forest: Full Correct Code\n",
    "\n",
    "from econml.grf import CausalForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features and outcome\n",
    "X = df[['age', 'income', 'prior_engagement']].values  # Features (2D)\n",
    "T = df['T'].values  # Treatment (1D)\n",
    "Y = df['Y_obs'].values  # Observed outcome (1D)\n",
    "\n",
    "# Fit causal forest\n",
    "forest = CausalForest(n_estimators=100, random_state=42)\n",
    "forest.fit(X, T, Y)  # Correct order: X, T, Y\n",
    "\n",
    "# Predict treatment effects (CATEs)\n",
    "cate_preds = forest.predict(X)\n",
    "\n",
    "# Store predictions\n",
    "df['CATE_predicted'] = cate_preds\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample predicted CATEs:\")\n",
    "print(df[['age', 'income', 'prior_engagement', 'CATE_predicted']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296df001",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291ba4e",
   "metadata": {},
   "source": [
    "<a id=\"placebo-robustness\"></a>\n",
    "# ğŸ§ª Placebo Tests & Robustness Checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfbd97b",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Even after careful causal estimation, you must ask:\n",
    "- Was it a real effect?\n",
    "- Could hidden bias still exist?\n",
    "\n",
    "**Robustness checks** build confidence that your findings are not artifacts of modeling choices, random noise, or hidden confounders.\n",
    "\n",
    "**Placebo tests** simulate situations where you expect **no effect** â€” if you detect an effect there, something's wrong.\n",
    "\n",
    "Robust causal analysis is not just about point estimates â€” itâ€™s about **proving to yourself that you aren't fooling yourself**.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec13654",
   "metadata": {},
   "source": [
    "<a id=\"placebo\"></a>\n",
    "#### ğŸ§» Randomized placebo treatments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e7d03",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Placebo tests inject \"fake\" treatments to validate your method.\n",
    "\n",
    "**Idea:**\n",
    "- Randomly assign a placebo treatment.\n",
    "- Re-estimate the treatment effect.\n",
    "- Expect **no significant effect** if your method is honest.\n",
    "\n",
    "If your model finds strong effects even when treatment is randomized, your pipeline is leaking bias or overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "**Placebo Tests Are Critical:**\n",
    "- They detect specification errors.\n",
    "- They detect uncontrolled confounding.\n",
    "- They expose overfitting to noise.\n",
    "\n",
    "Placebo tests are a basic but powerful check â€” always worth doing.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b0287d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placebo test: naive difference in means = 7.79\n"
     ]
    }
   ],
   "source": [
    "# Create a random placebo treatment\n",
    "np.random.seed(123)\n",
    "df['placebo_T'] = np.random.binomial(1, 0.5, size=len(df))\n",
    "\n",
    "# Estimate naive difference for placebo treatment\n",
    "placebo_treated_mean = df.loc[df['placebo_T'] == 1, 'Y_obs'].mean()\n",
    "placebo_control_mean = df.loc[df['placebo_T'] == 0, 'Y_obs'].mean()\n",
    "\n",
    "placebo_naive_diff = placebo_treated_mean - placebo_control_mean\n",
    "\n",
    "print(f\"Placebo test: naive difference in means = {placebo_naive_diff:.2f}\")\n",
    "\n",
    "# Ideally close to zero if model is unbiased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef2135",
   "metadata": {},
   "source": [
    "<a id=\"robustness\"></a>\n",
    "#### âš—ï¸ Sensitivity to unobserved confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb34b3db",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Even after adjusting for observed confounders, **unobserved variables** can still bias causal estimates.\n",
    "\n",
    "**Sensitivity analysis** asks:\n",
    "- How strong would hidden confounding have to be to overturn my results?\n",
    "\n",
    "---\n",
    "\n",
    "**Typical approaches:**\n",
    "- Simulate hidden confounders and see effect size shifts.\n",
    "- Use formulas (like Rosenbaum bounds) to quantify robustness.\n",
    "\n",
    "In practical data science:\n",
    "- Simulate scenarios with added fake bias.\n",
    "- Stress test conclusions under \"worst plausible\" hidden biases.\n",
    "\n",
    "If your conclusions survive plausible levels of unobserved bias, they are more credible.\n",
    "\n",
    "**Important mindset:**  \n",
    "No analysis is perfect â€” the goal is to **understand limits, not pretend away uncertainty**.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0444449c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive difference in means (with hidden confounding): 250.11\n",
      "Inflation in estimate due to hidden confounder: -0.42\n"
     ]
    }
   ],
   "source": [
    "# Simulate a hidden confounder correlated with treatment and outcome\n",
    "np.random.seed(42)\n",
    "df['hidden_confounder'] = np.random.normal(0, 1, size=len(df))\n",
    "\n",
    "# Make the outcome depend slightly on this hidden confounder\n",
    "df['Y_obs_biased'] = df['Y_obs'] + 2 * df['hidden_confounder']\n",
    "\n",
    "# Re-run naive difference with biased outcome\n",
    "treated_mean_biased = df.loc[df['T'] == 1, 'Y_obs_biased'].mean()\n",
    "control_mean_biased = df.loc[df['T'] == 0, 'Y_obs_biased'].mean()\n",
    "\n",
    "biased_naive_diff = treated_mean_biased - control_mean_biased\n",
    "\n",
    "print(f\"Naive difference in means (with hidden confounding): {biased_naive_diff:.2f}\")\n",
    "\n",
    "# See how much bias was introduced\n",
    "bias_inflation = biased_naive_diff - naive_diff\n",
    "print(f\"Inflation in estimate due to hidden confounder: {bias_inflation:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43860c2",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a9b11",
   "metadata": {},
   "source": [
    "<a id=\"counterfactuals\"></a>\n",
    "# ğŸ§¬ Counterfactual Thinking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51896a85",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "**Counterfactual thinking** is the backbone of causal inference.\n",
    "\n",
    "Instead of asking:\n",
    "> \"What happened?\"\n",
    "\n",
    "We ask:\n",
    "> \"What *would have* happened if things were different?\"\n",
    "\n",
    "In causal inference:\n",
    "- Each unit (user, patient, item) has two potential outcomes.\n",
    "- Only one is observed.\n",
    "- The other â€” the counterfactual â€” must be predicted or estimated.\n",
    "\n",
    "---\n",
    "\n",
    "**Counterfactual reasoning enables:**\n",
    "- Simulating user behavior under alternate scenarios.\n",
    "- Personalizing interventions based on predicted outcomes.\n",
    "\n",
    "Without counterfactuals, causal inference is blind.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4f6b0",
   "metadata": {},
   "source": [
    "<a id=\"what-if\"></a>\n",
    "#### ğŸ¤– Predicting what wouldâ€™ve happened\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32b2ad",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Predicting counterfactuals means estimating:\n",
    "- `Y(1)` for untreated units.\n",
    "- `Y(0)` for treated units.\n",
    "\n",
    "We use:\n",
    "- Machine learning models trained on observed data.\n",
    "- Causal forests, meta-learners, and other counterfactual predictors.\n",
    "\n",
    "**Goal:**\n",
    "- Recover the missing potential outcome.\n",
    "- Estimate **individual treatment effects (ITEs)**.\n",
    "\n",
    "This enables granular interventions â€” not just average effects across a population.\n",
    "\n",
    "---\n",
    "\n",
    "**Important to remember:**  \n",
    "Predicted counterfactuals are **estimates**, not direct observations â€” uncertainty always exists.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99646aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Counterfactual Predictions:\n",
      "   T        Y_obs  counterfactual_outcome\n",
      "0  0  1114.502287             1127.868133\n",
      "1  0  1099.893323             1119.847270\n",
      "2  0   704.133035              697.394845\n",
      "3  0  1139.203509             1151.640784\n",
      "4  0  1464.308234             1475.218807\n"
     ]
    }
   ],
   "source": [
    "# Predict counterfactual outcomes using Causal Forest\n",
    "# (Already trained earlier, we use forest)\n",
    "\n",
    "# Predict Y(1) and Y(0) separately\n",
    "cate_preds = df['CATE_predicted'].values\n",
    "baseline_preds = df['y_hat'].values  # From earlier outcome model\n",
    "\n",
    "# Predict counterfactual outcomes\n",
    "df['Y_cf_T1'] = baseline_preds + cate_preds  # Predicted outcome if treated\n",
    "df['Y_cf_T0'] = baseline_preds  # Predicted outcome if untreated (baseline)\n",
    "\n",
    "# Now simulate what would happen if treatment status flipped\n",
    "df['counterfactual_outcome'] = np.where(\n",
    "    df['T'] == 1,\n",
    "    df['Y_cf_T0'],  # If treated, counterfactual is untreated\n",
    "    df['Y_cf_T1']   # If untreated, counterfactual is treated\n",
    ")\n",
    "\n",
    "print(\"\\nSample Counterfactual Predictions:\")\n",
    "print(df[['T', 'Y_obs', 'counterfactual_outcome']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd5c38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<a id=\"personalization\"></a>\n",
    "#### ğŸ” Usage in recommendation & personalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3ae63",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "**Counterfactual predictions unlock personalization:**\n",
    "\n",
    "Instead of treating everyone the same, you can:\n",
    "- Target users where treatment has highest predicted uplift.\n",
    "- De-prioritize users who won't respond.\n",
    "\n",
    "Examples:\n",
    "- **Marketing**: Show ads only to users likely to convert if nudged.\n",
    "- **Healthcare**: Prioritize interventions for patients who benefit most.\n",
    "- **Products**: Recommend features or promotions to maximize lift per user.\n",
    "\n",
    "---\n",
    "\n",
    "**Strategic mindshift:**  \n",
    "Focus on **marginally persuadable users**, not just overall averages.\n",
    "\n",
    "---\n",
    "\n",
    "Real-world use cases often combine:\n",
    "- Causal effect estimation (CATE/ITE)\n",
    "- Ranking users by expected benefit\n",
    "- Action prioritization based on counterfactuals\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e8c9fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top users to prioritize based on CATE:\n",
      "            age        income  prior_engagement  CATE_predicted\n",
      "2841  21.800289  53281.835326          0.350447       20.543173\n",
      "724   42.050385  53280.579923          0.403388       20.443580\n",
      "3205  31.876058  53300.354298          0.420334       20.411161\n",
      "4614  40.670367  53244.477131          0.632127       20.275141\n",
      "3711  24.210210  53209.647772          0.335915       20.259483\n"
     ]
    }
   ],
   "source": [
    "# Rank users by predicted CATE\n",
    "df['priority_score'] = df['CATE_predicted']\n",
    "\n",
    "# Top 5 users we should prioritize for treatment\n",
    "top_users = df.sort_values('priority_score', ascending=False).head(5)\n",
    "\n",
    "print(\"\\nTop users to prioritize based on CATE:\")\n",
    "print(top_users[['age', 'income', 'prior_engagement', 'CATE_predicted']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98552806",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cfc25e",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# ğŸ“Œ Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a40be",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "You now have a practical understanding of core causal inference techniques.\n",
    "\n",
    "You should be able to:\n",
    "- Simulate data with confounding\n",
    "- Estimate naive effects and detect bias\n",
    "- Adjust using regression, matching, stratification\n",
    "- Apply modern tools like DML and Causal Forests\n",
    "- Think in terms of counterfactuals, not just correlations\n",
    "\n",
    "---\n",
    "\n",
    "**Remember:**  \n",
    "Causal thinking is not just a technique â€” itâ€™s a lens to see decision-making clearly.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ea89f",
   "metadata": {},
   "source": [
    "<a id=\"summary-table\"></a>\n",
    "#### ğŸ“ Summary table of methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62794b76",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "| Method | When Useful | Strengths | Weaknesses |\n",
    "|:---|:---|:---|:---|\n",
    "| **Simple Diff-in-Means** | Randomized experiments | Easy, unbiased | Useless with confounding |\n",
    "| **Regression Adjustment** | Observational data with measured confounders | Easy to implement | Model misspecification risk |\n",
    "| **Stratification** | Small number of discrete confounders | Transparent | Breaks down in high dimensions |\n",
    "| **Propensity Score Matching (PSM)** | Observational data with many confounders | Balances groups | Sensitive to model of treatment |\n",
    "| **Instrumental Variables (IV)** | Unobserved confounders exist | Bypasses confounding | Hard to find good instruments |\n",
    "| **Double Machine Learning (DML)** | High-dimensional nonlinear confounders | ML flexibility + debiasing | Needs lots of data, honest splits |\n",
    "| **Causal Forests** | Heterogeneous treatment effects | Flexible CATE estimation | Complex, less interpretable |\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27428737",
   "metadata": {},
   "source": [
    "<a id=\"method-choice\"></a>\n",
    "#### ğŸ“‹ When to use what\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca88bf3",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "**Choosing a method depends on:**\n",
    "\n",
    "- **Randomization present?**\n",
    "  - Yes â†’ Simple difference in means is fine.\n",
    "  - No â†’ Need adjustment.\n",
    "\n",
    "- **Are confounders observed?**\n",
    "  - Yes â†’ Regression, PSM, DML are options.\n",
    "  - No â†’ Need IV or natural experiments.\n",
    "\n",
    "- **Do you expect heterogeneous effects?**\n",
    "  - Yes â†’ Causal Trees, Causal Forests, Meta-learners.\n",
    "\n",
    "- **Is high-dimensional data involved?**\n",
    "  - Yes â†’ Prefer DML over simple regression.\n",
    "\n",
    "---\n",
    "\n",
    "Choosing the right method = matching the method to the bias and complexity in your data.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e590a5",
   "metadata": {},
   "source": [
    "<a id=\"causal-vs-predictive\"></a>\n",
    "#### ğŸ“ Causal vs Predictive mindset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7955a8db",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "**Predictive modeling mindset:**\n",
    "- Focuses on fitting observed outcomes.\n",
    "- Good for forecasts, risk scores, recommendation engines.\n",
    "- Does not care about interventions.\n",
    "\n",
    "**Causal inference mindset:**\n",
    "- Focuses on *what would happen if we intervened*.\n",
    "- Good for making decisions (policies, treatments, products).\n",
    "- Requires stronger assumptions, careful design.\n",
    "\n",
    "---\n",
    "\n",
    "**Key difference:**  \n",
    "Predictive models can be accurate yet useless for interventions.  \n",
    "Causal models are harder but necessary to make confident decisions.\n",
    "\n",
    "---\n",
    "\n",
    "**Quote to remember:**  \n",
    "> \"All models are wrong. Some models are useful.  \n",
    "> Only causal models are useful for actions.\"\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f102463",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
