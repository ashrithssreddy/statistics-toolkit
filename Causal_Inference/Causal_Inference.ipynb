{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0300ea",
   "metadata": {},
   "source": [
    "![Status: In Progress](https://img.shields.io/badge/status-in--progress-yellow)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-70%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green)\n",
    "\n",
    "<!-- ![Status: Complete](https://img.shields.io/badge/status-complete-brightgreen)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-95%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green) -->\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# ğŸ§­ Causal Inference\n",
    "\n",
    "- [ğŸ¯ Introduction to Causal Inference](#intro)\n",
    "  - [ğŸ“ What is Causal Inference?](#what-is-causal)\n",
    "  - [ğŸ“Œ Why go beyond Correlation?](#why-correlation)\n",
    "  - [ğŸ§­ Real-world problems that need causality](#real-world-examples)\n",
    "\n",
    "- [ğŸ§  Core Concepts & Notation](#notation-assumptions)\n",
    "  - [ğŸ§® Treatment, Outcome, Units](#treatment-outcome-units)\n",
    "  - [ğŸ“ Potential Outcomes (Rubin Causal Model)](#potential-outcomes)\n",
    "  - [ğŸ§µ Fundamental Problem of Causal Inference](#fundamental-problem)\n",
    "  - [ğŸ§  Assumptions (SUTVA, Ignorability, Overlap)](#core-assumptions)\n",
    "\n",
    "- [ğŸ§ª Simulated Dataset Setup](#simulated-data)\n",
    "  - [ğŸ§¬ Define treatment assignment logic](#treatment-logic)\n",
    "  - [ğŸ”¬ Inject confounding intentionally](#inject-confounding)\n",
    "  - [ğŸ§Š Simulate potential outcomes + observed data](#simulate-outcomes)\n",
    "\n",
    "- [ğŸš« Naive Estimation](#naive-estimation)\n",
    "  - [âŒ Simple difference in means](#diff-in-means)\n",
    "  - [âš ï¸ Bias due to confounding](#bias-confounding)\n",
    "\n",
    "- [ğŸ•¸ï¸ Causal Diagrams (DAGs)](#causal-diagrams)\n",
    "  - [ğŸ§¿ Quick primer on DAGs](#primer-dags)\n",
    "  - [ğŸ•·ï¸ Confounding vs. colliders vs. mediators](#confounder-collider-mediator)\n",
    "  - [ğŸ”— What can/canâ€™t be estimated just from data](#estimability-from-dags)\n",
    "\n",
    "- [ğŸ” Backdoor Adjustment Methods](#backdoor-adjustment)\n",
    "  - [ğŸ§¾ Conditioning on confounders](#conditioning)\n",
    "  - [ğŸ•µï¸â€â™‚ï¸ Stratification / Subgroup analysis](#stratification)\n",
    "  - [ğŸ“Š Regression Adjustment](#regression-adjustment)\n",
    "  - [ğŸ“Œ Propensity Score Matching (PSM)](#psm)\n",
    "\n",
    "- [ğŸ¯ Instrumental Variables (IV)](#iv-methods)\n",
    "  - [ğŸª When backdoor paths canâ€™t be blocked](#when-use-iv)\n",
    "  - [ğŸ¯ Valid instrument conditions](#iv-conditions)\n",
    "  - [ğŸ§© 2-Stage Least Squares (2SLS)](#2sls)\n",
    "\n",
    "- [ğŸ§° Double Machine Learning (DML)](#dml-methods)\n",
    "  - [ğŸª› Use ML models for nuisance functions](#ml-nuisance)\n",
    "  - [ğŸ§± Residualization + orthogonalization logic](#residualization)\n",
    "  - [ğŸ§² When to prefer over traditional regression](#dml-vs-regression)\n",
    "\n",
    "- [ğŸŒˆ Heterogeneous Treatment Effects](#heterogeneous-effects)\n",
    "  - [ğŸ¨ ATE vs. CATE vs. ITE](#ate-cate-ite)\n",
    "  - [ğŸŒŸ Uplift models and use cases](#uplift-usecases)\n",
    "  - [ğŸ§© Tree-based methods (Causal Trees, Causal Forests)](#causal-forests)\n",
    "\n",
    "- [ğŸ§ª Placebo Tests & Robustness Checks](#placebo-robustness)\n",
    "  - [ğŸ§» Randomized placebo treatments](#placebo)\n",
    "  - [âš—ï¸ Sensitivity to unobserved confounding](#robustness)\n",
    "\n",
    "- [ğŸ§¬ Counterfactual Thinking](#counterfactuals)\n",
    "  - [ğŸ¤– Predicting what wouldâ€™ve happened](#what-if)\n",
    "  - [ğŸ” Usage in recommendation & personalization](#personalization)\n",
    "\n",
    "- [ğŸ“Œ Closing Notes](#closing-notes)\n",
    "  - [ğŸ“ Summary table of methods](#summary-table)\n",
    "  - [ğŸ“‹ When to use what](#method-choice)\n",
    "  - [ğŸ“ Causal vs Predictive mindset](#causal-vs-predictive)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65903c57",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# ğŸ¯ Introduction to Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd39d98",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "##### ğŸ§  Why this Notebook\n",
    "Causal inference gives us the tools to answer \"what if\" questions â€” not just \"what is.\" In product, policy, medicine, and science, we often need to **act**, and actions require understanding their consequences.\n",
    "\n",
    "This field helps us:\n",
    "- Understand **how** and **why** outcomes change.\n",
    "- Move from data *descriptions* to data-*driven interventions*.\n",
    "- Avoid the trap of chasing noisy correlations.\n",
    "\n",
    "This notebook is a build-up from first principles to practical methods â€” with enough grounding to reason about experiments, models, and their assumptions clearly.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd6e5a",
   "metadata": {},
   "source": [
    "<a id=\"what-is-causal\"></a>\n",
    "#### ğŸ“ What is Causal Inference?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddec552",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "##### ğŸ“ Causal inference is the process of estimating the **effect** of one variable (the treatment) on another (the outcome), holding all else constant. The core idea is to estimate:\n",
    "> What would the outcome have been if the treatment had (or had not) occurred?\n",
    "\n",
    "Unlike correlation or predictive modeling:\n",
    "- It asks **counterfactual** questions â€” what *would* have happened under different scenarios.\n",
    "- It requires **assumptions**, **design**, and often **randomization** or clever statistical tricks.\n",
    "\n",
    "At its heart, causal inference is about:\n",
    "- Designing better **interventions**\n",
    "- Estimating **treatment effects**\n",
    "- Avoiding misleading **associational patterns**\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e04cf",
   "metadata": {},
   "source": [
    "<a id=\"why-correlation\"></a>\n",
    "#### ğŸ“Œ Why go beyond Correlation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7aa8cf",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "##### ğŸ“Œ Correlation can be dangerous when used as a proxy for causation.\n",
    "\n",
    "Example: Ice cream sales are correlated with shark attacks. Should we ban dessert?  \n",
    "Clearly not â€” theyâ€™re both caused by heatwaves (a confounder).\n",
    "\n",
    "Correlation fails because it:\n",
    "- Ignores **confounders** (common causes of both variables)\n",
    "- Misses **directionality** (what affects what)\n",
    "- Can be driven by **reverse causation** or **coincidence**\n",
    "\n",
    "Causal inference gives tools to:\n",
    "- **Identify** confounding\n",
    "- **Design** better studies (randomized or observational)\n",
    "- **Interpret** results in terms of actionable causes\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd9a45",
   "metadata": {},
   "source": [
    "<a id=\"real-world-examples\"></a>\n",
    "#### ğŸ§­ Real-world problems that need causality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cdc369",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "##### ğŸ§­ Correlation might be fine for dashboards. But when making **decisions**, causality is non-negotiable.\n",
    "\n",
    "Examples:\n",
    "- **Product**: Did that new button placement increase checkout, or was it a seasonal effect?\n",
    "- **Marketing**: Did the email nudge lead to purchases, or did loyal users open it anyway?\n",
    "- **Policy**: Did a tax cut help the economy, or was it already improving?\n",
    "- **Health**: Does a drug reduce disease, or do healthier people tend to take it?\n",
    "\n",
    "These questions involve **interventions**, and only causal methods can tell us what wouldâ€™ve happened under a different choice.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d999e6",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972fc15",
   "metadata": {},
   "source": [
    "<a id=\"notation-assumptions\"></a>\n",
    "# ğŸ§  Core Concepts & Notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb9997",
   "metadata": {},
   "source": [
    "<a id=\"treatment-outcome-units\"></a>\n",
    "#### ğŸ§® Treatment, Outcome, Units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7deb6",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "- **Treatment (`T`)**: The intervention or condition being tested (e.g., new design, drug, policy).\n",
    "- **Outcome (`Y`)**: The result or metric affected by the treatment (e.g., click, recovery, score).\n",
    "- **Units (`i`)**: The entities receiving treatment and producing outcomes (e.g., users, patients, schools).\n",
    "\n",
    "Each unit can receive a treatment or control, and we observe only one outcome â€” not both.\n",
    "\n",
    "This framing is universal and applies whether you're testing emails, ads, or vaccines.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e705a",
   "metadata": {},
   "source": [
    "<a id=\"potential-outcomes\"></a>\n",
    "#### ğŸ“ Potential Outcomes (Rubin Causal Model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1931ace",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "The **Potential Outcomes framework** (aka Rubin Causal Model) imagines two parallel worlds for each unit:\n",
    "\n",
    "- `Y(1)`: Outcome if treated  \n",
    "- `Y(0)`: Outcome if not treated  \n",
    "\n",
    "We define **Individual Treatment Effect (ITE)** as:  \n",
    "`ITE = Y(1) - Y(0)`\n",
    "\n",
    "**Key idea:**  \n",
    "Each unit has both potential outcomes â€” but we can only observe one. The other is **counterfactual**.\n",
    "\n",
    "This framework allows us to define:\n",
    "- ATE (Average Treatment Effect)\n",
    "- CATE (Conditional ATE, for subgroups)\n",
    "- And formalizes why causal inference is hard: we never see both outcomes.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d3fd",
   "metadata": {},
   "source": [
    "<a id=\"fundamental-problem\"></a>\n",
    "#### ğŸ§µ Fundamental Problem of Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f145ea",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "The **Fundamental Problem of Causal Inference**:  \n",
    "> For any individual, we can observe only one potential outcome â€” never both.\n",
    "\n",
    "Example:\n",
    "- A user sees version A â†’ you observe `Y(0)`\n",
    "- Youâ€™ll never know what `Y(1)` would have been for that exact user\n",
    "\n",
    "This creates a missing data problem: the counterfactual is unobservable.\n",
    "\n",
    "To solve this, we rely on:\n",
    "- **Randomization**\n",
    "- **Modeling + assumptions**\n",
    "- **Matching or weighting approaches**\n",
    "  \n",
    "All causal methods are, in some way, trying to **approximate the missing counterfactual**.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee05897",
   "metadata": {},
   "source": [
    "<a id=\"core-assumptions\"></a>\n",
    "#### ğŸ§  Assumptions (SUTVA, Ignorability, Overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed826353",
   "metadata": {},
   "source": [
    "<details><summary><strong>ğŸ“‰ Click to Expand</strong></summary>\n",
    "\n",
    "Causal inference relies heavily on assumptions â€” even when you donâ€™t randomize.\n",
    "\n",
    "Three core ones:\n",
    "\n",
    "- **SUTVA (Stable Unit Treatment Value Assumption)**  \n",
    "  â†’ Your treatment doesnâ€™t affect someone elseâ€™s outcome.  \n",
    "  â†’ No interference across units.\n",
    "\n",
    "- **Ignorability (a.k.a. Unconfoundedness)**  \n",
    "  â†’ Given the observed covariates, treatment assignment is as good as random.  \n",
    "  â†’ This lets you use observed data for estimation.\n",
    "\n",
    "- **Overlap (a.k.a. Positivity)**  \n",
    "  â†’ Every unit has a non-zero probability of receiving either treatment.  \n",
    "  â†’ You canâ€™t learn effects where thereâ€™s no variation.\n",
    "\n",
    "Without these, causal estimates can be biased or undefined. Always question whether they hold before trusting results.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb1851",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361ddee",
   "metadata": {},
   "source": [
    "<a id=\"simulated-data\"></a>\n",
    "# ğŸ§ª Simulated Dataset Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fe447",
   "metadata": {},
   "source": [
    "<a id=\"treatment-logic\"></a>\n",
    "#### ğŸ§¬ Define treatment assignment logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66180170",
   "metadata": {},
   "source": [
    "<a id=\"inject-confounding\"></a>\n",
    "#### ğŸ”¬ Inject confounding intentionally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca43ff",
   "metadata": {},
   "source": [
    "<a id=\"simulate-outcomes\"></a>\n",
    "#### ğŸ§Š Simulate potential outcomes + observed data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49e27e",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dde548",
   "metadata": {},
   "source": [
    "<a id=\"naive-estimation\"></a>\n",
    "# ğŸš« Naive Estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc35de",
   "metadata": {},
   "source": [
    "<a id=\"diff-in-means\"></a>\n",
    "#### âŒ Simple difference in means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c7490",
   "metadata": {},
   "source": [
    "<a id=\"bias-confounding\"></a>\n",
    "#### âš ï¸ Bias due to confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2f4dd",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaffce9",
   "metadata": {},
   "source": [
    "<a id=\"causal-diagrams\"></a>\n",
    "# ğŸ•¸ï¸ Causal Diagrams (DAGs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b06f1",
   "metadata": {},
   "source": [
    "<a id=\"primer-dags\"></a>\n",
    "#### ğŸ§¿ Quick primer on DAGs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a48aa4",
   "metadata": {},
   "source": [
    "<a id=\"confounder-collider-mediator\"></a>\n",
    "#### ğŸ•·ï¸ Confounding vs. colliders vs. mediators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5353f4",
   "metadata": {},
   "source": [
    "<a id=\"estimability-from-dags\"></a>\n",
    "#### ğŸ”— What can/canâ€™t be estimated just from data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6b2de",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef463393",
   "metadata": {},
   "source": [
    "<a id=\"backdoor-adjustment\"></a>\n",
    "# ğŸ” Backdoor Adjustment Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7760664",
   "metadata": {},
   "source": [
    "<a id=\"conditioning\"></a>\n",
    "#### ğŸ§¾ Conditioning on confounders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e16492",
   "metadata": {},
   "source": [
    "<a id=\"stratification\"></a>\n",
    "#### ğŸ•µï¸â€â™‚ï¸ Stratification / Subgroup analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00bc7ca",
   "metadata": {},
   "source": [
    "<a id=\"regression-adjustment\"></a>\n",
    "#### ğŸ“Š Regression Adjustment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5906e36",
   "metadata": {},
   "source": [
    "<a id=\"psm\"></a>\n",
    "#### ğŸ“Œ Propensity Score Matching (PSM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b259b1",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229aa095",
   "metadata": {},
   "source": [
    "<a id=\"iv-methods\"></a>\n",
    "# ğŸ¯ Instrumental Variables (IV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b63f1d",
   "metadata": {},
   "source": [
    "<a id=\"when-use-iv\"></a>\n",
    "#### ğŸª When backdoor paths canâ€™t be blocked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0322fe",
   "metadata": {},
   "source": [
    "<a id=\"iv-conditions\"></a>\n",
    "#### ğŸ¯ Valid instrument conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fff624",
   "metadata": {},
   "source": [
    "<a id=\"2sls\"></a>\n",
    "#### ğŸ§© 2-Stage Least Squares (2SLS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1dff19",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff962ca0",
   "metadata": {},
   "source": [
    "<a id=\"dml-methods\"></a>\n",
    "# ğŸ§° Double Machine Learning (DML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9754c",
   "metadata": {},
   "source": [
    "<a id=\"ml-nuisance\"></a>\n",
    "#### ğŸª› Use ML models for nuisance functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000b403",
   "metadata": {},
   "source": [
    "<a id=\"residualization\"></a>\n",
    "#### ğŸ§± Residualization + orthogonalization logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd36b53",
   "metadata": {},
   "source": [
    "<a id=\"dml-vs-regression\"></a>\n",
    "#### ğŸ§² When to prefer over traditional regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14a213",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15edb2",
   "metadata": {},
   "source": [
    "<a id=\"heterogeneous-effects\"></a>\n",
    "# ğŸŒˆ Heterogeneous Treatment Effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ad0cd",
   "metadata": {},
   "source": [
    "<a id=\"ate-cate-ite\"></a>\n",
    "#### ğŸ¨ ATE vs. CATE vs. ITE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26833b",
   "metadata": {},
   "source": [
    "<a id=\"uplift-usecases\"></a>\n",
    "#### ğŸŒŸ Uplift models and use cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5969183",
   "metadata": {},
   "source": [
    "<a id=\"causal-forests\"></a>\n",
    "#### ğŸ§© Tree-based methods (Causal Trees, Causal Forests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296df001",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291ba4e",
   "metadata": {},
   "source": [
    "<a id=\"placebo-robustness\"></a>\n",
    "# ğŸ§ª Placebo Tests & Robustness Checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec13654",
   "metadata": {},
   "source": [
    "<a id=\"placebo\"></a>\n",
    "#### ğŸ§» Randomized placebo treatments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef2135",
   "metadata": {},
   "source": [
    "<a id=\"robustness\"></a>\n",
    "#### âš—ï¸ Sensitivity to unobserved confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43860c2",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a9b11",
   "metadata": {},
   "source": [
    "<a id=\"counterfactuals\"></a>\n",
    "# ğŸ§¬ Counterfactual Thinking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4f6b0",
   "metadata": {},
   "source": [
    "<a id=\"what-if\"></a>\n",
    "#### ğŸ¤– Predicting what wouldâ€™ve happened\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd5c38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<a id=\"personalization\"></a>\n",
    "#### ğŸ” Usage in recommendation & personalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98552806",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cfc25e",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# ğŸ“Œ Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ea89f",
   "metadata": {},
   "source": [
    "<a id=\"summary-table\"></a>\n",
    "#### ğŸ“ Summary table of methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27428737",
   "metadata": {},
   "source": [
    "<a id=\"method-choice\"></a>\n",
    "#### ğŸ“‹ When to use what\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e590a5",
   "metadata": {},
   "source": [
    "<a id=\"causal-vs-predictive\"></a>\n",
    "#### ğŸ“ Causal vs Predictive mindset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f102463",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
