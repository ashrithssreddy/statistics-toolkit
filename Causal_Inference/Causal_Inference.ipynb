{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be0300ea",
   "metadata": {},
   "source": [
    "![Status: In Progress](https://img.shields.io/badge/status-in--progress-yellow)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-70%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green)\n",
    "\n",
    "<!-- ![Status: Complete](https://img.shields.io/badge/status-complete-brightgreen)\n",
    "![Python](https://img.shields.io/badge/python-3.10-blue)\n",
    "![Coverage](https://img.shields.io/badge/coverage-95%25-yellowgreen)\n",
    "![License](https://img.shields.io/badge/license-MIT-green) -->\n",
    "\n",
    "<a id=\"table-of-contents\"></a>\n",
    "# 🧭 Causal Inference\n",
    "\n",
    "- [🎯 Introduction to Causal Inference](#intro)\n",
    "  - [🎓 What is Causal Inference?](#what-is-causal)\n",
    "  - [📌 Why go beyond Correlation?](#why-correlation)\n",
    "  - [🧭 Real-world problems that need causality](#real-world-examples)\n",
    "\n",
    "- [🧠 Core Concepts & Notation](#notation-assumptions)\n",
    "  - [🧮 Treatment, Outcome, Units](#treatment-outcome-units)\n",
    "  - [📐 Potential Outcomes (Rubin Causal Model)](#potential-outcomes)\n",
    "  - [🧵 Fundamental Problem of Causal Inference](#fundamental-problem)\n",
    "  - [🧠 Assumptions (SUTVA, Ignorability, Overlap)](#core-assumptions)\n",
    "\n",
    "- [🧪 Simulated Dataset Setup](#simulated-data)\n",
    "  - [🧬 Define treatment assignment logic](#treatment-logic)\n",
    "  - [🔬 Inject confounding intentionally](#inject-confounding)\n",
    "  - [🧊 Simulate potential outcomes + observed data](#simulate-outcomes)\n",
    "\n",
    "- [🚫 Naive Estimation](#naive-estimation)\n",
    "  - [❌ Simple difference in means](#diff-in-means)\n",
    "  - [⚠️ Bias due to confounding](#bias-confounding)\n",
    "\n",
    "- [🕸️ Causal Diagrams (DAGs)](#causal-diagrams)\n",
    "  - [🧿 Quick primer on DAGs](#primer-dags)\n",
    "  - [🕷️ Confounding vs. colliders vs. mediators](#confounder-collider-mediator)\n",
    "  - [🔗 What can/can’t be estimated just from data](#estimability-from-dags)\n",
    "\n",
    "- [🔍 Backdoor Adjustment Methods](#backdoor-adjustment)\n",
    "  - [🧾 Conditioning on confounders](#conditioning)\n",
    "  - [🕵️‍♂️ Stratification / Subgroup analysis](#stratification)\n",
    "  - [📊 Regression Adjustment](#regression-adjustment)\n",
    "  - [📌 Propensity Score Matching (PSM)](#psm)\n",
    "\n",
    "- [🎯 Instrumental Variables (IV)](#iv-methods)\n",
    "  - [🪝 When backdoor paths can’t be blocked](#when-use-iv)\n",
    "  - [🎯 Valid instrument conditions](#iv-conditions)\n",
    "  - [🧩 2-Stage Least Squares (2SLS)](#2sls)\n",
    "\n",
    "- [🧰 Double Machine Learning (DML)](#dml-methods)\n",
    "  - [🪛 Use ML models for nuisance functions](#ml-nuisance)\n",
    "  - [🧱 Residualization + orthogonalization logic](#residualization)\n",
    "  - [🧲 When to prefer over traditional regression](#dml-vs-regression)\n",
    "\n",
    "- [🌈 Heterogeneous Treatment Effects](#heterogeneous-effects)\n",
    "  - [🎨 ATE vs. CATE vs. ITE](#ate-cate-ite)\n",
    "  - [🌟 Uplift models and use cases](#uplift-usecases)\n",
    "  - [🧩 Tree-based methods (Causal Trees, Causal Forests)](#causal-forests)\n",
    "\n",
    "- [🧪 Placebo Tests & Robustness Checks](#placebo-robustness)\n",
    "  - [🧻 Randomized placebo treatments](#placebo)\n",
    "  - [⚗️ Sensitivity to unobserved confounding](#robustness)\n",
    "\n",
    "- [🧬 Counterfactual Thinking](#counterfactuals)\n",
    "  - [🤖 Predicting what would’ve happened](#what-if)\n",
    "  - [🔁 Usage in recommendation & personalization](#personalization)\n",
    "\n",
    "- [📌 Closing Notes](#closing-notes)\n",
    "  - [📝 Summary table of methods](#summary-table)\n",
    "  - [📋 When to use what](#method-choice)\n",
    "  - [📎 Causal vs Predictive mindset](#causal-vs-predictive)\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65903c57",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# 🎯 Introduction to Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd39d98",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "##### 🧠 Why this Notebook\n",
    "Causal inference gives us the tools to answer \"what if\" questions — not just \"what is.\" In product, policy, medicine, and science, we often need to **act**, and actions require understanding their consequences.\n",
    "\n",
    "This field helps us:\n",
    "- Understand **how** and **why** outcomes change.\n",
    "- Move from data *descriptions* to data-*driven interventions*.\n",
    "- Avoid the trap of chasing noisy correlations.\n",
    "\n",
    "This notebook is a build-up from first principles to practical methods — with enough grounding to reason about experiments, models, and their assumptions clearly.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd6e5a",
   "metadata": {},
   "source": [
    "<a id=\"what-is-causal\"></a>\n",
    "#### 🎓 What is Causal Inference?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddec552",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "##### 🎓 Causal inference is the process of estimating the **effect** of one variable (the treatment) on another (the outcome), holding all else constant. The core idea is to estimate:\n",
    "> What would the outcome have been if the treatment had (or had not) occurred?\n",
    "\n",
    "Unlike correlation or predictive modeling:\n",
    "- It asks **counterfactual** questions — what *would* have happened under different scenarios.\n",
    "- It requires **assumptions**, **design**, and often **randomization** or clever statistical tricks.\n",
    "\n",
    "At its heart, causal inference is about:\n",
    "- Designing better **interventions**\n",
    "- Estimating **treatment effects**\n",
    "- Avoiding misleading **associational patterns**\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e04cf",
   "metadata": {},
   "source": [
    "<a id=\"why-correlation\"></a>\n",
    "#### 📌 Why go beyond Correlation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7aa8cf",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "##### 📌 Correlation can be dangerous when used as a proxy for causation.\n",
    "\n",
    "Example: Ice cream sales are correlated with shark attacks. Should we ban dessert?  \n",
    "Clearly not — they’re both caused by heatwaves (a confounder).\n",
    "\n",
    "Correlation fails because it:\n",
    "- Ignores **confounders** (common causes of both variables)\n",
    "- Misses **directionality** (what affects what)\n",
    "- Can be driven by **reverse causation** or **coincidence**\n",
    "\n",
    "Causal inference gives tools to:\n",
    "- **Identify** confounding\n",
    "- **Design** better studies (randomized or observational)\n",
    "- **Interpret** results in terms of actionable causes\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd9a45",
   "metadata": {},
   "source": [
    "<a id=\"real-world-examples\"></a>\n",
    "#### 🧭 Real-world problems that need causality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cdc369",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "##### 🧭 Correlation might be fine for dashboards. But when making **decisions**, causality is non-negotiable.\n",
    "\n",
    "Examples:\n",
    "- **Product**: Did that new button placement increase checkout, or was it a seasonal effect?\n",
    "- **Marketing**: Did the email nudge lead to purchases, or did loyal users open it anyway?\n",
    "- **Policy**: Did a tax cut help the economy, or was it already improving?\n",
    "- **Health**: Does a drug reduce disease, or do healthier people tend to take it?\n",
    "\n",
    "These questions involve **interventions**, and only causal methods can tell us what would’ve happened under a different choice.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d999e6",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1972fc15",
   "metadata": {},
   "source": [
    "<a id=\"notation-assumptions\"></a>\n",
    "# 🧠 Core Concepts & Notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fb9997",
   "metadata": {},
   "source": [
    "<a id=\"treatment-outcome-units\"></a>\n",
    "#### 🧮 Treatment, Outcome, Units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7deb6",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "- **Treatment (`T`)**: The intervention or condition being tested (e.g., new design, drug, policy).\n",
    "- **Outcome (`Y`)**: The result or metric affected by the treatment (e.g., click, recovery, score).\n",
    "- **Units (`i`)**: The entities receiving treatment and producing outcomes (e.g., users, patients, schools).\n",
    "\n",
    "Each unit can receive a treatment or control, and we observe only one outcome — not both.\n",
    "\n",
    "This framing is universal and applies whether you're testing emails, ads, or vaccines.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e705a",
   "metadata": {},
   "source": [
    "<a id=\"potential-outcomes\"></a>\n",
    "#### 📐 Potential Outcomes (Rubin Causal Model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1931ace",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "The **Potential Outcomes framework** (aka Rubin Causal Model) imagines two parallel worlds for each unit:\n",
    "\n",
    "- `Y(1)`: Outcome if treated  \n",
    "- `Y(0)`: Outcome if not treated  \n",
    "\n",
    "We define **Individual Treatment Effect (ITE)** as:  \n",
    "`ITE = Y(1) - Y(0)`\n",
    "\n",
    "**Key idea:**  \n",
    "Each unit has both potential outcomes — but we can only observe one. The other is **counterfactual**.\n",
    "\n",
    "This framework allows us to define:\n",
    "- ATE (Average Treatment Effect)\n",
    "- CATE (Conditional ATE, for subgroups)\n",
    "- And formalizes why causal inference is hard: we never see both outcomes.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d3fd",
   "metadata": {},
   "source": [
    "<a id=\"fundamental-problem\"></a>\n",
    "#### 🧵 Fundamental Problem of Causal Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f145ea",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "The **Fundamental Problem of Causal Inference**:  \n",
    "> For any individual, we can observe only one potential outcome — never both.\n",
    "\n",
    "Example:\n",
    "- A user sees version A → you observe `Y(0)`\n",
    "- You’ll never know what `Y(1)` would have been for that exact user\n",
    "\n",
    "This creates a missing data problem: the counterfactual is unobservable.\n",
    "\n",
    "To solve this, we rely on:\n",
    "- **Randomization**\n",
    "- **Modeling + assumptions**\n",
    "- **Matching or weighting approaches**\n",
    "  \n",
    "All causal methods are, in some way, trying to **approximate the missing counterfactual**.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee05897",
   "metadata": {},
   "source": [
    "<a id=\"core-assumptions\"></a>\n",
    "#### 🧠 Assumptions (SUTVA, Ignorability, Overlap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed826353",
   "metadata": {},
   "source": [
    "<details><summary><strong>📉 Click to Expand</strong></summary>\n",
    "\n",
    "Causal inference relies heavily on assumptions — even when you don’t randomize.\n",
    "\n",
    "Three core ones:\n",
    "\n",
    "- **SUTVA (Stable Unit Treatment Value Assumption)**  \n",
    "  → Your treatment doesn’t affect someone else’s outcome.  \n",
    "  → No interference across units.\n",
    "\n",
    "- **Ignorability (a.k.a. Unconfoundedness)**  \n",
    "  → Given the observed covariates, treatment assignment is as good as random.  \n",
    "  → This lets you use observed data for estimation.\n",
    "\n",
    "- **Overlap (a.k.a. Positivity)**  \n",
    "  → Every unit has a non-zero probability of receiving either treatment.  \n",
    "  → You can’t learn effects where there’s no variation.\n",
    "\n",
    "Without these, causal estimates can be biased or undefined. Always question whether they hold before trusting results.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb1851",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361ddee",
   "metadata": {},
   "source": [
    "<a id=\"simulated-data\"></a>\n",
    "# 🧪 Simulated Dataset Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fe447",
   "metadata": {},
   "source": [
    "<a id=\"treatment-logic\"></a>\n",
    "#### 🧬 Define treatment assignment logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66180170",
   "metadata": {},
   "source": [
    "<a id=\"inject-confounding\"></a>\n",
    "#### 🔬 Inject confounding intentionally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca43ff",
   "metadata": {},
   "source": [
    "<a id=\"simulate-outcomes\"></a>\n",
    "#### 🧊 Simulate potential outcomes + observed data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49e27e",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dde548",
   "metadata": {},
   "source": [
    "<a id=\"naive-estimation\"></a>\n",
    "# 🚫 Naive Estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc35de",
   "metadata": {},
   "source": [
    "<a id=\"diff-in-means\"></a>\n",
    "#### ❌ Simple difference in means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c7490",
   "metadata": {},
   "source": [
    "<a id=\"bias-confounding\"></a>\n",
    "#### ⚠️ Bias due to confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2f4dd",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaffce9",
   "metadata": {},
   "source": [
    "<a id=\"causal-diagrams\"></a>\n",
    "# 🕸️ Causal Diagrams (DAGs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540b06f1",
   "metadata": {},
   "source": [
    "<a id=\"primer-dags\"></a>\n",
    "#### 🧿 Quick primer on DAGs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a48aa4",
   "metadata": {},
   "source": [
    "<a id=\"confounder-collider-mediator\"></a>\n",
    "#### 🕷️ Confounding vs. colliders vs. mediators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5353f4",
   "metadata": {},
   "source": [
    "<a id=\"estimability-from-dags\"></a>\n",
    "#### 🔗 What can/can’t be estimated just from data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6b2de",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef463393",
   "metadata": {},
   "source": [
    "<a id=\"backdoor-adjustment\"></a>\n",
    "# 🔍 Backdoor Adjustment Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7760664",
   "metadata": {},
   "source": [
    "<a id=\"conditioning\"></a>\n",
    "#### 🧾 Conditioning on confounders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e16492",
   "metadata": {},
   "source": [
    "<a id=\"stratification\"></a>\n",
    "#### 🕵️‍♂️ Stratification / Subgroup analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00bc7ca",
   "metadata": {},
   "source": [
    "<a id=\"regression-adjustment\"></a>\n",
    "#### 📊 Regression Adjustment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5906e36",
   "metadata": {},
   "source": [
    "<a id=\"psm\"></a>\n",
    "#### 📌 Propensity Score Matching (PSM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b259b1",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229aa095",
   "metadata": {},
   "source": [
    "<a id=\"iv-methods\"></a>\n",
    "# 🎯 Instrumental Variables (IV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b63f1d",
   "metadata": {},
   "source": [
    "<a id=\"when-use-iv\"></a>\n",
    "#### 🪝 When backdoor paths can’t be blocked\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0322fe",
   "metadata": {},
   "source": [
    "<a id=\"iv-conditions\"></a>\n",
    "#### 🎯 Valid instrument conditions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fff624",
   "metadata": {},
   "source": [
    "<a id=\"2sls\"></a>\n",
    "#### 🧩 2-Stage Least Squares (2SLS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1dff19",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff962ca0",
   "metadata": {},
   "source": [
    "<a id=\"dml-methods\"></a>\n",
    "# 🧰 Double Machine Learning (DML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef9754c",
   "metadata": {},
   "source": [
    "<a id=\"ml-nuisance\"></a>\n",
    "#### 🪛 Use ML models for nuisance functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3000b403",
   "metadata": {},
   "source": [
    "<a id=\"residualization\"></a>\n",
    "#### 🧱 Residualization + orthogonalization logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd36b53",
   "metadata": {},
   "source": [
    "<a id=\"dml-vs-regression\"></a>\n",
    "#### 🧲 When to prefer over traditional regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14a213",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15edb2",
   "metadata": {},
   "source": [
    "<a id=\"heterogeneous-effects\"></a>\n",
    "# 🌈 Heterogeneous Treatment Effects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7ad0cd",
   "metadata": {},
   "source": [
    "<a id=\"ate-cate-ite\"></a>\n",
    "#### 🎨 ATE vs. CATE vs. ITE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26833b",
   "metadata": {},
   "source": [
    "<a id=\"uplift-usecases\"></a>\n",
    "#### 🌟 Uplift models and use cases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5969183",
   "metadata": {},
   "source": [
    "<a id=\"causal-forests\"></a>\n",
    "#### 🧩 Tree-based methods (Causal Trees, Causal Forests)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296df001",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291ba4e",
   "metadata": {},
   "source": [
    "<a id=\"placebo-robustness\"></a>\n",
    "# 🧪 Placebo Tests & Robustness Checks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec13654",
   "metadata": {},
   "source": [
    "<a id=\"placebo\"></a>\n",
    "#### 🧻 Randomized placebo treatments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffef2135",
   "metadata": {},
   "source": [
    "<a id=\"robustness\"></a>\n",
    "#### ⚗️ Sensitivity to unobserved confounding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43860c2",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a9b11",
   "metadata": {},
   "source": [
    "<a id=\"counterfactuals\"></a>\n",
    "# 🧬 Counterfactual Thinking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4f6b0",
   "metadata": {},
   "source": [
    "<a id=\"what-if\"></a>\n",
    "#### 🤖 Predicting what would’ve happened\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefd5c38",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<a id=\"personalization\"></a>\n",
    "#### 🔁 Usage in recommendation & personalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98552806",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cfc25e",
   "metadata": {},
   "source": [
    "<a id=\"closing-notes\"></a>\n",
    "# 📌 Closing Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ea89f",
   "metadata": {},
   "source": [
    "<a id=\"summary-table\"></a>\n",
    "#### 📝 Summary table of methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27428737",
   "metadata": {},
   "source": [
    "<a id=\"method-choice\"></a>\n",
    "#### 📋 When to use what\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e590a5",
   "metadata": {},
   "source": [
    "<a id=\"causal-vs-predictive\"></a>\n",
    "#### 📎 Causal vs Predictive mindset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f102463",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
