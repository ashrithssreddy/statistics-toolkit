{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf94292f",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- [Data-Setup](#Data-Setup)\n",
    "- [Randomization Methods](#Randomization-Methods)\n",
    "- [AA Testing](#AA-Testing)\n",
    "    - [SRM Check](#SRM-Check)\n",
    "- [Power Analysis](#Power-Analysis)\n",
    "- [AB Testing](#AB-Testing)\n",
    "    - [Definitions](#Definitions)\n",
    "    - [Results Summary](#Results-Summary)\n",
    "    - [Test](#Test)\n",
    "- [How Long](#How-Long)\n",
    "- [Results](#Results)\n",
    "    - [Summary](#Conversion-Rates)\n",
    "    - [Visualization](#Visualization)\n",
    "    - [Confidence Intervals Within Groups](#Confidence-Intervals-Outcomes)\n",
    "    - [Confidence Intervals Across Groups](#Confidence-Intervals-Difference)\n",
    "    - [Conclusion](#Conclusion)\n",
    "- [Post Hoc Analysis](#Post-Hoc-Analysis)\n",
    "    - [Segmented Lift](#Segmented-Lift)\n",
    "    - [Gaurdrail Metrics](#Gaurdrail-Metrics)\n",
    "    - [Rollout Simulation](#Rollout-Simulation)\n",
    "- [Other Notes](#Other-Notes)\n",
    "    - [Experimentation-Infrastructure](#Experimentation-Infrastructure)\n",
    "- [Scratch Notes](#Scratch-Notes)\n",
    "    - [Other Use Cases](#Other-Use-Cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c7961",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b194d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chi2_contingency, ttest_ind, ttest_rel, mannwhitneyu\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "# Set Seed \n",
    "my_seed=42\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e7fb9",
   "metadata": {},
   "source": [
    "##### Sample user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dab99fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>city</th>\n",
       "      <th>past_purchase_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>iOS</td>\n",
       "      <td>51.305706</td>\n",
       "      <td>sf</td>\n",
       "      <td>46.847308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Android</td>\n",
       "      <td>45.514890</td>\n",
       "      <td>ny</td>\n",
       "      <td>57.589692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>51.376412</td>\n",
       "      <td>sf</td>\n",
       "      <td>42.271748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>iOS</td>\n",
       "      <td>20.186466</td>\n",
       "      <td>ny</td>\n",
       "      <td>47.631814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>iOS</td>\n",
       "      <td>46.704922</td>\n",
       "      <td>austin</td>\n",
       "      <td>45.146365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>iOS</td>\n",
       "      <td>37.762846</td>\n",
       "      <td>austin</td>\n",
       "      <td>47.978073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>iOS</td>\n",
       "      <td>48.843474</td>\n",
       "      <td>austin</td>\n",
       "      <td>47.823188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>iOS</td>\n",
       "      <td>55.117280</td>\n",
       "      <td>sf</td>\n",
       "      <td>60.987769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>iOS</td>\n",
       "      <td>54.150362</td>\n",
       "      <td>austin</td>\n",
       "      <td>58.254163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>iOS</td>\n",
       "      <td>62.407749</td>\n",
       "      <td>sf</td>\n",
       "      <td>58.135096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id platform  engagement_score    city  past_purchase_count\n",
       "0         1      iOS         51.305706      sf            46.847308\n",
       "1         2  Android         45.514890      ny            57.589692\n",
       "2         3  Android         51.376412      sf            42.271748\n",
       "3         4      iOS         20.186466      ny            47.631814\n",
       "4         5      iOS         46.704922  austin            45.146365\n",
       "..      ...      ...               ...     ...                  ...\n",
       "95       96      iOS         37.762846  austin            47.978073\n",
       "96       97      iOS         48.843474  austin            47.823188\n",
       "97       98      iOS         55.117280      sf            60.987769\n",
       "98       99      iOS         54.150362  austin            58.254163\n",
       "99      100      iOS         62.407749      sf            58.135096\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_count = 100 \n",
    "\n",
    "np.random.seed(my_seed)  # For reproducibility\n",
    "users = pd.DataFrame({\n",
    "    'user_id': range(1, observations_count+1),\n",
    "    'platform': np.random.choice(['iOS', 'Android'], size=observations_count, p=[0.6, 0.4]),  # 60% iOS, 40% Android\n",
    "    'engagement_score': np.random.normal(50, 15, observations_count),  # Simulated user engagement scores\n",
    "    'city': np.random.choice(['ny', 'sf', 'chicago', 'austin'], size=observations_count),\n",
    "    'past_purchase_count': np.random.normal(loc=50, scale=10, size=observations_count)  # pre_experiment_metric for CUPED randomization\n",
    "})\n",
    "users\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff754e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb39ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e90324b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "853f1591",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cad63c",
   "metadata": {},
   "source": [
    "# Randomization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f09e4f",
   "metadata": {},
   "source": [
    "- Ensures that differences in outcome metrics are due to the experiment and not pre-existing differences between users.\n",
    "- Eliminates selection bias (e.g., users choosing their own group).\n",
    "- Helps balance confounding variables (e.g., demographics, device type, purchase history).\n",
    "- Enables valid statistical inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09b1086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomization_method = \"simple\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab4fa6",
   "metadata": {},
   "source": [
    "#### Simple Randomization\n",
    "- Each user has an equal chance (e.g., 50/50 split for A/B) of being assigned to treatment or control.\n",
    "- Works well when sample sizes are large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a9d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e03a828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id      group\n",
       "0         1    control\n",
       "1         2  treatment\n",
       "2         3  treatment\n",
       "3         4  treatment\n",
       "4         5    control\n",
       "..      ...        ...\n",
       "95       96    control\n",
       "96       97  treatment\n",
       "97       98    control\n",
       "98       99    control\n",
       "99      100    control\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign each user to 'control' or 'treatment' with 50% probability\n",
    "users['group'] = np.random.choice(['control', 'treatment'], size=len(users), p=[0.5, 0.5])\n",
    "\n",
    "# Display the result\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ce64c",
   "metadata": {},
   "source": [
    "#### Stratified Sampling\n",
    "- Ensures balance across key segments (e.g., country, platform, user tenure).\n",
    "- Example: If 60% of your users are on iOS and 40% on Android, simple randomization might cause an imbalance, so you stratify by platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify by platform to ensure balance\n",
    "train, test = train_test_split(users, test_size=0.5, stratify=users['platform'], random_state=my_seed)\n",
    "\n",
    "# Assign groups\n",
    "train['group'] = 'control'\n",
    "test['group'] = 'treatment'\n",
    "\n",
    "# Merge and display\n",
    "users = pd.concat([train, test]).sort_values('user_id')\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a72cf",
   "metadata": {},
   "source": [
    "#### Block Randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eda074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define block size (e.g., groups of 10 users)\n",
    "block_size = 10\n",
    "\n",
    "# Assign blocks\n",
    "users['block'] = (users['user_id'] - 1) // block_size\n",
    "\n",
    "# Within each block, randomly assign 50% to control and 50% to treatment\n",
    "users['group'] = users.groupby('block')['user_id'].transform(lambda x: np.random.choice(['control', 'treatment'], size=len(x), replace=True))\n",
    "\n",
    "# Drop the block column after assignment\n",
    "# users = users.drop(columns=['block'])\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628a65bc",
   "metadata": {},
   "source": [
    "#### Match Pair Randomization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7433cc",
   "metadata": {},
   "source": [
    "Participants are paired based on similar characteristics before being randomly assigned to different groups. This ensures that treatment and control groups are balanced on key covariates, reducing variance and improving statistical power.\n",
    "\n",
    "When to Use Matched-Pair Randomization?\n",
    "- When you have a small sample size and need to control for confounders.\n",
    "- When key characteristics (e.g., age, income, purchase history) could influence the outcome.\n",
    "- When you want to minimize variance by ensuring similar individuals are in each group.\n",
    "\n",
    "How It Works:\n",
    "- Identify key variables that might impact the outcome (e.g., age, income, engagement level).\n",
    "- Sort users based on these variables.\n",
    "= Create pairs (or small groups) of users with similar characteristics.\n",
    "- Within each pair, randomly assign one user to treatment and the other to control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881dd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort users by engagement to create pairs\n",
    "users = users.sort_values(by='engagement_score').reset_index(drop=True)\n",
    "\n",
    "# Assign treatment/control in pairs\n",
    "users['group'] = np.where(users.index % 2 == 0, 'control', 'treatment')\n",
    "users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872f04b",
   "metadata": {},
   "source": [
    "#### Cluster Randomization\n",
    "- Assigns whole groups (e.g., entire cities or schools) instead of individuals.\n",
    "- Useful when spillover effects are a concern (e.g., referral programs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fdc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Randomly assign cities to control or treatment\n",
    "unique_cities = users['city'].unique()\n",
    "city_assignments = dict(zip(unique_cities, np.random.choice(['control', 'treatment'], size=len(unique_cities), replace=True)))\n",
    "\n",
    "# Assign users based on their city\n",
    "users['group'] = users['city'].map(city_assignments)\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8419594",
   "metadata": {},
   "source": [
    "#### CUPED\n",
    "- Uses historical data to reduce variance and increase test sensitivity.\n",
    "- Doesn’t change how users are assigned but helps in post-analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ddd000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Randomization\n",
    "users['group'] = np.random.choice(['control', 'treatment'], size=len(users), p=[0.5, 0.5])\n",
    "\n",
    "\n",
    "pre_experiment_metric = 'past_purchase_count'\n",
    "\n",
    "# Compute CUPED adjustment\n",
    "X = users[[pre_experiment_metric]]\n",
    "X = sm.add_constant(X)  # Add intercept\n",
    "y = np.random.normal(loc=0, scale=5, size=observation_count)  # Simulated experiment outcome\n",
    "\n",
    "# Regression to estimate theta (correction factor)\n",
    "theta = sm.OLS(y, X).fit().params[pre_experiment_metric]\n",
    "\n",
    "# Adjust the outcome using pre-experiment data\n",
    "users['adjusted_outcome'] = y - theta * users[pre_experiment_metric]\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73691185",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d61b9",
   "metadata": {},
   "source": [
    "# AA Testing\n",
    "\n",
    "# What specifically are we checking for???????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0f628",
   "metadata": {},
   "source": [
    "A/A testing is an experiment where both groups (control and treatment) receive the **same experience** to ensure that randomization is working correctly. It acts as a **sanity check** before running an A/B test.\n",
    "\n",
    "##### Importance\n",
    "- **Validates Randomization:** Ensures that groups are statistically similar before testing.\n",
    "- **Detects Sample Ratio Mismatch (SRM):** Verifies that user assignment is balanced.\n",
    "- **Estimates Variance for Power Analysis:** Helps understand variability before defining sample size for A/B testing.\n",
    "- **Checks for Pre-Existing Bias:** Ensures no systematic differences exist between control and treatment groups.\n",
    "\n",
    "##### Process\n",
    "- **Randomly assign users** to two equal groups (just like an A/B test).\n",
    "- **Measure key metrics** (e.g., conversion rate, engagement, revenue).\n",
    "- **Perform statistical tests** (e.g., t-test for continuous data, chi-square for categorical data) to confirm no significant difference.\n",
    "- **Analyze Sample Ratio Mismatch (SRM)** to verify even split between groups.\n",
    "\n",
    "##### Result\n",
    "- **No significant difference:** Randomization is working correctly, and the experiment is set up properly.\n",
    "- **Significant difference detected:** Investigate potential issues such as randomization bugs, sample bias, or instrumentation errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a477d4",
   "metadata": {},
   "source": [
    "#### 🧪 When to Use Which Statistical Test in A/B Testing\n",
    "\n",
    "| **Metric Type**        | **Example**                        | **Recommended Test**                      | **Why**                                                  |\n",
    "|------------------------|------------------------------------|-------------------------------------------|-----------------------------------------------------------|\n",
    "| Continuous             | Revenue, time on site, scores      | `scipy.stats.ttest_ind` (T-test)          | Compares means of two independent groups                 |\n",
    "| Continuous (unequal variance) | Same as above               | `ttest_ind(..., equal_var=False)`         | Welch’s T-test — safer when variances differ             |\n",
    "| Binary (0/1 outcomes)  | Conversion, click, purchase        | `statsmodels.stats.proportions_ztest`     | Compares proportions between two groups                  |\n",
    "| Count data             | # pageviews, # items bought        | Poisson or Negative Binomial test         | For skewed count distributions                           |\n",
    "| Non-parametric         | Ordinal/skewed data, NPS scores    | Mann-Whitney U test                       | No assumption of normality                               |\n",
    "| Multiple groups (A/B/C)| Multi-variant tests                | ANOVA (continuous), Chi-squared (binary)  | Tests across 3+ groups                                   |\n",
    "\n",
    "---\n",
    "\n",
    "#### ✅ Quick Rules of Thumb:\n",
    "- If your metric is **continuous + normal-ish** → Use **T-test**\n",
    "- If it’s **binary (e.g., clicked or not)** → Use **Z-test**\n",
    "- If it’s **non-normal or skewed** → Use **Mann-Whitney U test**\n",
    "- If testing **3 or more variants** → Use **ANOVA** or **Chi-squared**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee29032",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(my_seed)\n",
    "\n",
    "# Step 1: Simulate a base population of customers\n",
    "n_customers = 2000\n",
    "population = pd.DataFrame({\n",
    "    'user_id': np.arange(1, n_customers + 1),\n",
    "    'is_eligible': np.random.choice([0, 1], size=n_customers, p=[0.4, 0.6]),  # 60% eligible\n",
    "    'engagement_score': np.random.normal(loc=50, scale=10, size=n_customers)  # some behavioral metric\n",
    "})\n",
    "print(\"population:\\n\")\n",
    "population\n",
    "\n",
    "# Step 2: Filter to eligible population\n",
    "eligible_population = population[population['is_eligible'] == 1].copy()\n",
    "n_eligible = len(eligible_population)\n",
    "\n",
    "# Step 3: Randomly assign eligible users into two groups (A1 and A2)\n",
    "eligible_population['group'] = np.random.choice(['A1', 'A2'], size=n_eligible, replace=True)\n",
    "print(\"eligible_population:\\n\")\n",
    "eligible_population\n",
    "\n",
    "# Step 4: Split into the two groups\n",
    "group_A1 = eligible_population[eligible_population['group'] == 'A1']['engagement_score']\n",
    "group_A2 = eligible_population[eligible_population['group'] == 'A2']['engagement_score']\n",
    "print(\"group_A1, group_A2:\\n\")\n",
    "print(group_A1.head())\n",
    "print(group_A2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba07388",
   "metadata": {},
   "source": [
    "## SRM Check \n",
    "Is group assignment balanced?\n",
    "\n",
    "- 🔍 SRM (Sample Ratio Mismatch) checks whether the observed group sizes match the expected ratio.\n",
    "- In a perfect world, random assignment to 'A1' and 'A2' should give ~50/50 split.\n",
    "- SRM helps catch bugs in randomization, data logging, or user eligibility filtering.\n",
    "\n",
    "🎯 Real-World Experiment Split Ratios\n",
    "\n",
    "| **Scenario**                     | **Split**              | **Why**                                 |\n",
    "|----------------------------------|------------------------|------------------------------------------|\n",
    "| Default A/B                      | 50 / 50                | Maximizes power and ensures fairness     |\n",
    "| Risky feature                    | 10 / 90 or 20 / 80     | Limits user exposure to minimize risk    |\n",
    "| Ramp-up                          | Step-wise (1-5-25-50…) | Gradual rollout to catch issues early    |\n",
    "| A/B/C Test                       | 33 / 33 / 33 or weighted | Compare multiple variants fairly or with bias |\n",
    "| High control confidence needed   | 70 / 30 or 60 / 40     | More stability in baseline comparisons   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_counts = eligible_population['group'].value_counts().sort_index()\n",
    "expected_counts = [n_eligible / 2, n_eligible / 2]\n",
    "\n",
    "# Print observed counts and percentages\n",
    "print(\"\\n📊 Group Assignment Breakdown\")\n",
    "for group in observed_counts.index:\n",
    "    count = observed_counts[group]\n",
    "    pct = count / n_eligible * 100\n",
    "    print(f\"Group {group}: {count} users ({pct:.2f}%)\")\n",
    "    \n",
    "# Chi-Square Goodness of Fit Test\n",
    "chi2_stat, chi2_p = stats.chisquare(f_obs=observed_counts, f_exp=expected_counts)\n",
    "\n",
    "print(\"\\n🔍 SRM Check\")\n",
    "print(f\"Chi2 Stat: {chi2_stat:.4f}\")\n",
    "print(f\"P-value : {chi2_p:.4f}\")\n",
    "if chi2_p < 0.05:\n",
    "    print(\"⚠️ Sample Ratio Mismatch detected — investigate assignment logic.\")\n",
    "else:\n",
    "    print(\"✅ No SRM — group assignment is balanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b97c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Run 2-sample (independent) t-test\n",
    "t_stat, p_value = stats.ttest_ind(group_A1, group_A2)\n",
    "\n",
    "print(f\"\\nT-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"⚠️ Statistically significant difference found — check randomization.\")\n",
    "else:\n",
    "    print(\"✅ No significant difference — randomization looks good.\")\n",
    "\n",
    "# Step 7: Visualize distributions\n",
    "plt.hist(group_A1, bins=30, alpha=0.5, label='Group A1');\n",
    "plt.hist(group_A2, bins=30, alpha=0.5, label='Group A2');\n",
    "plt.title('AA Test: Distribution Comparison');\n",
    "plt.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48617f5",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f238b7a7",
   "metadata": {},
   "source": [
    "# Power Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860c5e4",
   "metadata": {},
   "source": [
    "Power analysis helps determine the **minimum sample size** needed to detect an expected effect with statistical confidence.\n",
    "\n",
    "`Why It Matters:`\n",
    "- Avoids **underpowered** tests (can't detect real differences)\n",
    "- Avoids **overpowered** tests (wastes resources)\n",
    "- Balances tradeoffs between **sample size**, **effect size**, **confidence level**, and **statistical power**\n",
    "\n",
    "`Key Inputs:`\n",
    "- **alpha (α):** Significance level (probability of Type I error, usually 0.05)\n",
    "- **Power (1 - β):** Probability of detecting a true effect (commonly 0.80 or 0.90)\n",
    "- **Baseline conversion rate:** Current performance (e.g., 10%)\n",
    "- **Minimum Detectable Effect (MDE):** Smallest lift you care to detect (e.g., +2%)\n",
    "\n",
    "We use a two-sample z-test for proportions to estimate sample size per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38526dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(alpha, power, baseline_rate, mde):\n",
    "    \"\"\"\n",
    "    Calculate the sample size required for each group in an A/B test.\n",
    "    \n",
    "    Parameters:\n",
    "    - alpha: Significance level (e.g., 0.05)\n",
    "    - power: Desired power (e.g., 0.80)\n",
    "    - baseline_rate: Baseline conversion rate (as a proportion, e.g., 0.10)\n",
    "    - mde: Minimum Detectable Effect (as a proportion, e.g., 0.02 for +2%)\n",
    "\n",
    "    Returns:\n",
    "    - Sample size per group\n",
    "    \"\"\"\n",
    "    # Z-scores\n",
    "    z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
    "    z_beta = stats.norm.ppf(power)\n",
    "\n",
    "    # Pooled standard error\n",
    "    pooled_std = np.sqrt(\n",
    "        2 * baseline_rate * (1 - baseline_rate) + \n",
    "        mde**2 / 2  # adjustment for effect size difference\n",
    "    )\n",
    "\n",
    "    # Sample size formula\n",
    "    n = ((z_alpha + z_beta)**2 * 2 * baseline_rate * (1 - baseline_rate)) / (mde**2)\n",
    "    return int(np.ceil(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef00a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "alpha = 0.05\n",
    "power = 0.80\n",
    "baseline_rate = 0.10  # 10% baseline conversion\n",
    "mde = 0.02            # 2% lift\n",
    "\n",
    "required_sample_size = calculate_sample_size(alpha, power, baseline_rate, mde)\n",
    "\n",
    "# Conclusions\n",
    "print(\"📈 Power Analysis Summary\")\n",
    "print(f\"- Baseline conversion rate: {baseline_rate}\")\n",
    "print(f\"- Minimum detectable effect (MDE): {mde}\")\n",
    "print(f\"- Target conversion rate: {(baseline_rate + mde):.2f}\")\n",
    "print(f\"- Significance level (α): {alpha}\")\n",
    "print(f\"- Statistical power (1 - β): {power}\")\n",
    "\n",
    "print(f\"\\n✅ Result:\")\n",
    "print(f\"To detect a lift from {baseline_rate} to {(baseline_rate + mde):.2f} with\")\n",
    "print(f\"{power*100:.0f}% power and {alpha*100:.0f}% significance level,\")\n",
    "print(f\"you need at least {required_sample_size} users in each group (control and treatment).\")\n",
    "print(f\"Total required sample size: {required_sample_size * 2} users.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e3add",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e68463",
   "metadata": {},
   "source": [
    "# AB Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cb41c7",
   "metadata": {},
   "source": [
    "### 🛠️ Metric Tracked:\n",
    "- **Primary metric:** Conversion rate (binary: clicked = 1, did not click = 0)\n",
    "- **Unit of analysis:** Unique user\n",
    "\n",
    "---\n",
    "\n",
    "#### 📈 Outcome Analysis Plan:\n",
    "- Two-sample **z-test for proportions** to compare conversion rates\n",
    "- Compute confidence intervals and p-values\n",
    "- Optional: visualizations of effect size and confidence bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(my_seed)\n",
    "\n",
    "# Step 1: Simulate eligible population\n",
    "n = 7064  # from power analysis\n",
    "users = pd.DataFrame({\n",
    "    'user_id': np.arange(1, n + 1),\n",
    "})\n",
    "\n",
    "# Step 2: Randomly assign users to control or treatment\n",
    "users['group'] = np.random.choice(['control', 'treatment'], size=n, replace=True)\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e7c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Simulate conversions\n",
    "# Assume baseline = 0.10, treatment = 0.12\n",
    "conversion_rate = {\n",
    "    'control': 0.10,\n",
    "    'treatment': 0.12\n",
    "}\n",
    "users['converted'] = users['group'].apply(lambda g: np.random.binomial(1, conversion_rate[g]))\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3611da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: View summary\n",
    "summary = users.groupby('group')['converted'].agg(['count', 'sum', 'mean']).rename(columns={\n",
    "    'count': 'n_users',\n",
    "    'sum': 'n_converted',\n",
    "    'mean': 'conversion_rate'\n",
    "})\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25456943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Run 2-proportion z-test\n",
    "control_conv = summary.loc['control', 'conversion_rate']\n",
    "treatment_conv = summary.loc['treatment', 'conversion_rate']\n",
    "n_control = summary.loc['control', 'n_users']\n",
    "n_treatment = summary.loc['treatment', 'n_users']\n",
    "x_control = summary.loc['control', 'n_converted']\n",
    "x_treatment = summary.loc['treatment', 'n_converted']\n",
    "\n",
    "# Pooled conversion rate\n",
    "p_pooled = (x_control + x_treatment) / (n_control + n_treatment)\n",
    "se_pooled = np.sqrt(p_pooled * (1 - p_pooled) * (1/n_control + 1/n_treatment))\n",
    "\n",
    "z_stat = (treatment_conv - control_conv) / se_pooled\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f10423",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d6dc29",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab688c",
   "metadata": {},
   "source": [
    "#### Conversion Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310c97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"\\n📊 Z-Test Results\")\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value    : {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"✅ Statistically significant difference detected.\")\n",
    "else:\n",
    "    print(\"🚫 No significant difference detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d108e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already generated in earlier step, but good to reinforce\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe451b",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d648a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(['Control', 'Treatment'],\n",
    "              [control_conv, treatment_conv],\n",
    "              color=['gray', 'skyblue'])\n",
    "\n",
    "# Add values on top\n",
    "for bar in bars:\n",
    "    height = bar.get_height();\n",
    "    ax.annotate(f'{height:.4f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 5),  # vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom');\n",
    "ax.set_ylabel('Conversion Rate');\n",
    "ax.set_title('A/B Test: Conversion Rate by Group');\n",
    "ax.set_ylim(0, max(control_conv, treatment_conv) + 0.02);\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772d796",
   "metadata": {},
   "source": [
    "#### 95% Confidence Intervals (`outcome of group`)\n",
    "\n",
    "- The 95% confidence interval gives a range in which we expect the **true conversion rate** to fall for each group.\n",
    "- If the confidence intervals **do not overlap**, it's strong evidence that the difference is statistically significant.\n",
    "- If they **do overlap**, it doesn't guarantee insignificance — you still need the p-value to decide — but it suggests caution when interpreting lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confidence intervals\n",
    "def compute_ci(p, n, z=1.96):\n",
    "    se = np.sqrt(p * (1 - p) / n)\n",
    "    return (p - z*se, p + z*se)\n",
    "\n",
    "ci_control = compute_ci(control_conv, n_control)\n",
    "ci_treatment = compute_ci(treatment_conv, n_treatment)\n",
    "\n",
    "# Plot with error bars\n",
    "plt.errorbar(['Control', 'Treatment'],\n",
    "             [control_conv, treatment_conv],\n",
    "             yerr=[[control_conv - ci_control[0], treatment_conv - ci_treatment[0]],\n",
    "                   [ci_control[1] - control_conv, ci_treatment[1] - treatment_conv]],\n",
    "             fmt='o', capsize=10, color='black')\n",
    "plt.ylabel('Conversion Rate');\n",
    "plt.title('Conversion Rate with 95% Confidence Intervals');\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8be8b",
   "metadata": {},
   "source": [
    "#### 95% Confidence Intervals (`difference in outcomes`). AKA `Lift Analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute lift\n",
    "lift = treatment_conv - control_conv\n",
    "\n",
    "# Standard error for the difference in proportions\n",
    "se_diff = np.sqrt(\n",
    "    (control_conv * (1 - control_conv) / n_control) +\n",
    "    (treatment_conv * (1 - treatment_conv) / n_treatment)\n",
    ")\n",
    "\n",
    "# 95% Confidence Interval for the lift\n",
    "z = 1.96  # for 95%\n",
    "ci_lower = lift - z * se_diff\n",
    "ci_upper = lift + z * se_diff\n",
    "\n",
    "# Print result\n",
    "print(\"📈 Lift Analysis\")\n",
    "print(f\"- Absolute Lift: {lift:.4f}\")\n",
    "print(f\"- 95% Confidence Interval for Lift: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "\n",
    "# Interpretation\n",
    "if ci_lower > 0:\n",
    "    print(\"✅ We're 95% confident the new version improved conversion.\")\n",
    "elif ci_upper < 0:\n",
    "    print(\"🚫 We're 95% confident the new version hurt conversion.\")\n",
    "else:\n",
    "    print(\"🤷 The confidence interval includes 0 — we can't say the lift is statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba669a",
   "metadata": {},
   "source": [
    "#### Final Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf90d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\" + \"=\"*40)\n",
    "print(\"          📊FINAL A/B TEST SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(f\"👥  Control conversion rate   :  {control_conv:.4f}\")\n",
    "print(f\"🧪  Treatment conversion rate :  {treatment_conv:.4f}\")\n",
    "print(f\"📈  Absolute lift             :  {(treatment_conv - control_conv):.4f}\")\n",
    "print(f\"📊  Percentage lift           :  {((treatment_conv - control_conv)/control_conv):.2%}\")\n",
    "print(f\"🧪  P-value (from z-test)     :  {p_value:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"✅  RESULT: Statistically significant improvement detected.\")\n",
    "else:\n",
    "    print(\"❌  RESULT: No statistically significant difference detected.\")\n",
    "\n",
    "print(\"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0457202f",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dca748",
   "metadata": {},
   "source": [
    "# How Long\n",
    "##### to run the test?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24419d96",
   "metadata": {},
   "source": [
    "The runtime of an A/B test depends on how quickly you can reach the required **sample size per group**, as estimated during power analysis.\n",
    "\n",
    "##### Key Inputs:\n",
    "- ✅ Daily eligible traffic volume\n",
    "- ✅ Required sample size (from power analysis)\n",
    "- ✅ Whether traffic is split 50/50 or unevenly\n",
    "\n",
    "##### Formula:\n",
    "> **Days = Required Sample Size per Group / (Daily Eligible Users × Group Split Proportion)**\n",
    "\n",
    "This ensures the experiment runs **long enough to detect the effect** with the desired statistical confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e721e86",
   "metadata": {},
   "source": [
    "##### ⏳ How Long to Run an A/B Test — Real-World Guide\n",
    "\n",
    "1. **Estimate sample size** needed (done via power analysis)\n",
    "2. **Understand your traffic** — how many eligible users per day?\n",
    "3. **Factor in group split** — if it's 50/50, each group gets half the traffic\n",
    "4. **Divide required sample per group by daily users per group** to estimate days\n",
    "\n",
    "---\n",
    "\n",
    "##### 💡 Real-World Recommendations\n",
    "\n",
    "- ✅ **Ramp-Up Period**: Don’t go full traffic on Day 1. Start with 5%, then 25%, then 50% over 2–3 days. This is safer and helps catch bugs early.\n",
    "  \n",
    "- ✅ **Cool-Down Buffer**: Let the test stabilize before analysis. Avoid cutting off during weekends or anomalies.\n",
    "  \n",
    "- ✅ **Trust Checks**:\n",
    "  - Run an **A/A test first** to validate setup\n",
    "  - Do an **SRM check** to confirm assignment balance\n",
    "  - Monitor **guardrail metrics** (e.g., bounce rate, latency)\n",
    "\n",
    "- ⏳ Add **1–2 buffer days** for these. It’s not just about stats — it’s about reliability and business trust.\n",
    "\n",
    "---\n",
    "\n",
    "##### 🧠 Tip\n",
    "> “We typically recommend calculating sample size from power analysis, then dividing by daily traffic per variant. But we also factor in buffer days for ramp-up, trust checks, and traffic noise — just to make sure we don’t rush analysis before data is stable.”\n",
    "\n",
    "> “We use power analysis to plan — it gives stakeholders a timeline and sets expectations.\n",
    "But we don’t blindly stop based on sample size. I monitor SRM, metric stability, cohort coverage, and confidence intervals before making the call. We want decisions that are trustworthy, not just statistically complete.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_total_test_duration(required_sample_size_per_group, daily_eligible_users, allocation_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Estimate total days needed to complete an A/B test for both groups.\n",
    "\n",
    "    Parameters:\n",
    "    - required_sample_size_per_group: int, sample size needed per group (from power analysis)\n",
    "    - daily_eligible_users: int, total eligible users arriving each day\n",
    "    - allocation_ratio: float, proportion of traffic sent to each group (e.g., 0.5 for 50/50)\n",
    "\n",
    "    Returns:\n",
    "    - Estimated total number of days to complete both groups\n",
    "    \"\"\"\n",
    "    # Max group load per day (assuming symmetric or asymmetric allocation)\n",
    "    daily_users_per_group = daily_eligible_users * allocation_ratio\n",
    "    days_needed = required_sample_size_per_group / daily_users_per_group\n",
    "\n",
    "    return int(np.ceil(days_needed))\n",
    "\n",
    "# Example Usage\n",
    "required_sample = 3532\n",
    "daily_users = 10000\n",
    "allocation = 0.5  # 50% of users per group\n",
    "\n",
    "total_days = estimate_total_test_duration(required_sample, daily_users, allocation)\n",
    "buffer_days = 2  # For ramp-up, cool-down, or traffic anomalies\n",
    "\n",
    "print(f\"📅 Estimated minimum duration per group : {total_days} days\")\n",
    "print(f\"📦 Add buffer (ramp-up, weekends, trust checks): {buffer_days} days\")\n",
    "print(f\"🧮 Total recommended runtime             : {total_days + buffer_days} days\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5851f1e",
   "metadata": {},
   "source": [
    "#### Monitoring Dashboard\n",
    "- Guardrails\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e17a8c",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ce892",
   "metadata": {},
   "source": [
    "# Post Hoc Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6554534",
   "metadata": {},
   "source": [
    "> 🔍 After statistical significance, we do a post-hoc dive. We check for lift by user segment, inspect guardrail metrics, and simulate rollout impact. This turns A/B tests into real product decisions.\n",
    "\n",
    "Post-hoc analysis helps interpret test results **beyond the primary metric**, and answer key follow-up questions like:\n",
    "- Did the effect differ by segment (e.g. platform, user type)?\n",
    "- Were any guardrail metrics negatively impacted?\n",
    "- What does the lift mean in terms of actual revenue or conversions?\n",
    "- What happens if we roll this out 100%?\n",
    "\n",
    "This step helps turn **statistical significance into business confidence.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aad359",
   "metadata": {},
   "source": [
    "#### Segmented Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a few realistic segmentation features to the users DataFrame\n",
    "# (e.g., platform, device_type, user_tier, region)\n",
    "\n",
    "np.random.seed(my_seed)  # for reproducibility\n",
    "\n",
    "users['platform'] = np.random.choice(['iOS', 'Android'], size=len(users))\n",
    "users['device_type'] = np.random.choice(['mobile', 'desktop'], size=len(users), p=[0.7, 0.3])\n",
    "users['user_tier'] = np.random.choice(['new', 'returning'], size=len(users), p=[0.4, 0.6])\n",
    "users['region'] = np.random.choice(['North', 'South', 'East', 'West'], size=len(users))\n",
    "\n",
    "# Return a preview of the updated DataFrame\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e71bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmented_lift_analysis(df, segment_cols, outcome_col='converted'):\n",
    "    for segment in segment_cols:\n",
    "        print(f\"\\n📊 Segment: {segment}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # 1. Aggregate conversion metrics\n",
    "        grouped = df.groupby([segment, 'group'])[outcome_col].agg(['count', 'sum', 'mean']).reset_index()\n",
    "        grouped.columns = [segment, 'group', 'n_users', 'n_converted', 'conversion_rate']\n",
    "\n",
    "        # 2. Pivot to calculate absolute and percentage lift\n",
    "        pivoted = grouped.pivot(index=segment, columns='group', values='conversion_rate').reset_index()\n",
    "        pivoted['absolute_lift'] = pivoted['treatment'] - pivoted['control']\n",
    "        pivoted['percentage_lift'] = pivoted['absolute_lift'] / pivoted['control']\n",
    "        print(pivoted[[segment, 'control', 'treatment', 'absolute_lift', 'percentage_lift']].to_string(index=False))\n",
    "\n",
    "        # 3. Plot\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        ax = sns.barplot(data=grouped, x=segment, y='conversion_rate', hue='group')\n",
    "\n",
    "        # 4. Add value labels\n",
    "        for bar in ax.patches:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f\"{height:.3f}\", \n",
    "                        (bar.get_x() + bar.get_width() / 2, height + 0.005),\n",
    "                        ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "        # 5. Style tweaks — fixed layout\n",
    "        ax.set_title(f'Conversion Rate by {segment} and Group', pad=15)\n",
    "        ax.set_ylabel('Conversion Rate')\n",
    "        ax.set_xlabel(segment)\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        ax.set_ylim(0, grouped['conversion_rate'].max() + 0.05)\n",
    "\n",
    "        # 👇 FIXED LEGEND POSITION\n",
    "        ax.legend(\n",
    "            # title='Group', \n",
    "            loc='upper right', \n",
    "            fontsize='small', \n",
    "            title_fontsize='small',\n",
    "            frameon=True,\n",
    "            borderpad=0.5)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e98f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "segmented_columns = ['platform', 'device_type', 'user_tier', 'region']\n",
    "segmented_lift_analysis(users, segmented_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e932f50",
   "metadata": {},
   "source": [
    "#### Guardrail Metric Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3384edde",
   "metadata": {},
   "source": [
    "Guardrail metrics are **non-primary metrics** that help ensure an experiment isn't causing unintended harm.\n",
    "\n",
    "We monitor them alongside the main success metric to:\n",
    "- Detect regressions in user experience or system performance\n",
    "- Catch trade-offs early (e.g., improved conversions but worse bounce rate)\n",
    "\n",
    "---\n",
    "\n",
    "📊 Common Guardrail Metrics\n",
    "- Bounce Rate — did the experience frustrate users?\n",
    "- Page Load Time / Latency — did the feature slow down the UI?\n",
    "- Session Length / Engagement — did users stick around?\n",
    "- Error Rate — did the experiment introduce bugs?\n",
    "\n",
    "---\n",
    "\n",
    "✅ When to Act:\n",
    "- If the **treatment worsens a guardrail metric**, even if the primary metric improved → we pause, investigate, or reject the rollout.\n",
    "Guardrails aren’t always deal-breakers, but they’re **trust checks** that make A/B test results *safe* to act on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a simulated guardrail metric: bounce_rate (continuous between 0.1 and 0.9)\n",
    "# Bounce rate is typically higher when users disengage quickly\n",
    "\n",
    "np.random.seed(my_seed)\n",
    "users['bounce_rate'] = np.where(\n",
    "    users['converted'] == 1,\n",
    "    np.random.normal(loc=0.2, scale=0.05, size=len(users)),  # lower bounce if converted\n",
    "    np.random.normal(loc=0.6, scale=0.1, size=len(users))   # higher bounce if not\n",
    ")\n",
    "\n",
    "# Clip to stay between 0 and 1\n",
    "users['bounce_rate'] = users['bounce_rate'].clip(0, 1)\n",
    "\n",
    "# Return sample for inspection\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example if you had bounce_rate as a column:\n",
    "guardrail = users.groupby('group')['bounce_rate'].mean()\n",
    "print(\"🚦 Average Bounce Rate by Group:\")\n",
    "print(guardrail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group means\n",
    "bounce_by_group = users.groupby('group')['bounce_rate'].mean()\n",
    "bounce_diff = bounce_by_group['treatment'] - bounce_by_group['control']\n",
    "\n",
    "# 2. Optional statistical test (t-test)\n",
    "control_bounce = users[users['group'] == 'control']['bounce_rate']\n",
    "treatment_bounce = users[users['group'] == 'treatment']['bounce_rate']\n",
    "t_stat, p_val = ttest_ind(treatment_bounce, control_bounce)\n",
    "\n",
    "# 3. Print summary and conclusion\n",
    "print(\"🚦 Guardrail Check\")\n",
    "print(f\"- Control  : {bounce_by_group['control']:.4f}\")\n",
    "print(f\"- Treatment: {bounce_by_group['treatment']:.4f}\")\n",
    "print(f\"- Difference: {bounce_diff:+.4f}\")\n",
    "print(f\"- P-value (t-test): {p_val:.4f}\")\n",
    "\n",
    "# 4. Conclusion\n",
    "if p_val < 0.05:\n",
    "    if bounce_diff > 0:\n",
    "        print(\"❌ Statistically significant *increase* in bounce rate — potential UX regression.\")\n",
    "    else:\n",
    "        print(\"✅ Statistically significant *decrease* in bounce rate — UX may have improved.\")\n",
    "else:\n",
    "    print(\"🟡 No significant change in bounce rate — guardrail looks stable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0e6a5",
   "metadata": {},
   "source": [
    "#### Rollout Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc441e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume full exposure to daily_eligible_users\n",
    "daily_impact = (treatment_conv - control_conv) * daily_eligible_users\n",
    "monthly_impact = daily_impact * 30\n",
    "\n",
    "print(f\"📈 Estimated additional conversions per day: {daily_impact:.0f}\")\n",
    "print(f\"📈 Estimated additional conversions per month: {monthly_impact:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87d394",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16893894",
   "metadata": {},
   "source": [
    "# Scratch Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "n_control = 5000  # Sample size for control group\n",
    "n_treatment = 5000  # Sample size for treatment group\n",
    "\n",
    "# Assume conversion rate is 10% for control and 12% for treatment\n",
    "control_conversions = np.random.binomial(1, 0.10, n_control)\n",
    "treatment_conversions = np.random.binomial(1, 0.12, n_treatment)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'group': ['control'] * n_control + ['treatment'] * n_treatment,\n",
    "    'conversion': np.concatenate([control_conversions, treatment_conversions])\n",
    "})\n",
    "df.head()\n",
    "df.shape\n",
    "\n",
    "# Display summary\n",
    "df.groupby('group')['conversion'].agg(['mean', 'count', 'sum'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b4e4c",
   "metadata": {},
   "source": [
    "#### AB Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b4d57",
   "metadata": {},
   "source": [
    "1. Chi-Square Test (Categorical Data - Conversion Rates)     \n",
    "Used when testing differences in proportions (e.g., conversion rate increase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contingency table\n",
    "conversion_table = pd.crosstab(df['group'], df['conversion'])\n",
    "\n",
    "# Chi-Square Test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(conversion_table)\n",
    "\n",
    "# Print results\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")\n",
    "\n",
    "# Check significance\n",
    "alpha = 0.05  # 95% confidence level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: Significant difference detected.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff20b9a4",
   "metadata": {},
   "source": [
    "2. Independent T-Test (Continuous Data - Avg. Time Spent, Revenue)    \n",
    "Used when comparing means of continuous data between two independent groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform independent t-test\n",
    "t_stat, p_val = ttest_ind(control_conversions, treatment_conversions)\n",
    "\n",
    "print(f\"T-Statistic: {t_stat:.4f}\")\n",
    "print(f\"P-Value: {p_val:.4f}\")\n",
    "\n",
    "if p_val < alpha:\n",
    "    print(\"Reject the null hypothesis: The new feature has a significant effect.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e340824",
   "metadata": {},
   "source": [
    "3. Paired T-Test (Before/After Tests - Same Users)    \n",
    "Used when measuring differences within the same group (e.g., before vs. after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: User engagement before & after a UI change\n",
    "before = np.random.normal(200, 25, 100)  # Mean 200 sec, std dev 25\n",
    "after = np.random.normal(210, 25, 100)  # Mean 210 sec, std dev 25\n",
    "\n",
    "t_stat, p_val = ttest_rel(before, after)\n",
    "\n",
    "print(f\"Paired T-Test Statistic: {t_stat:.4f}\")\n",
    "print(f\"P-Value: {p_val:.4f}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"Significant difference detected.\")\n",
    "else:\n",
    "    print(\"No significant difference detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e055e0f8",
   "metadata": {},
   "source": [
    "4. Mann-Whitney U Test (Non-Normal Continuous Data)\n",
    "A non-parametric test used when data isn’t normally distributed (e.g., skewed revenue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Revenue data (skewed distribution)\n",
    "control_revenue = np.random.exponential(50, 5000)  # Skewed\n",
    "treatment_revenue = np.random.exponential(55, 5000)  # Skewed\n",
    "\n",
    "u_stat, p_val = mannwhitneyu(control_revenue, treatment_revenue)\n",
    "\n",
    "print(f\"Mann-Whitney U Statistic: {u_stat:.4f}\")\n",
    "print(f\"P-Value: {p_val:.4f}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"Significant difference detected.\")\n",
    "else:\n",
    "    print(\"No significant difference detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1fad0a",
   "metadata": {},
   "source": [
    " 5. Bayesian A/B Testing (Alternative Approach)    \n",
    "Instead of p-values, Bayesian A/B testing provides posterior probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymc3 as pm\n",
    "\n",
    "# # Simulated conversion data\n",
    "# control_conversions = np.sum(np.random.binomial(1, 0.10, 5000))\n",
    "# treatment_conversions = np.sum(np.random.binomial(1, 0.12, 5000))\n",
    "\n",
    "# with pm.Model():\n",
    "#     control_rate = pm.Beta(\"control_rate\", alpha=1, beta=1)\n",
    "#     treatment_rate = pm.Beta(\"treatment_rate\", alpha=1, beta=1)\n",
    "\n",
    "#     # Priors\n",
    "#     control = pm.Binomial(\"control\", n=5000, p=control_rate, observed=control_conversions)\n",
    "#     treatment = pm.Binomial(\"treatment\", n=5000, p=treatment_rate, observed=treatment_conversions)\n",
    "\n",
    "#     trace = pm.sample(2000, return_inferencedata=True)\n",
    "\n",
    "# # Compute probability that the treatment is better\n",
    "# prob_treatment_better = (trace.posterior[\"treatment_rate\"] > trace.posterior[\"control_rate\"]).mean().item()\n",
    "\n",
    "# print(f\"Probability that the treatment is better: {prob_treatment_better:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552361b0",
   "metadata": {},
   "source": [
    "6. Power Analysis (How Much Data Do You Need?)\n",
    "Used to determine sample size before running an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "effect_size = 0.02  # Expected lift in conversion rate\n",
    "alpha = 0.05  # Significance level\n",
    "power = 0.8  # Desired statistical power\n",
    "\n",
    "# Compute sample size per group\n",
    "analysis = TTestIndPower()\n",
    "sample_size = analysis.solve_power(effect_size, power=power, alpha=alpha, ratio=1)\n",
    "\n",
    "print(f\"Required Sample Size per Group: {int(sample_size)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58b5a3",
   "metadata": {},
   "source": [
    "# Other Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474d439",
   "metadata": {},
   "source": [
    "### Experimentation Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7cf4d",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
