{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf94292f",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- [Data-Setup](#Data-Setup)\n",
    "- [Randomization Methods](#Randomization-Methods)\n",
    "- [AA Testing](#AA-Testing)\n",
    "    - [SRM Check](#SRM-Check)\n",
    "- [Power Analysis](#Power-Analysis)\n",
    "- [AB Testing](#AB-Testing)\n",
    "    - [Definitions](#Definitions)\n",
    "    - [Results Summary](#Results-Summary)\n",
    "    - [Test](#Test)\n",
    "- [How Long](#How-Long)\n",
    "- [Results](#Results)\n",
    "    - [Summary](#Conversion-Rates)\n",
    "    - [Visualization](#Visualization)\n",
    "    - [Confidence Intervals Within Groups](#Confidence-Intervals-Outcomes)\n",
    "    - [Confidence Intervals Across Groups](#Confidence-Intervals-Difference)\n",
    "    - [Conclusion](#Conclusion)\n",
    "- [Post Hoc Analysis](#Post-Hoc-Analysis)\n",
    "    - [Segmented Lift](#Segmented-Lift)\n",
    "    - [Gaurdrail Metrics](#Gaurdrail-Metrics)\n",
    "    - [Rollout Simulation](#Rollout-Simulation)\n",
    "- [Other Notes](#Other-Notes)\n",
    "    - [Experimentation-Infrastructure](#Experimentation-Infrastructure)\n",
    "- [Scratch Notes](#Scratch-Notes)\n",
    "    - [Other Use Cases](#Other-Use-Cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a36564",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>üß™ A/B Test - Decision Flow (click to expand)</strong></summary>\n",
    "\n",
    "```\n",
    "[What is your outcome type?]  \n",
    "   |  \n",
    "   +--> Binary (e.g., converted = 1 or 0, clicked or not)  \n",
    "   |     |  \n",
    "   |     +--> What are you comparing?  \n",
    "   |           |  \n",
    "   |           +--> Proportions (e.g., 10% vs 12% conversion rate)  \n",
    "   |           |     |  \n",
    "   |           |     +--> Comparing 2 groups ---------> Use Z-test  \n",
    "   |           |     |                                 Compares success rates (proportions) between 2 groups  \n",
    "   |           |     +--> Comparing 3+ groups --------> Use Chi-Square Test  \n",
    "   |           |                                       Tests whether at least one group‚Äôs success rate differs; follow with pairwise Z-tests  \n",
    "   |           +--> Counts (e.g., number of users who converted)  \n",
    "   |                 +--> Comparing 2 groups ---------> Use Chi-Square Test  \n",
    "   |                 +--> Comparing 3+ groups --------> Use Chi-Square Test  \n",
    "   |  \n",
    "   +--> Continuous (e.g., revenue, time spent, items bought)  \n",
    "   |     +--> Comparing 2 groups  \n",
    "   |     |     +--> Are the groups made of different users?  \n",
    "   |     |           +--> Yes  \n",
    "   |     |           |     +--> Is the outcome roughly normal?  \n",
    "   |     |           |           +--> Yes ------------> Use Independent T-test  \n",
    "   |     |           |           +--> No -------------> Use Mann-Whitney U Test  \n",
    "   |     |           +--> No (same users before/after)  \n",
    "   |     |                 +--> Is the outcome roughly normal?  \n",
    "   |     |                       +--> Yes ------------> Use Paired T-test  \n",
    "   |     |                       +--> No -------------> Use Wilcoxon Signed-Rank Test  \n",
    "   |     +--> Comparing 3+ groups --------------------> Use ANOVA  \n",
    "   |  \n",
    "   +--> Categorical (e.g., selected A/B/C option)  \n",
    "         +--> Comparing 2 or more groups -------------> Use Chi-Square Test  \n",
    "\n",
    "[Other Scenarios]  \n",
    "   +--> Want to control for other variables? ---------> Use Regression (Linear or Logistic)  \n",
    "   +--> Prefer probability over p-values? ------------> Use Bayesian A/B Testing  \n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3568002b",
   "metadata": {},
   "source": [
    "<details> <summary><strong>üìä A/B Test - Decision Flow Flattened Table (click to expand) </strong></summary>\n",
    "    \n",
    "| Outcome Type | What Are You Comparing?          | Group Count | Group Structure | Outcome Distribution | Statistical Test        | What It Does                                             | Example Problem Statement |\n",
    "|--------------|----------------------------------|-------------|------------------|-----------------------|--------------------------|----------------------------------------------------------|----------------------------|\n",
    "| Binary        | Proportions (% converted)        | 2           | Independent      | N/A                   | Z-test                   | Compares proportions between 2 groups                    | Does the new homepage increase conversion from 10% to 12%? |\n",
    "| Binary        | Proportions                      | 3+          | Independent      | N/A                   | Chi-Square               | Tests if at least one group‚Äôs conversion rate differs    | Is there a significant difference in conversion across blue/orange/green CTA? |\n",
    "| Binary        | Counts (e.g., #converted users)  | 2           | Independent      | N/A                   | Chi-Square               | Compares success/failure counts between groups           | Did 120 out of 1000 in group A convert vs 150 out of 1000 in group B? |\n",
    "| Binary        | Counts                           | 3+          | Independent      | N/A                   | Chi-Square               | Compares categorical counts across multiple groups       | Do different signup flows lead to different conversion counts? |\n",
    "| Continuous    | Mean of a metric (e.g., revenue) | 2           | Independent      | Normal                | Independent T-test       | Compares average outcome across 2 independent groups     | Does average order value differ between control and treatment? |\n",
    "| Continuous    | Mean of a metric                 | 2           | Independent      | Not normal            | Mann-Whitney U           | Compares ranks/distributions between 2 independent groups| Is time-on-site higher in treatment group (skewed data)? |\n",
    "| Continuous    | Before vs After (same users)     | 2           | Paired           | Normal                | Paired T-test            | Compares mean change for same users before and after     | Did users spend more on their second visit after UI update? |\n",
    "| Continuous    | Before vs After (same users)     | 2           | Paired           | Not normal            | Wilcoxon Signed-Rank     | Compares paired non-normal outcomes                      | Did session duration increase for the same users post-change? |\n",
    "| Continuous    | Mean outcome                     | 3+          | Independent      | Any                   | ANOVA                    | Compares means across 3 or more groups                   | Does average basket size differ across A/B/C pricing variants? |\n",
    "| Categorical   | User-selected categories         | 2+          | Independent      | N/A                   | Chi-Square               | Tests distribution of categories across groups           | Do users pick different plans (Basic, Pro, Premium) across test groups? |\n",
    "| Any           | Adjusting for other variables    | Any         | Any              | N/A                   | Regression (Linear/Logistic) | Measures treatment effect while controlling for covariates | Is treatment still effective after accounting for device and region? |\n",
    "| Any           | Prefer probability > p-value     | Any         | Any              | N/A                   | Bayesian A/B Test        | Returns probability one group is better than the other   | What‚Äôs the probability green button outperforms blue? |\n",
    "| Binary (Paired) | Conversion before vs after (same users) | 2     | Paired           | N/A                   | McNemar‚Äôs Test           | Tests change in conversion for same users                | Did logged-in users convert more after design change? |  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae43f8",
   "metadata": {},
   "source": [
    "<details> <summary><strong>üìä When to Use Which Statistical Test in A/B Testing </strong></summary>\n",
    "\n",
    "#### üß™ When to Use Which Statistical Test in A/B Testing\n",
    "\n",
    "| **Metric Type**        | **Example**                        | **Recommended Test**                      | **Why**                                                  |\n",
    "|------------------------|------------------------------------|-------------------------------------------|-----------------------------------------------------------|\n",
    "| Continuous             | Revenue, time on site, scores      | `scipy.stats.ttest_ind` (T-test)          | Compares means of two independent groups                 |\n",
    "| Continuous (unequal variance) | Same as above               | `ttest_ind(..., equal_var=False)`         | Welch‚Äôs T-test ‚Äî safer when variances differ             |\n",
    "| Binary (0/1 outcomes)  | Conversion, click, purchase        | `statsmodels.stats.proportions_ztest`     | Compares proportions between two groups                  |\n",
    "| Count data             | # pageviews, # items bought        | Poisson or Negative Binomial test         | For skewed count distributions                           |\n",
    "| Non-parametric         | Ordinal/skewed data, NPS scores    | Mann-Whitney U test                       | No assumption of normality                               |\n",
    "| Multiple groups (A/B/C)| Multi-variant tests                | ANOVA (continuous), Chi-squared (binary)  | Tests across 3+ groups                                   |\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Quick Rules of Thumb:\n",
    "- If your metric is **continuous + normal-ish** ‚Üí Use **T-test**\n",
    "- If it‚Äôs **binary (e.g., clicked or not)** ‚Üí Use **Z-test**\n",
    "- If it‚Äôs **non-normal or skewed** ‚Üí Use **Mann-Whitney U test**\n",
    "- If testing **3 or more variants** ‚Üí Use **ANOVA** or **Chi-squared**\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c7961",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b194d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chi2_contingency, ttest_ind, ttest_rel, mannwhitneyu\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.power import TTestIndPower, TTestPower, FTestAnovaPower\n",
    "\n",
    "# Set Seed \n",
    "my_seed=42\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23628ec2",
   "metadata": {},
   "source": [
    "##### Test Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31eb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_type = 'binary'  # options: 'binary', 'continuous_independent', 'continuous_paired', 'anova'\n",
    "# Options:\n",
    "#   'binary'                 ‚Üí For conversion rate comparisons (Z-test)\n",
    "#   'continuous_independent' ‚Üí Comparing means across different users (T-test)\n",
    "#   'continuous_paired'      ‚Üí Comparing means for same users (Paired T-test)\n",
    "#   'anova'                  ‚Üí Comparing means across 3+ groups (ANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f0040",
   "metadata": {},
   "source": [
    "##### Sample user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbc8e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>city</th>\n",
       "      <th>past_purchase_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>iOS</td>\n",
       "      <td>51.305706</td>\n",
       "      <td>sf</td>\n",
       "      <td>46.847308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Android</td>\n",
       "      <td>45.514890</td>\n",
       "      <td>ny</td>\n",
       "      <td>57.589692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>51.376412</td>\n",
       "      <td>sf</td>\n",
       "      <td>42.271748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>iOS</td>\n",
       "      <td>20.186466</td>\n",
       "      <td>ny</td>\n",
       "      <td>47.631814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>iOS</td>\n",
       "      <td>46.704922</td>\n",
       "      <td>austin</td>\n",
       "      <td>45.146365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>iOS</td>\n",
       "      <td>37.762846</td>\n",
       "      <td>austin</td>\n",
       "      <td>47.978073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>iOS</td>\n",
       "      <td>48.843474</td>\n",
       "      <td>austin</td>\n",
       "      <td>47.823188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>iOS</td>\n",
       "      <td>55.117280</td>\n",
       "      <td>sf</td>\n",
       "      <td>60.987769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>iOS</td>\n",
       "      <td>54.150362</td>\n",
       "      <td>austin</td>\n",
       "      <td>58.254163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>iOS</td>\n",
       "      <td>62.407749</td>\n",
       "      <td>sf</td>\n",
       "      <td>58.135096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id platform  engagement_score    city  past_purchase_count\n",
       "0         1      iOS         51.305706      sf            46.847308\n",
       "1         2  Android         45.514890      ny            57.589692\n",
       "2         3  Android         51.376412      sf            42.271748\n",
       "3         4      iOS         20.186466      ny            47.631814\n",
       "4         5      iOS         46.704922  austin            45.146365\n",
       "..      ...      ...               ...     ...                  ...\n",
       "95       96      iOS         37.762846  austin            47.978073\n",
       "96       97      iOS         48.843474  austin            47.823188\n",
       "97       98      iOS         55.117280      sf            60.987769\n",
       "98       99      iOS         54.150362  austin            58.254163\n",
       "99      100      iOS         62.407749      sf            58.135096\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_count = 100 \n",
    "\n",
    "np.random.seed(my_seed)  # For reproducibility\n",
    "users = pd.DataFrame({\n",
    "    'user_id': range(1, observations_count+1),\n",
    "    'platform': np.random.choice(['iOS', 'Android'], size=observations_count, p=[0.6, 0.4]),  # 60% iOS, 40% Android\n",
    "    'engagement_score': np.random.normal(50, 15, observations_count),  # Simulated user engagement scores\n",
    "    'city': np.random.choice(['ny', 'sf', 'chicago', 'austin'], size=observations_count),\n",
    "    'past_purchase_count': np.random.normal(loc=50, scale=10, size=observations_count)  # pre_experiment_metric for CUPED randomization\n",
    "})\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f1591",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cad63c",
   "metadata": {},
   "source": [
    "# Randomization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48c869",
   "metadata": {},
   "source": [
    "Randomization is used to ensure that observed differences in outcome metrics are due to the experiment, not pre-existing differences.\n",
    "\n",
    "- Prevents **selection bias** (e.g., users self-selecting into groups)  \n",
    "- Balances **confounding factors** like platform, region, or past behavior  \n",
    "- Enables **valid inference** through statistical testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab4fa6",
   "metadata": {},
   "source": [
    "### üéØ Simple Randomization  \n",
    "Each user is assigned to control or treatment with **equal probability**, independent of any characteristics.\n",
    "\n",
    "---\n",
    "##### When to Use\n",
    "- Sample size is **large enough** to ensure natural balance  \n",
    "- No strong concern about **confounding variables**  \n",
    "- Need a **quick, default assignment** strategy\n",
    "\n",
    "##### How It Works\n",
    "- Assign each user randomly (e.g., 50/50 split)  \n",
    "- No grouping, segmentation, or blocking involved  \n",
    "- Groups are expected to balance out on average  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e9964e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_simple_randomization(df, group_col='group', seed=my_seed):\n",
    "    \"\"\"\n",
    "    Randomly assigns each row to 'control' or 'treatment' with equal probability.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing observations\n",
    "    - group_col: name of the column to store group assignments\n",
    "    - seed: random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with an added group assignment column\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    df[group_col] = np.random.choice(['control', 'treatment'], size=len(df), p=[0.5, 0.5])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ce64c",
   "metadata": {},
   "source": [
    "### Stratified Sampling  \n",
    "Ensures that key segments (e.g., platform, region) are evenly represented across control and treatment.\n",
    "\n",
    "---\n",
    "\n",
    "##### When to Use\n",
    "- User base is **naturally skewed** (e.g., 70% mobile, 30% desktop)  \n",
    "- Important to control for **known confounders** like geography or device  \n",
    "- You want balance **within subgroups**, not just overall\n",
    "\n",
    "##### How It Works\n",
    "- Pick a stratification variable (e.g., platform)  \n",
    "- Split population into strata (groups)  \n",
    "- Randomly assign users **within each stratum**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43aeb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stratified_randomization(df, stratify_col, group_col='group', seed=my_seed):\n",
    "    \"\"\"\n",
    "    Performs stratified randomization to ensure balanced assignment across a key segment.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to assign groups to\n",
    "    - stratify_col: column to balance across (e.g., platform, region)\n",
    "    - group_col: name of the column to store group assignments\n",
    "    - seed: random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with assigned groups, balanced across stratification column\n",
    "    \"\"\"\n",
    "    # Split data into control and treatment while preserving distribution of the stratify column\n",
    "    train, test = train_test_split(df, test_size=0.5, stratify=df[stratify_col], random_state=seed)\n",
    "\n",
    "    # Assign groups manually\n",
    "    train[group_col] = 'control'\n",
    "    test[group_col] = 'treatment'\n",
    "\n",
    "    # Combine and preserve original order (by index)\n",
    "    return pd.concat([train, test]).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b69b4f6",
   "metadata": {},
   "source": [
    "### Block Randomization  \n",
    "Groups users into fixed-size blocks and randomly assigns groups within each block.\n",
    "\n",
    "---\n",
    "\n",
    "##### When to Use\n",
    "- Users arrive in **time-based batches** (e.g., daily cohorts)  \n",
    "- Sample size is **small** and needs enforced balance  \n",
    "- You want to minimize **temporal or ordering effects**\n",
    "\n",
    "##### How It Works\n",
    "- Create blocks based on order or ID (e.g., every 10 users)  \n",
    "- Randomize assignments **within each block**  \n",
    "- Ensures near-equal split in every batch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04a062a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_block_randomization(\n",
    "    df,\n",
    "    observation_id_col,\n",
    "    group_col='group',\n",
    "    block_size=10,\n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Assigns treatment/control groups using block randomization.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to modify\n",
    "    - observation_id_col: Unique row identifier (e.g., user_id, session_id)\n",
    "    - group_col: Column to assign groups into\n",
    "    - block_size: Number of observations per block\n",
    "    - seed: Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with assigned group_col\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    df[group_col] = (\n",
    "        df\n",
    "        .assign(_block=(df[observation_id_col] - 1) // block_size)\n",
    "        .groupby('_block')[observation_id_col]\n",
    "        .transform(lambda x: np.random.choice(['control', 'treatment'], size=len(x), replace=True))\n",
    "    )\n",
    "\n",
    "    # Drop the block column if you want ‚Äî optional\n",
    "    # df = df.drop(columns=['_block'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7433cc",
   "metadata": {},
   "source": [
    "### Match Pair Randomization\n",
    "\n",
    "Participants are **paired based on similar characteristics** before random group assignment.  \n",
    "This reduces variance and improves **statistical power** by ensuring balance on key covariates.\n",
    "\n",
    "---\n",
    "\n",
    "##### When to Use\n",
    "- Small sample size with high risk of **confounding**\n",
    "- Outcomes influenced by user traits (e.g., **age, income, tenure**)  \n",
    "- Need to **minimize variance** across groups\n",
    "\n",
    "##### How It Works\n",
    "1. Identify important covariates (e.g., age, purchase history)  \n",
    "2. Sort users by those variables  \n",
    "3. Create matched pairs (or small groups)  \n",
    "4. Randomly assign one to **control**, the other to **treatment**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ba496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_matched_pair_randomization(df, sort_col, group_col='group'):\n",
    "    \"\"\"\n",
    "    Assigns groups using matched-pair randomization based on a sorting variable.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to assign groups to\n",
    "    - sort_col: column used to sort users before pairing (e.g., engagement score)\n",
    "    - group_col: name of the column to store group assignments\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with alternating control/treatment assignments within sorted pairs\n",
    "    \"\"\"\n",
    "    # Sort by the matching variable to bring similar observations together\n",
    "    df = df.sort_values(by=sort_col).reset_index(drop=True)\n",
    "\n",
    "    # Alternate assignments to create matched pairs (control, treatment, control, ...)\n",
    "    df[group_col] = np.where(df.index % 2 == 0, 'control', 'treatment')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872f04b",
   "metadata": {},
   "source": [
    "### Cluster Randomization\n",
    "Entire **groups or clusters** (e.g., cities, stores, schools) are assigned to control or treatment.  \n",
    "Used when it's impractical or risky to randomize individuals within a cluster.\n",
    "\n",
    "---\n",
    "\n",
    "###### When to Use\n",
    "- Users naturally exist in **groups** (e.g., teams, locations, devices)\n",
    "- There's a risk of **interference** between users (e.g., word-of-mouth)\n",
    "- Operational or tech constraints prevent individual-level randomization\n",
    "\n",
    "###### How It Works\n",
    "1. Define the cluster unit (e.g., store, city)  \n",
    "2. Randomly assign each cluster to control or treatment  \n",
    "3. All users within the cluster inherit the group assignment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b28e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cluster_randomization(df, cluster_col, group_col='group', seed=my_seed):\n",
    "    \"\"\"\n",
    "    Assigns groups using cluster-level randomization, where all observations in a cluster\n",
    "    receive the same assignment.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to assign groups to\n",
    "    - cluster_col: column defining the cluster (e.g., city, store)\n",
    "    - group_col: name of the column to store group assignments\n",
    "    - seed: random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with group assignments applied at the cluster level\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Randomly assign each cluster to control or treatment\n",
    "    unique_clusters = df[cluster_col].unique()\n",
    "    cluster_assignments = dict(\n",
    "        zip(unique_clusters, np.random.choice(['control', 'treatment'], size=len(unique_clusters)))\n",
    "    )\n",
    "\n",
    "    # Map cluster-level assignments back to the full dataset\n",
    "    df[group_col] = df[cluster_col].map(cluster_assignments)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8419594",
   "metadata": {},
   "source": [
    "### CUPED (Controlled Pre-Experiment Data)\n",
    "A statistical adjustment that uses **pre-experiment behavior** to reduce variance and improve power.  \n",
    "It helps detect smaller effects without increasing sample size.\n",
    "\n",
    "##### When to Use\n",
    "- You have reliable **pre-experiment metrics** (e.g., past spend, engagement)\n",
    "- You want to **reduce variance** and improve test sensitivity\n",
    "- You‚Äôre dealing with **small lifts** or **costly sample sizes**\n",
    "\n",
    "##### How It Works\n",
    "1. Identify a pre-period metric **correlated with your outcome**\n",
    "2. Use regression to compute an adjustment (theta)  \n",
    "3. Subtract the correlated component from your outcome metric  \n",
    "4. Analyze the adjusted metric instead of the raw one  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86dda432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cuped(df, pre_metric, group_col='group', outcome_col='adjusted_outcome', seed=my_seed):\n",
    "    \"\"\"\n",
    "    Applies CUPED (Controlled Pre-Experiment Data) adjustment to reduce variance\n",
    "    using a pre-experiment covariate.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to assign groups and compute adjusted outcomes\n",
    "    - pre_metric: name of the pre-experiment covariate column\n",
    "    - group_col: name of the column to store group assignments\n",
    "    - outcome_col: name of the new column to store the CUPED-adjusted outcome\n",
    "    - seed: random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with random assignment and adjusted outcome using CUPED\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Perform simple randomization (required before applying CUPED)\n",
    "    df = apply_simple_randomization(df.copy(), group_col=group_col, seed=seed)\n",
    "\n",
    "    # Simulate experiment outcome (in practice, this would be your actual metric)\n",
    "    y = np.random.normal(loc=0, scale=5, size=len(df))\n",
    "\n",
    "    # Regress outcome on pre-experiment metric to estimate theta (correction factor)\n",
    "    X = sm.add_constant(df[[pre_metric]])\n",
    "    theta = sm.OLS(y, X).fit().params[pre_metric]\n",
    "\n",
    "    # Apply CUPED adjustment: reduce outcome variance using theta * pre-metric\n",
    "    df[outcome_col] = y - theta * df[pre_metric]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c80305db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>city</th>\n",
       "      <th>past_purchase_count</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>iOS</td>\n",
       "      <td>51.305706</td>\n",
       "      <td>sf</td>\n",
       "      <td>46.847308</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Android</td>\n",
       "      <td>45.514890</td>\n",
       "      <td>ny</td>\n",
       "      <td>57.589692</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>51.376412</td>\n",
       "      <td>sf</td>\n",
       "      <td>42.271748</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>iOS</td>\n",
       "      <td>20.186466</td>\n",
       "      <td>ny</td>\n",
       "      <td>47.631814</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>iOS</td>\n",
       "      <td>46.704922</td>\n",
       "      <td>austin</td>\n",
       "      <td>45.146365</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>iOS</td>\n",
       "      <td>37.762846</td>\n",
       "      <td>austin</td>\n",
       "      <td>47.978073</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>iOS</td>\n",
       "      <td>48.843474</td>\n",
       "      <td>austin</td>\n",
       "      <td>47.823188</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>iOS</td>\n",
       "      <td>55.117280</td>\n",
       "      <td>sf</td>\n",
       "      <td>60.987769</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>iOS</td>\n",
       "      <td>54.150362</td>\n",
       "      <td>austin</td>\n",
       "      <td>58.254163</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>iOS</td>\n",
       "      <td>62.407749</td>\n",
       "      <td>sf</td>\n",
       "      <td>58.135096</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id platform  engagement_score    city  past_purchase_count      group\n",
       "0         1      iOS         51.305706      sf            46.847308    control\n",
       "1         2  Android         45.514890      ny            57.589692  treatment\n",
       "2         3  Android         51.376412      sf            42.271748  treatment\n",
       "3         4      iOS         20.186466      ny            47.631814  treatment\n",
       "4         5      iOS         46.704922  austin            45.146365    control\n",
       "..      ...      ...               ...     ...                  ...        ...\n",
       "95       96      iOS         37.762846  austin            47.978073    control\n",
       "96       97      iOS         48.843474  austin            47.823188  treatment\n",
       "97       98      iOS         55.117280      sf            60.987769    control\n",
       "98       99      iOS         54.150362  austin            58.254163    control\n",
       "99      100      iOS         62.407749      sf            58.135096    control\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_map = {\n",
    "    \"simple\": lambda df: apply_simple_randomization(df),\n",
    "    \"stratified\": lambda df: apply_stratified_randomization(df, stratify_col='platform'),\n",
    "    \"block\": lambda df: apply_block_randomization(users, observation_id_col='user_id', block_size=10),    \n",
    "    \"matched_pair\": lambda df: apply_matched_pair_randomization(df, sort_col='engagement_score'),\n",
    "    \"cluster\": lambda df: apply_cluster_randomization(df, cluster_col='city'),\n",
    "    \"cuped\": lambda df: apply_cuped(df, pre_metric='past_purchase_count'),\n",
    "}\n",
    "\n",
    "randomization_method=\"simple\"\n",
    "if randomization_method not in method_map:\n",
    "    raise ValueError(f\"‚ùå Unsupported method: {randomization_method}\")\n",
    "    \n",
    "users = method_map[randomization_method](users)\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73691185",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d61b9",
   "metadata": {},
   "source": [
    "# AA Testing\n",
    "\n",
    "# What specifically are we checking for???????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0f628",
   "metadata": {},
   "source": [
    "A/A testing is an experiment where both groups (control and treatment) receive the **same experience** to ensure that randomization is working correctly. It acts as a **sanity check** before running an A/B test.\n",
    "\n",
    "##### Importance\n",
    "- **Validates Randomization:** Ensures that groups are statistically similar before testing.\n",
    "- **Detects Sample Ratio Mismatch (SRM):** Verifies that user assignment is balanced.\n",
    "- **Estimates Variance for Power Analysis:** Helps understand variability before defining sample size for A/B testing.\n",
    "- **Checks for Pre-Existing Bias:** Ensures no systematic differences exist between control and treatment groups.\n",
    "\n",
    "##### Process\n",
    "- **Randomly assign users** to two equal groups (just like an A/B test).\n",
    "- **Measure key metrics** (e.g., conversion rate, engagement, revenue).\n",
    "- **Perform statistical tests** (e.g., t-test for continuous data, chi-square for categorical data) to confirm no significant difference.\n",
    "- **Analyze Sample Ratio Mismatch (SRM)** to verify even split between groups.\n",
    "\n",
    "##### Result\n",
    "- **No significant difference:** Randomization is working correctly, and the experiment is set up properly.\n",
    "- **Significant difference detected:** Investigate potential issues such as randomization bugs, sample bias, or instrumentation errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f110a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead75bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(my_seed)\n",
    "\n",
    "# Step 1: Simulate a base population of customers\n",
    "n_customers = 2000\n",
    "population = pd.DataFrame({\n",
    "    'user_id': np.arange(1, n_customers + 1),\n",
    "    'is_eligible': np.random.choice([0, 1], size=n_customers, p=[0.4, 0.6]),  # 60% eligible\n",
    "    'engagement_score': np.random.normal(loc=50, scale=10, size=n_customers)  # some behavioral metric\n",
    "})\n",
    "print(\"population:\\n\")\n",
    "population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25762724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Filter to eligible population\n",
    "eligible_population = population[population['is_eligible'] == 1].copy()\n",
    "n_eligible = len(eligible_population)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76093e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Randomly assign eligible users into two groups (A1 and A2)\n",
    "eligible_population['group'] = np.random.choice(['A1', 'A2'], size=n_eligible, replace=True)\n",
    "print(\"eligible_population:\\n\")\n",
    "eligible_population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b53895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split into the two groups\n",
    "group_A1 = eligible_population[eligible_population['group'] == 'A1']['engagement_score']\n",
    "group_A2 = eligible_population[eligible_population['group'] == 'A2']['engagement_score']\n",
    "print(\"group_A1, group_A2:\\n\")\n",
    "print(group_A1.head())\n",
    "print(group_A2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82acab3b",
   "metadata": {},
   "source": [
    "## SRM Check \n",
    "Is group assignment balanced?\n",
    "\n",
    "- üîç SRM (Sample Ratio Mismatch) checks whether the observed group sizes match the expected ratio.\n",
    "- In a perfect world, random assignment to 'A1' and 'A2' should give ~50/50 split.\n",
    "- SRM helps catch bugs in randomization, data logging, or user eligibility filtering.\n",
    "\n",
    "üéØ Real-World Experiment Split Ratios\n",
    "\n",
    "| **Scenario**                     | **Split**              | **Why**                                 |\n",
    "|----------------------------------|------------------------|------------------------------------------|\n",
    "| Default A/B                      | 50 / 50                | Maximizes power and ensures fairness     |\n",
    "| Risky feature                    | 10 / 90 or 20 / 80     | Limits user exposure to minimize risk    |\n",
    "| Ramp-up                          | Step-wise (1-5-25-50‚Ä¶) | Gradual rollout to catch issues early    |\n",
    "| A/B/C Test                       | 33 / 33 / 33 or weighted | Compare multiple variants fairly or with bias |\n",
    "| High control confidence needed   | 70 / 30 or 60 / 40     | More stability in baseline comparisons   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_counts = eligible_population['group'].value_counts().sort_index()\n",
    "expected_counts = [n_eligible / 2, n_eligible / 2]\n",
    "\n",
    "# Print observed counts and percentages\n",
    "print(\"\\nüìä Group Assignment Breakdown\")\n",
    "for group in observed_counts.index:\n",
    "    count = observed_counts[group]\n",
    "    pct = count / n_eligible * 100\n",
    "    print(f\"Group {group}: {count} users ({pct:.2f}%)\")\n",
    "    \n",
    "# Chi-Square Goodness of Fit Test\n",
    "chi2_stat, chi2_p = stats.chisquare(f_obs=observed_counts, f_exp=expected_counts)\n",
    "\n",
    "print(\"\\nüîç SRM Check\")\n",
    "print(f\"Chi2 Stat: {chi2_stat:.4f}\")\n",
    "print(f\"P-value : {chi2_p:.4f}\")\n",
    "if chi2_p < 0.05:\n",
    "    print(\"‚ö†Ô∏è Sample Ratio Mismatch detected ‚Äî investigate assignment logic.\")\n",
    "else:\n",
    "    print(\"‚úÖ No SRM ‚Äî group assignment is balanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Run 2-sample (independent) t-test\n",
    "t_stat, p_value = stats.ttest_ind(group_A1, group_A2)\n",
    "\n",
    "print(f\"\\nT-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"‚ö†Ô∏è Statistically significant difference found ‚Äî check randomization.\")\n",
    "else:\n",
    "    print(\"‚úÖ No significant difference ‚Äî randomization looks good.\")\n",
    "\n",
    "# Step 7: Visualize distributions\n",
    "plt.hist(group_A1, bins=30, alpha=0.5, label='Group A1');\n",
    "plt.hist(group_A2, bins=30, alpha=0.5, label='Group A2');\n",
    "plt.title('AA Test: Distribution Comparison');\n",
    "plt.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48617f5",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02dc03",
   "metadata": {},
   "source": [
    "# Power Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b860c5e4",
   "metadata": {},
   "source": [
    "Power analysis helps determine the **minimum sample size** needed to detect an expected effect with statistical confidence.\n",
    "\n",
    "##### Why It Matters:\n",
    "- Avoids **underpowered** tests (can't detect real differences)\n",
    "- Avoids **overpowered** tests (wastes resources)\n",
    "- Balances tradeoffs between **sample size**, **effect size**, **confidence level**, and **statistical power**\n",
    "\n",
    "##### Key Inputs:\n",
    "- **alpha (Œ±):** Significance level (probability of Type I error, usually 0.05\n",
    "- **Power (1 - Œ≤):** Probability of detecting a true effect (commonly 0.80 or 0.90)\n",
    "- **Baseline:** Current performance (e.g., 10% conversion rate)\n",
    "- **Minimum Detectable Effect (MDE):** Smallest lift you care to detect (e.g., +2%)\n",
    "\n",
    "We use a two-sample z-test for proportions to estimate sample size per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb08576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_power_sample_size(\n",
    "    experiment_type,\n",
    "    alpha=0.05,\n",
    "    power=0.80,\n",
    "    baseline_rate=None,   # For binary: e.g., 0.10 = 10% conversion rate\n",
    "    mde=None,             # Minimum Detectable Effect (absolute change)\n",
    "                          # e.g., 0.02 for 2% lift in binary, or $5 increase in continuous\n",
    "    std_dev=None,         # Std deviation of outcome for continuous outcomes\n",
    "    effect_size=None,     # Cohen's d (for t-tests) or f (for ANOVA)\n",
    "    num_groups=2          # Required only for ANOVA (‚â•3)\n",
    "):\n",
    "    \"\"\"\n",
    "    Generalized sample size calculator for A/B testing based on experiment type.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    experiment_type : str\n",
    "        Type of experiment. One of:\n",
    "        - 'binary'                  : Binary outcome (Z-test on proportions)\n",
    "        - 'continuous_independent' : Continuous outcome, different users (t-test)\n",
    "        - 'continuous_paired'      : Continuous outcome, same users (paired t-test)\n",
    "        - 'anova'                  : Continuous outcome, 3+ groups (ANOVA)\n",
    "\n",
    "    alpha : float\n",
    "        Significance level (Type I error), usually 0.05\n",
    "\n",
    "    power : float\n",
    "        Desired power of the test, e.g., 0.80 for 80%\n",
    "\n",
    "    baseline_rate : float\n",
    "        Current conversion rate (only for binary tests), e.g., 0.10 = 10%\n",
    "\n",
    "    mde : float\n",
    "        Minimum detectable effect. Examples:\n",
    "        - Binary: 0.02 ‚Üí detect +2% lift\n",
    "        - Continuous: 5 ‚Üí detect $5 increase\n",
    "\n",
    "    std_dev : float\n",
    "        Standard deviation of the metric (for continuous outcomes)\n",
    "\n",
    "    effect_size : float\n",
    "        Optional: if you already know Cohen‚Äôs d (for t-tests) or f (for ANOVA)\n",
    "\n",
    "    num_groups : int\n",
    "        Only for ANOVA. Must be ‚â• 3.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    int\n",
    "        Required sample size per group\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- 1. Binary outcome -----\n",
    "    if experiment_type == 'binary':\n",
    "        if baseline_rate is None or mde is None:\n",
    "            raise ValueError(\"baseline_rate and mde are required for binary tests.\")\n",
    "        \n",
    "        z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
    "        z_beta = stats.norm.ppf(power)\n",
    "        p1 = baseline_rate\n",
    "        p2 = p1 + mde\n",
    "        pooled_std = np.sqrt(2 * p1 * (1 - p1))\n",
    "\n",
    "        n = ((z_alpha + z_beta) ** 2 * pooled_std ** 2) / (mde ** 2)\n",
    "        return int(np.ceil(n))\n",
    "\n",
    "    # ----- 2. Continuous: Independent groups -----\n",
    "    elif experiment_type == 'continuous_independent':\n",
    "        if std_dev is None and effect_size is None:\n",
    "            raise ValueError(\"Provide std_dev or effect_size for continuous_independent test.\")\n",
    "        \n",
    "        if effect_size is None:\n",
    "            effect_size = mde / std_dev\n",
    "        \n",
    "        analysis = TTestIndPower()\n",
    "        n = analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha)\n",
    "        return int(np.ceil(n))\n",
    "\n",
    "    # ----- 3. Continuous: Paired test -----\n",
    "    elif experiment_type == 'continuous_paired':\n",
    "        if std_dev is None and effect_size is None:\n",
    "            raise ValueError(\"Provide std_dev or effect_size for continuous_paired test.\")\n",
    "        \n",
    "        if effect_size is None:\n",
    "            effect_size = mde / std_dev\n",
    "        \n",
    "        analysis = TTestPower()\n",
    "        n = analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha)\n",
    "        return int(np.ceil(n))\n",
    "\n",
    "    # ----- 4. ANOVA -----\n",
    "    elif experiment_type == 'anova':\n",
    "        if effect_size is None or num_groups < 3:\n",
    "            raise ValueError(\"effect_size and num_groups >= 3 are required for ANOVA.\")\n",
    "        \n",
    "        analysis = FTestAnovaPower()\n",
    "        n = analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha, k_groups=num_groups)\n",
    "        return int(np.ceil(n))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported experiment_type: {experiment_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "722b7d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required_sample_size per group: 3532\n"
     ]
    }
   ],
   "source": [
    "# üéØ Experiment assumptions\n",
    "alpha = 0.05                  # Type I error tolerance\n",
    "power = 0.80                  # 1 - Œ≤ (probability of detecting a true effect)\n",
    "baseline_rate = 0.10          # For binary: current conversion rate = 10%\n",
    "mde = 0.02                    # Minimum detectable lift = +2% (or $5, etc.)\n",
    "std_dev = None                # Only for continuous outcomes (e.g., revenue)\n",
    "effect_size = None            # Optional, used if std_dev is not given\n",
    "num_groups = 3                # Only needed for ANOVA (‚â• 3)\n",
    "\n",
    "# üßÆ Sample size calculation\n",
    "required_sample_size = calculate_power_sample_size(\n",
    "    experiment_type=experiment_type,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    baseline_rate=baseline_rate,\n",
    "    mde=mde,\n",
    "    std_dev=std_dev,\n",
    "    effect_size=effect_size,\n",
    "    num_groups=num_groups\n",
    ")\n",
    "print(\"required_sample_size per group:\", required_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2a0464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_power_analysis_summary(\n",
    "    experiment_type,\n",
    "    alpha,\n",
    "    power,\n",
    "    baseline_rate=None,\n",
    "    mde=None,\n",
    "    std_dev=None,\n",
    "    effect_size=None,\n",
    "    num_groups=2,\n",
    "    required_sample_size=None\n",
    "):\n",
    "    print(\"üìà Power Analysis Summary\")\n",
    "    print(f\"- Significance level (Œ±): {alpha}\")\n",
    "    print(f\"- Statistical power (1 - Œ≤): {power}\")\n",
    "    \n",
    "    if experiment_type == 'binary':\n",
    "        print(f\"- Baseline conversion rate: {baseline_rate}\")\n",
    "        print(f\"- Minimum detectable effect (MDE): {mde}\")\n",
    "        print(f\"- Target conversion rate: {baseline_rate + mde:.2f}\")\n",
    "        print(f\"\\n‚úÖ Result:\")\n",
    "        print(f\"To detect a lift from {baseline_rate:.2f} to {baseline_rate + mde:.2f},\")\n",
    "        print(f\"you need {required_sample_size} users in each group (control and treatment).\")\n",
    "        print(f\"Total sample size: {required_sample_size * 2} users.\")\n",
    "    \n",
    "    elif experiment_type == 'continuous_independent':\n",
    "        if std_dev:\n",
    "            print(f\"- Baseline Std Dev: {std_dev}\")\n",
    "            print(f\"- MDE (raw difference to detect): {mde}\")\n",
    "            print(f\"- Cohen's d (calculated): {mde / std_dev:.2f}\")\n",
    "        else:\n",
    "            print(f\"- Effect size (Cohen's d): {effect_size}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Result:\")\n",
    "        print(f\"To detect a mean difference of {mde} between two independent groups,\")\n",
    "        print(f\"you need {required_sample_size} users per group (total {required_sample_size * 2}).\")\n",
    "    \n",
    "    elif experiment_type == 'continuous_paired':\n",
    "        if std_dev:\n",
    "            print(f\"- Std Dev of differences: {std_dev}\")\n",
    "            print(f\"- MDE (within-user change): {mde}\")\n",
    "            print(f\"- Cohen's d (calculated): {mde / std_dev:.2f}\")\n",
    "        else:\n",
    "            print(f\"- Effect size (Cohen's d): {effect_size}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Result:\")\n",
    "        print(f\"To detect a mean change of {mde} within the same users,\")\n",
    "        print(f\"you need data from {required_sample_size} users.\")\n",
    "\n",
    "    elif experiment_type == 'anova':\n",
    "        print(f\"- Number of groups: {num_groups}\")\n",
    "        print(f\"- Effect size (Cohen's f): {effect_size}\")\n",
    "        print(f\"\\n‚úÖ Result:\")\n",
    "        print(f\"To detect differences in mean outcome across {num_groups} groups,\")\n",
    "        print(f\"you need {required_sample_size} users per group ({required_sample_size * num_groups} total).\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Unknown experiment type ‚Äî no summary printed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8803c60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Power Analysis Summary\n",
      "- Significance level (Œ±): 0.05\n",
      "- Statistical power (1 - Œ≤): 0.8\n",
      "- Baseline conversion rate: 0.1\n",
      "- Minimum detectable effect (MDE): 0.02\n",
      "- Target conversion rate: 0.12\n",
      "\n",
      "‚úÖ Result:\n",
      "To detect a lift from 0.10 to 0.12,\n",
      "you need 3532 users in each group (control and treatment).\n",
      "Total sample size: 7064 users.\n"
     ]
    }
   ],
   "source": [
    "print_power_analysis_summary(\n",
    "    experiment_type=experiment_type,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    baseline_rate=baseline_rate,\n",
    "    mde=mde,\n",
    "    std_dev=std_dev,\n",
    "    effect_size=effect_size,\n",
    "    num_groups=num_groups,\n",
    "    required_sample_size=required_sample_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e3add",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e68463",
   "metadata": {},
   "source": [
    "# AB Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25b9fec",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Metric Tracked:\n",
    "- **Primary metric:** Conversion rate (binary: clicked = 1, did not click = 0)\n",
    "- **Unit of analysis:** Unique user\n",
    "\n",
    "---\n",
    "\n",
    "#### üìà Outcome Analysis Plan:\n",
    "- Two-sample **z-test for proportions** to compare conversion rates\n",
    "- Compute confidence intervals and p-values\n",
    "- Optional: visualizations of effect size and confidence bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(my_seed)\n",
    "\n",
    "# Step 1: Simulate eligible population\n",
    "n = 7064  # from power analysis\n",
    "users = pd.DataFrame({\n",
    "    'user_id': np.arange(1, n + 1),\n",
    "})\n",
    "\n",
    "# Step 2: Randomly assign users to control or treatment\n",
    "users['group'] = np.random.choice(['control', 'treatment'], size=n, replace=True)\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63be386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Simulate conversions\n",
    "# Assume baseline = 0.10, treatment = 0.12\n",
    "conversion_rate = {\n",
    "    'control': 0.10,\n",
    "    'treatment': 0.12\n",
    "}\n",
    "users['converted'] = users['group'].apply(lambda g: np.random.binomial(1, conversion_rate[g]))\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a03185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: View summary\n",
    "summary = users.groupby('group')['converted'].agg(['count', 'sum', 'mean']).rename(columns={\n",
    "    'count': 'n_users',\n",
    "    'sum': 'n_converted',\n",
    "    'mean': 'conversion_rate'\n",
    "})\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Run 2-proportion z-test\n",
    "control_conv = summary.loc['control', 'conversion_rate']\n",
    "treatment_conv = summary.loc['treatment', 'conversion_rate']\n",
    "n_control = summary.loc['control', 'n_users']\n",
    "n_treatment = summary.loc['treatment', 'n_users']\n",
    "x_control = summary.loc['control', 'n_converted']\n",
    "x_treatment = summary.loc['treatment', 'n_converted']\n",
    "\n",
    "# Pooled conversion rate\n",
    "p_pooled = (x_control + x_treatment) / (n_control + n_treatment)\n",
    "se_pooled = np.sqrt(p_pooled * (1 - p_pooled) * (1/n_control + 1/n_treatment))\n",
    "\n",
    "z_stat = (treatment_conv - control_conv) / se_pooled\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f10423",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d6dc29",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fbb583",
   "metadata": {},
   "source": [
    "#### Conversion Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd8d38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"\\nüìä Z-Test Results\")\n",
    "print(f\"Z-statistic: {z_stat:.4f}\")\n",
    "print(f\"P-value    : {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"‚úÖ Statistically significant difference detected.\")\n",
    "else:\n",
    "    print(\"üö´ No significant difference detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93bc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already generated in earlier step, but good to reinforce\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21904129",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8abd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(['Control', 'Treatment'],\n",
    "              [control_conv, treatment_conv],\n",
    "              color=['gray', 'skyblue'])\n",
    "\n",
    "# Add values on top\n",
    "for bar in bars:\n",
    "    height = bar.get_height();\n",
    "    ax.annotate(f'{height:.4f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 5),  # vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom');\n",
    "ax.set_ylabel('Conversion Rate');\n",
    "ax.set_title('A/B Test: Conversion Rate by Group');\n",
    "ax.set_ylim(0, max(control_conv, treatment_conv) + 0.02);\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d922e",
   "metadata": {},
   "source": [
    "#### 95% Confidence Intervals (`outcome of group`)\n",
    "\n",
    "- The 95% confidence interval gives a range in which we expect the **true conversion rate** to fall for each group.\n",
    "- If the confidence intervals **do not overlap**, it's strong evidence that the difference is statistically significant.\n",
    "- If they **do overlap**, it doesn't guarantee insignificance ‚Äî you still need the p-value to decide ‚Äî but it suggests caution when interpreting lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confidence intervals\n",
    "def compute_ci(p, n, z=1.96):\n",
    "    se = np.sqrt(p * (1 - p) / n)\n",
    "    return (p - z*se, p + z*se)\n",
    "\n",
    "ci_control = compute_ci(control_conv, n_control)\n",
    "ci_treatment = compute_ci(treatment_conv, n_treatment)\n",
    "\n",
    "# Plot with error bars\n",
    "plt.errorbar(['Control', 'Treatment'],\n",
    "             [control_conv, treatment_conv],\n",
    "             yerr=[[control_conv - ci_control[0], treatment_conv - ci_treatment[0]],\n",
    "                   [ci_control[1] - control_conv, ci_treatment[1] - treatment_conv]],\n",
    "             fmt='o', capsize=10, color='black')\n",
    "plt.ylabel('Conversion Rate');\n",
    "plt.title('Conversion Rate with 95% Confidence Intervals');\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb707b79",
   "metadata": {},
   "source": [
    "#### 95% Confidence Intervals (`difference in outcomes`). AKA `Lift Analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate absolute lift\n",
    "lift = treatment_conv - control_conv\n",
    "\n",
    "# Standard error for the difference in proportions\n",
    "se_diff = np.sqrt(\n",
    "    (control_conv * (1 - control_conv) / n_control) +\n",
    "    (treatment_conv * (1 - treatment_conv) / n_treatment)\n",
    ")\n",
    "\n",
    "# 95% Confidence Interval for the lift\n",
    "z = 1.96  # for 95%\n",
    "ci_lower = lift - z * se_diff\n",
    "ci_upper = lift + z * se_diff\n",
    "\n",
    "# Print result\n",
    "print(\"üìà Lift Analysis\")\n",
    "print(f\"- Absolute Lift: {lift:.4f}\")\n",
    "print(f\"- 95% Confidence Interval for Lift: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "\n",
    "# Interpretation\n",
    "if ci_lower > 0:\n",
    "    print(\"‚úÖ We're 95% confident the new version improved conversion.\")\n",
    "elif ci_upper < 0:\n",
    "    print(\"üö´ We're 95% confident the new version hurt conversion.\")\n",
    "else:\n",
    "    print(\"ü§∑ The confidence interval includes 0 ‚Äî we can't say the lift is statistically significant.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a553b",
   "metadata": {},
   "source": [
    "#### Final Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\" + \"=\"*40)\n",
    "print(\"          üìäFINAL A/B TEST SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(f\"üë•  Control conversion rate   :  {control_conv:.4f}\")\n",
    "print(f\"üß™  Treatment conversion rate :  {treatment_conv:.4f}\")\n",
    "print(f\"üìà  Absolute lift             :  {(treatment_conv - control_conv):.4f}\")\n",
    "print(f\"üìä  Percentage lift           :  {((treatment_conv - control_conv)/control_conv):.2%}\")\n",
    "print(f\"üß™  P-value (from z-test)     :  {p_value:.4f}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"‚úÖ  RESULT: Statistically significant improvement detected.\")\n",
    "else:\n",
    "    print(\"‚ùå  RESULT: No statistically significant difference detected.\")\n",
    "\n",
    "print(\"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0457202f",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dca748",
   "metadata": {},
   "source": [
    "# How Long\n",
    "##### to run the test?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decf16bf",
   "metadata": {},
   "source": [
    "The runtime of an A/B test depends on how quickly you can reach the required **sample size per group**, as estimated during power analysis.\n",
    "\n",
    "##### Key Inputs:\n",
    "- ‚úÖ Daily eligible traffic volume\n",
    "- ‚úÖ Required sample size (from power analysis)\n",
    "- ‚úÖ Whether traffic is split 50/50 or unevenly\n",
    "\n",
    "##### Formula:\n",
    "> **Days = Required Sample Size per Group / (Daily Eligible Users √ó Group Split Proportion)**\n",
    "\n",
    "This ensures the experiment runs **long enough to detect the effect** with the desired statistical confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a916f0c",
   "metadata": {},
   "source": [
    "##### ‚è≥ How Long to Run an A/B Test ‚Äî Real-World Guide\n",
    "\n",
    "1. **Estimate sample size** needed (done via power analysis)\n",
    "2. **Understand your traffic** ‚Äî how many eligible users per day?\n",
    "3. **Factor in group split** ‚Äî if it's 50/50, each group gets half the traffic\n",
    "4. **Divide required sample per group by daily users per group** to estimate days\n",
    "\n",
    "---\n",
    "\n",
    "##### üí° Real-World Recommendations\n",
    "\n",
    "- ‚úÖ **Ramp-Up Period**: Don‚Äôt go full traffic on Day 1. Start with 5%, then 25%, then 50% over 2‚Äì3 days. This is safer and helps catch bugs early.\n",
    "  \n",
    "- ‚úÖ **Cool-Down Buffer**: Let the test stabilize before analysis. Avoid cutting off during weekends or anomalies.\n",
    "  \n",
    "- ‚úÖ **Trust Checks**:\n",
    "  - Run an **A/A test first** to validate setup\n",
    "  - Do an **SRM check** to confirm assignment balance\n",
    "  - Monitor **guardrail metrics** (e.g., bounce rate, latency)\n",
    "\n",
    "- ‚è≥ Add **1‚Äì2 buffer days** for these. It‚Äôs not just about stats ‚Äî it‚Äôs about reliability and business trust.\n",
    "\n",
    "---\n",
    "\n",
    "##### üß† Tip\n",
    "> ‚ÄúWe typically recommend calculating sample size from power analysis, then dividing by daily traffic per variant. But we also factor in buffer days for ramp-up, trust checks, and traffic noise ‚Äî just to make sure we don‚Äôt rush analysis before data is stable.‚Äù\n",
    "\n",
    "> ‚ÄúWe use power analysis to plan ‚Äî it gives stakeholders a timeline and sets expectations.\n",
    "But we don‚Äôt blindly stop based on sample size. I monitor SRM, metric stability, cohort coverage, and confidence intervals before making the call. We want decisions that are trustworthy, not just statistically complete.‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b87fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_total_test_duration(required_sample_size_per_group, daily_eligible_users, allocation_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Estimate total days needed to complete an A/B test for both groups.\n",
    "\n",
    "    Parameters:\n",
    "    - required_sample_size_per_group: int, sample size needed per group (from power analysis)\n",
    "    - daily_eligible_users: int, total eligible users arriving each day\n",
    "    - allocation_ratio: float, proportion of traffic sent to each group (e.g., 0.5 for 50/50)\n",
    "\n",
    "    Returns:\n",
    "    - Estimated total number of days to complete both groups\n",
    "    \"\"\"\n",
    "    # Max group load per day (assuming symmetric or asymmetric allocation)\n",
    "    daily_users_per_group = daily_eligible_users * allocation_ratio\n",
    "    days_needed = required_sample_size_per_group / daily_users_per_group\n",
    "\n",
    "    return int(np.ceil(days_needed))\n",
    "\n",
    "# Example Usage\n",
    "required_sample = 3532\n",
    "daily_users = 10000\n",
    "allocation = 0.5  # 50% of users per group\n",
    "\n",
    "total_days = estimate_total_test_duration(required_sample, daily_users, allocation)\n",
    "buffer_days = 2  # For ramp-up, cool-down, or traffic anomalies\n",
    "\n",
    "print(f\"üìÖ Estimated minimum duration per group : {total_days} days\")\n",
    "print(f\"üì¶ Add buffer (ramp-up, weekends, trust checks): {buffer_days} days\")\n",
    "print(f\"üßÆ Total recommended runtime             : {total_days + buffer_days} days\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48203b7",
   "metadata": {},
   "source": [
    "#### Monitoring Dashboard\n",
    "- Guardrails\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e17a8c",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ce892",
   "metadata": {},
   "source": [
    "# Post Hoc Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78601d2",
   "metadata": {},
   "source": [
    "> üîç After statistical significance, we do a post-hoc dive. We check for lift by user segment, inspect guardrail metrics, and simulate rollout impact. This turns A/B tests into real product decisions.\n",
    "\n",
    "Post-hoc analysis helps interpret test results **beyond the primary metric**, and answer key follow-up questions like:\n",
    "- Did the effect differ by segment (e.g. platform, user type)?\n",
    "- Were any guardrail metrics negatively impacted?\n",
    "- What does the lift mean in terms of actual revenue or conversions?\n",
    "- What happens if we roll this out 100%?\n",
    "\n",
    "This step helps turn **statistical significance into business confidence.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4025c73",
   "metadata": {},
   "source": [
    "#### Segmented Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add a few realistic segmentation features to the users DataFrame\n",
    "# (e.g., platform, device_type, user_tier, region)\n",
    "\n",
    "np.random.seed(my_seed)  # for reproducibility\n",
    "\n",
    "users['platform'] = np.random.choice(['iOS', 'Android'], size=len(users))\n",
    "users['device_type'] = np.random.choice(['mobile', 'desktop'], size=len(users), p=[0.7, 0.3])\n",
    "users['user_tier'] = np.random.choice(['new', 'returning'], size=len(users), p=[0.4, 0.6])\n",
    "users['region'] = np.random.choice(['North', 'South', 'East', 'West'], size=len(users))\n",
    "\n",
    "# Return a preview of the updated DataFrame\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmented_lift_analysis(df, segment_cols, outcome_col='converted'):\n",
    "    for segment in segment_cols:\n",
    "        print(f\"\\nüìä Segment: {segment}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        # 1. Aggregate conversion metrics\n",
    "        grouped = df.groupby([segment, 'group'])[outcome_col].agg(['count', 'sum', 'mean']).reset_index()\n",
    "        grouped.columns = [segment, 'group', 'n_users', 'n_converted', 'conversion_rate']\n",
    "\n",
    "        # 2. Pivot to calculate absolute and percentage lift\n",
    "        pivoted = grouped.pivot(index=segment, columns='group', values='conversion_rate').reset_index()\n",
    "        pivoted['absolute_lift'] = pivoted['treatment'] - pivoted['control']\n",
    "        pivoted['percentage_lift'] = pivoted['absolute_lift'] / pivoted['control']\n",
    "        print(pivoted[[segment, 'control', 'treatment', 'absolute_lift', 'percentage_lift']].to_string(index=False))\n",
    "\n",
    "        # 3. Plot\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        ax = sns.barplot(data=grouped, x=segment, y='conversion_rate', hue='group')\n",
    "\n",
    "        # 4. Add value labels\n",
    "        for bar in ax.patches:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f\"{height:.3f}\", \n",
    "                        (bar.get_x() + bar.get_width() / 2, height + 0.005),\n",
    "                        ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "        # 5. Style tweaks ‚Äî fixed layout\n",
    "        ax.set_title(f'Conversion Rate by {segment} and Group', pad=15)\n",
    "        ax.set_ylabel('Conversion Rate')\n",
    "        ax.set_xlabel(segment)\n",
    "        ax.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        ax.set_ylim(0, grouped['conversion_rate'].max() + 0.05)\n",
    "\n",
    "        # üëá FIXED LEGEND POSITION\n",
    "        ax.legend(\n",
    "            # title='Group', \n",
    "            loc='upper right', \n",
    "            fontsize='small', \n",
    "            title_fontsize='small',\n",
    "            frameon=True,\n",
    "            borderpad=0.5)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec67d4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "segmented_columns = ['platform', 'device_type', 'user_tier', 'region']\n",
    "segmented_lift_analysis(users, segmented_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8135b7",
   "metadata": {},
   "source": [
    "#### Guardrail Metric Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cca45b",
   "metadata": {},
   "source": [
    "Guardrail metrics are **non-primary metrics** that help ensure an experiment isn't causing unintended harm.\n",
    "\n",
    "We monitor them alongside the main success metric to:\n",
    "- Detect regressions in user experience or system performance\n",
    "- Catch trade-offs early (e.g., improved conversions but worse bounce rate)\n",
    "\n",
    "---\n",
    "\n",
    "üìä Common Guardrail Metrics\n",
    "- Bounce Rate ‚Äî did the experience frustrate users?\n",
    "- Page Load Time / Latency ‚Äî did the feature slow down the UI?\n",
    "- Session Length / Engagement ‚Äî did users stick around?\n",
    "- Error Rate ‚Äî did the experiment introduce bugs?\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ When to Act:\n",
    "- If the **treatment worsens a guardrail metric**, even if the primary metric improved ‚Üí we pause, investigate, or reject the rollout.\n",
    "Guardrails aren‚Äôt always deal-breakers, but they‚Äôre **trust checks** that make A/B test results *safe* to act on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c31c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a simulated guardrail metric: bounce_rate (continuous between 0.1 and 0.9)\n",
    "# Bounce rate is typically higher when users disengage quickly\n",
    "\n",
    "np.random.seed(my_seed)\n",
    "users['bounce_rate'] = np.where(\n",
    "    users['converted'] == 1,\n",
    "    np.random.normal(loc=0.2, scale=0.05, size=len(users)),  # lower bounce if converted\n",
    "    np.random.normal(loc=0.6, scale=0.1, size=len(users))   # higher bounce if not\n",
    ")\n",
    "\n",
    "# Clip to stay between 0 and 1\n",
    "users['bounce_rate'] = users['bounce_rate'].clip(0, 1)\n",
    "\n",
    "# Return sample for inspection\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example if you had bounce_rate as a column:\n",
    "guardrail = users.groupby('group')['bounce_rate'].mean()\n",
    "print(\"üö¶ Average Bounce Rate by Group:\")\n",
    "print(guardrail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fcb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group means\n",
    "bounce_by_group = users.groupby('group')['bounce_rate'].mean()\n",
    "bounce_diff = bounce_by_group['treatment'] - bounce_by_group['control']\n",
    "\n",
    "# 2. Optional statistical test (t-test)\n",
    "control_bounce = users[users['group'] == 'control']['bounce_rate']\n",
    "treatment_bounce = users[users['group'] == 'treatment']['bounce_rate']\n",
    "t_stat, p_val = ttest_ind(treatment_bounce, control_bounce)\n",
    "\n",
    "# 3. Print summary and conclusion\n",
    "print(\"üö¶ Guardrail Check\")\n",
    "print(f\"- Control  : {bounce_by_group['control']:.4f}\")\n",
    "print(f\"- Treatment: {bounce_by_group['treatment']:.4f}\")\n",
    "print(f\"- Difference: {bounce_diff:+.4f}\")\n",
    "print(f\"- P-value (t-test): {p_val:.4f}\")\n",
    "\n",
    "# 4. Conclusion\n",
    "if p_val < 0.05:\n",
    "    if bounce_diff > 0:\n",
    "        print(\"‚ùå Statistically significant *increase* in bounce rate ‚Äî potential UX regression.\")\n",
    "    else:\n",
    "        print(\"‚úÖ Statistically significant *decrease* in bounce rate ‚Äî UX may have improved.\")\n",
    "else:\n",
    "    print(\"üü° No significant change in bounce rate ‚Äî guardrail looks stable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397302e7",
   "metadata": {},
   "source": [
    "#### Rollout Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume full exposure to daily_eligible_users\n",
    "daily_impact = (treatment_conv - control_conv) * daily_eligible_users\n",
    "monthly_impact = daily_impact * 30\n",
    "\n",
    "print(f\"üìà Estimated additional conversions per day: {daily_impact:.0f}\")\n",
    "print(f\"üìà Estimated additional conversions per month: {monthly_impact:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87d394",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16893894",
   "metadata": {},
   "source": [
    "# Scratch Notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f2c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate data\n",
    "n_control = 5000  # Sample size for control group\n",
    "n_treatment = 5000  # Sample size for treatment group\n",
    "\n",
    "# Assume conversion rate is 10% for control and 12% for treatment\n",
    "control_conversions = np.random.binomial(1, 0.10, n_control)\n",
    "treatment_conversions = np.random.binomial(1, 0.12, n_treatment)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'group': ['control'] * n_control + ['treatment'] * n_treatment,\n",
    "    'conversion': np.concatenate([control_conversions, treatment_conversions])\n",
    "})\n",
    "df.head()\n",
    "df.shape\n",
    "\n",
    "# Display summary\n",
    "df.groupby('group')['conversion'].agg(['mean', 'count', 'sum'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568b4e4c",
   "metadata": {},
   "source": [
    "#### AB Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118b4d57",
   "metadata": {},
   "source": [
    "1. Chi-Square Test (Categorical Data - Conversion Rates)     \n",
    "Used when testing differences in proportions (e.g., conversion rate increase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create contingency table\n",
    "conversion_table = pd.crosstab(df['group'], df['conversion'])\n",
    "\n",
    "# Chi-Square Test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(conversion_table)\n",
    "\n",
    "# Print results\n",
    "print(f\"Chi-Square Statistic: {chi2_stat:.4f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")\n",
    "\n",
    "# Check significance\n",
    "alpha = 0.05  # 95% confidence level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: Significant difference detected.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff20b9a4",
   "metadata": {},
   "source": [
    "2. Independent T-Test (Continuous Data - Avg. Time Spent, Revenue)    \n",
    "Used when comparing means of continuous data between two independent groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform independent t-test\n",
    "t_stat, p_val = ttest_ind(control_conversions, treatment_conversions)\n",
    "\n",
    "print(f\"T-Statistic: {t_stat:.4f}\")\n",
    "print(f\"P-Value: {p_val:.4f}\")\n",
    "\n",
    "if p_val < alpha:\n",
    "    print(\"Reject the null hypothesis: The new feature has a significant effect.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant difference detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e340824",
   "metadata": {},
   "source": [
    "3. Paired T-Test (Before/After Tests - Same Users)    \n",
    "Used when measuring differences within the same group (e.g., before vs. after)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: User engagement before & after a UI change\n",
    "before = np.random.normal(200, 25, 100)  # Mean 200 sec, std dev 25\n",
    "after = np.random.normal(210, 25, 100)  # Mean 210 sec, std dev 25\n",
    "\n",
    "t_stat, p_val = ttest_rel(before, after)\n",
    "\n",
    "print(f\"Paired T-Test Statistic: {t_stat:.4f}\")\n",
    "print(f\"P-Value: {p_val:.4f}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"Significant difference detected.\")\n",
    "else:\n",
    "    print(\"No significant difference detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e055e0f8",
   "metadata": {},
   "source": [
    "4. Mann-Whitney U Test (Non-Normal Continuous Data)\n",
    "A non-parametric test used when data isn‚Äôt normally distributed (e.g., skewed revenue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845d0398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Revenue data (skewed distribution)\n",
    "control_revenue = np.random.exponential(50, 5000)  # Skewed\n",
    "treatment_revenue = np.random.exponential(55, 5000)  # Skewed\n",
    "\n",
    "u_stat, p_val = mannwhitneyu(control_revenue, treatment_revenue)\n",
    "\n",
    "print(f\"Mann-Whitney U Statistic: {u_stat:.4f}\")\n",
    "print(f\"P-Value: {p_val:.4f}\")\n",
    "\n",
    "if p_val < 0.05:\n",
    "    print(\"Significant difference detected.\")\n",
    "else:\n",
    "    print(\"No significant difference detected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1fad0a",
   "metadata": {},
   "source": [
    " 5. Bayesian A/B Testing (Alternative Approach)    \n",
    "Instead of p-values, Bayesian A/B testing provides posterior probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0a4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymc3 as pm\n",
    "\n",
    "# # Simulated conversion data\n",
    "# control_conversions = np.sum(np.random.binomial(1, 0.10, 5000))\n",
    "# treatment_conversions = np.sum(np.random.binomial(1, 0.12, 5000))\n",
    "\n",
    "# with pm.Model():\n",
    "#     control_rate = pm.Beta(\"control_rate\", alpha=1, beta=1)\n",
    "#     treatment_rate = pm.Beta(\"treatment_rate\", alpha=1, beta=1)\n",
    "\n",
    "#     # Priors\n",
    "#     control = pm.Binomial(\"control\", n=5000, p=control_rate, observed=control_conversions)\n",
    "#     treatment = pm.Binomial(\"treatment\", n=5000, p=treatment_rate, observed=treatment_conversions)\n",
    "\n",
    "#     trace = pm.sample(2000, return_inferencedata=True)\n",
    "\n",
    "# # Compute probability that the treatment is better\n",
    "# prob_treatment_better = (trace.posterior[\"treatment_rate\"] > trace.posterior[\"control_rate\"]).mean().item()\n",
    "\n",
    "# print(f\"Probability that the treatment is better: {prob_treatment_better:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552361b0",
   "metadata": {},
   "source": [
    "6. Power Analysis (How Much Data Do You Need?)\n",
    "Used to determine sample size before running an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "effect_size = 0.02  # Expected lift in conversion rate\n",
    "alpha = 0.05  # Significance level\n",
    "power = 0.8  # Desired statistical power\n",
    "\n",
    "# Compute sample size per group\n",
    "analysis = TTestIndPower()\n",
    "sample_size = analysis.solve_power(effect_size, power=power, alpha=alpha, ratio=1)\n",
    "\n",
    "print(f\"Required Sample Size per Group: {int(sample_size)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58b5a3",
   "metadata": {},
   "source": [
    "# Other Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1464ee7d",
   "metadata": {},
   "source": [
    "### Experimentation Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7cf4d",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
