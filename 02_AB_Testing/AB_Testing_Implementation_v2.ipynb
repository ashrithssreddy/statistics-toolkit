{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf94292f",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- [Data Setup](#Data-Setup)\n",
    "- [Randomization Methods](#Randomization-Methods)\n",
    "- [EDA](#EDA)\n",
    "- [AA Testing](#AA-Testing)\n",
    "    - [SRM Check](#SRM-Check)\n",
    "- [Power Analysis](#Power-Analysis)\n",
    "- [AB Testing](#AB-Testing)\n",
    "- [Results](#Results)\n",
    "    - [Summaries](#Summaries)\n",
    "    - [Visualization](#Visualization)\n",
    "    - [Confidence Intervals Within Groups](#95-confidence-intervals)\n",
    "    - [Lift Analysis](#Lift-Analysis)\n",
    "    - [Conclusion](#Conclusion)\n",
    "- [How Long](#How-Long)\n",
    "- [Post Hoc Analysis](#Post-Hoc-Analysis)\n",
    "    - [Segmented Lift](#Segmented-Lift)\n",
    "    - [Guardrail Metrics](#Guardrail-Metrics)\n",
    "    - [Rollout Simulation](#Rollout-Simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692c7961",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b194d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import (\n",
    "    ttest_ind,\n",
    "    ttest_rel,\n",
    "    chi2_contingency,\n",
    "    mannwhitneyu\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.power import (\n",
    "    TTestIndPower,\n",
    "    TTestPower,\n",
    "    FTestAnovaPower,\n",
    "    NormalIndPower\n",
    ")\n",
    "\n",
    "# Set Seed \n",
    "my_seed=42\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edc9bb8",
   "metadata": {},
   "source": [
    "##### Sample user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f125df9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>device_type</th>\n",
       "      <th>user_tier</th>\n",
       "      <th>region</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>city</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>converted</th>\n",
       "      <th>past_purchase_count</th>\n",
       "      <th>bounce_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>iOS</td>\n",
       "      <td>mobile</td>\n",
       "      <td>new</td>\n",
       "      <td>East</td>\n",
       "      <td>basic</td>\n",
       "      <td>chicago</td>\n",
       "      <td>40.191524</td>\n",
       "      <td>0</td>\n",
       "      <td>60.899050</td>\n",
       "      <td>0.739936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Android</td>\n",
       "      <td>mobile</td>\n",
       "      <td>new</td>\n",
       "      <td>West</td>\n",
       "      <td>premium</td>\n",
       "      <td>austin</td>\n",
       "      <td>50.409701</td>\n",
       "      <td>0</td>\n",
       "      <td>44.288160</td>\n",
       "      <td>0.692463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>desktop</td>\n",
       "      <td>returning</td>\n",
       "      <td>South</td>\n",
       "      <td>premium</td>\n",
       "      <td>chicago</td>\n",
       "      <td>49.289439</td>\n",
       "      <td>1</td>\n",
       "      <td>50.438288</td>\n",
       "      <td>0.232384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>iOS</td>\n",
       "      <td>desktop</td>\n",
       "      <td>new</td>\n",
       "      <td>East</td>\n",
       "      <td>basic</td>\n",
       "      <td>austin</td>\n",
       "      <td>26.267349</td>\n",
       "      <td>0</td>\n",
       "      <td>59.558027</td>\n",
       "      <td>0.535306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>iOS</td>\n",
       "      <td>desktop</td>\n",
       "      <td>new</td>\n",
       "      <td>East</td>\n",
       "      <td>basic</td>\n",
       "      <td>austin</td>\n",
       "      <td>35.894016</td>\n",
       "      <td>0</td>\n",
       "      <td>45.157416</td>\n",
       "      <td>0.669822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>iOS</td>\n",
       "      <td>mobile</td>\n",
       "      <td>returning</td>\n",
       "      <td>South</td>\n",
       "      <td>premium</td>\n",
       "      <td>ny</td>\n",
       "      <td>61.562033</td>\n",
       "      <td>0</td>\n",
       "      <td>48.154486</td>\n",
       "      <td>0.707015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>Android</td>\n",
       "      <td>desktop</td>\n",
       "      <td>new</td>\n",
       "      <td>South</td>\n",
       "      <td>basic</td>\n",
       "      <td>austin</td>\n",
       "      <td>34.192468</td>\n",
       "      <td>0</td>\n",
       "      <td>55.923295</td>\n",
       "      <td>0.597348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>iOS</td>\n",
       "      <td>mobile</td>\n",
       "      <td>new</td>\n",
       "      <td>South</td>\n",
       "      <td>basic</td>\n",
       "      <td>sf</td>\n",
       "      <td>56.417216</td>\n",
       "      <td>0</td>\n",
       "      <td>50.993138</td>\n",
       "      <td>0.511813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>Android</td>\n",
       "      <td>mobile</td>\n",
       "      <td>new</td>\n",
       "      <td>East</td>\n",
       "      <td>premium</td>\n",
       "      <td>sf</td>\n",
       "      <td>24.471467</td>\n",
       "      <td>0</td>\n",
       "      <td>46.095913</td>\n",
       "      <td>0.583693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>iOS</td>\n",
       "      <td>mobile</td>\n",
       "      <td>returning</td>\n",
       "      <td>North</td>\n",
       "      <td>basic</td>\n",
       "      <td>austin</td>\n",
       "      <td>41.579930</td>\n",
       "      <td>0</td>\n",
       "      <td>55.161440</td>\n",
       "      <td>0.525510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id platform device_type  user_tier region plan_type     city  \\\n",
       "0          1      iOS      mobile        new   East     basic  chicago   \n",
       "1          2  Android      mobile        new   West   premium   austin   \n",
       "2          3  Android     desktop  returning  South   premium  chicago   \n",
       "3          4      iOS     desktop        new   East     basic   austin   \n",
       "4          5      iOS     desktop        new   East     basic   austin   \n",
       "..       ...      ...         ...        ...    ...       ...      ...   \n",
       "995      996      iOS      mobile  returning  South   premium       ny   \n",
       "996      997  Android     desktop        new  South     basic   austin   \n",
       "997      998      iOS      mobile        new  South     basic       sf   \n",
       "998      999  Android      mobile        new   East   premium       sf   \n",
       "999     1000      iOS      mobile  returning  North     basic   austin   \n",
       "\n",
       "     engagement_score  converted  past_purchase_count  bounce_rate  \n",
       "0           40.191524          0            60.899050     0.739936  \n",
       "1           50.409701          0            44.288160     0.692463  \n",
       "2           49.289439          1            50.438288     0.232384  \n",
       "3           26.267349          0            59.558027     0.535306  \n",
       "4           35.894016          0            45.157416     0.669822  \n",
       "..                ...        ...                  ...          ...  \n",
       "995         61.562033          0            48.154486     0.707015  \n",
       "996         34.192468          0            55.923295     0.597348  \n",
       "997         56.417216          0            50.993138     0.511813  \n",
       "998         24.471467          0            46.095913     0.583693  \n",
       "999         41.579930          0            55.161440     0.525510  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations_count = 1000\n",
    "\n",
    "np.random.seed(my_seed) # For reproducibility\n",
    "users = pd.DataFrame({\n",
    "    # identifiers\n",
    "    'user_id': range(1, observations_count+1),\n",
    "\n",
    "    # segmentation features\n",
    "    'platform': np.random.choice(['iOS', 'Android'], size=observations_count, p=[0.6, 0.4]), # 60% iOS, 40% Android\n",
    "    'device_type': np.random.choice(['mobile', 'desktop'], size=observations_count, p=[0.7, 0.3]),\n",
    "    'user_tier': np.random.choice(['new', 'returning'], size=observations_count, p=[0.4, 0.6]),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], size=observations_count, p=[0.25, 0.25, 0.25, 0.25]),\n",
    "    'plan_type': np.random.choice(['basic', 'premium', 'pro'], size=observations_count, p=[0.6, 0.3, 0.1]), # 60% basic, 30% premium, 10% pro\n",
    "    'city': np.random.choice(['ny', 'sf', 'chicago', 'austin'], size=observations_count),\n",
    "\n",
    "    # outcome metrics\n",
    "    'engagement_score': np.random.normal(50, 15, observations_count), # Simulated user engagement scores\n",
    "    'converted': np.random.binomial(n=1, p=0.1, size=observations_count), # Simulated binary conversion: ~10% baseline\n",
    "    'past_purchase_count': np.random.normal(loc=50, scale=10, size=observations_count), # pre_experiment_metric for CUPED randomization\n",
    "    'bounce_rate': np.nan\n",
    "})\n",
    "\n",
    "\n",
    "# Simulate guardrail metric (bounce_rate) — lower if user converted\n",
    "np.random.seed(my_seed)\n",
    "users['bounce_rate'] = np.where(\n",
    "    users['converted'] == 1,\n",
    "    np.random.normal(loc=0.2, scale=0.05, size=observations_count),\n",
    "    np.random.normal(loc=0.6, scale=0.10, size=observations_count)\n",
    ")\n",
    "users['bounce_rate'] = users['bounce_rate'].clip(0, 1) # Bound bounce_rate between 0 and 1\n",
    "\n",
    "users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23628ec2",
   "metadata": {},
   "source": [
    "##### Experiment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31eb0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 🔧 Experiment Setup Inputs\n",
    "# -------------------------\n",
    "\n",
    "# 1. Main outcome variable you're testing\n",
    "outcome_metric_col = 'engagement_score'\n",
    "\n",
    "# 2. Metric type: 'binary', 'continuous', or 'categorical'\n",
    "outcome_metric_datatype = 'continuous'\n",
    "\n",
    "# 3. Group assignment (to be generated)\n",
    "group_labels = ('control', 'treatment')\n",
    "\n",
    "# 4. Experimental design variant: independent or paired\n",
    "variant = 'independent'  # Options: 'independent' (supported), 'paired' (not supported yet)\n",
    "\n",
    "# 5. Optional: Unique identifier for each observation (can be user_id, session_id, etc.)\n",
    "observation_id_col = 'user_id'\n",
    "\n",
    "# 6. Optional: Pre-experiment metric for CUPED, if used\n",
    "pre_experiment_metric = 'past_purchase_count'  # Can be None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38c98b",
   "metadata": {},
   "source": [
    "#### Other Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff851a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# ⚙️ Derived Controls\n",
    "# -------------------------\n",
    "\n",
    "group_count = len(group_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775b66c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomization_method = \"simple\"\n",
    "group_col = 'group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab20393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 🧪 Central Control Panel\n",
    "# -------------------------\n",
    "\n",
    "test_config = {\n",
    "    'outcome_metric_col': outcome_metric_col,\n",
    "    'outcome_metric_datatype': outcome_metric_datatype,\n",
    "    'group_labels': group_labels,\n",
    "    'group_count': group_count,\n",
    "    'variant': variant,\n",
    "    'observation_id_col': observation_id_col,\n",
    "    'pre_experiment_metric': pre_experiment_metric,\n",
    "\n",
    "    # To be filled in after diagnostic tests\n",
    "    'normality': None,\n",
    "    'equal_variance': None,\n",
    "    'family': None\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f1591",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cad63c",
   "metadata": {},
   "source": [
    "# Randomization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48c869",
   "metadata": {},
   "source": [
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "Randomization is used to ensure that observed differences in outcome metrics are due to the experiment, not pre-existing differences.\n",
    "\n",
    "- Prevents **selection bias** (e.g., users self-selecting into groups)  \n",
    "- Balances **confounding factors** like platform, region, or past behavior  \n",
    "- Enables **valid inference** through statistical testing\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab4fa6",
   "metadata": {},
   "source": [
    "### 🎯 Simple Randomization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7eea3",
   "metadata": {},
   "source": [
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "Each user is assigned to control or treatment with **equal probability**, independent of any characteristics.\n",
    "\n",
    "##### When to Use\n",
    "- Sample size is **large enough** to ensure natural balance  \n",
    "- No strong concern about **confounding variables**  \n",
    "- Need a **quick, default assignment** strategy\n",
    "\n",
    "##### How It Works\n",
    "- Assign each user randomly (e.g., 50/50 split)  \n",
    "- No grouping, segmentation, or blocking involved  \n",
    "- Groups are expected to balance out on average  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e9964e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_simple_randomization(df, group_labels=group_labels, group_col=group_col, seed=my_seed):\n",
    "    \"\"\"\n",
    "    Randomly assigns each row to one of the specified groups.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing observations\n",
    "    - group_labels: tuple of group names (default = ('control', 'treatment'))\n",
    "    - group_col: name of the column to store group assignments\n",
    "    - seed: random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with an added group assignment column\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    df[group_col] = np.random.choice(group_labels, size=len(df), replace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e703a33",
   "metadata": {},
   "source": [
    "### Stratified Sampling  \n",
    "\n",
    "\n",
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "Ensures that key segments (e.g., platform, region) are evenly represented across control and treatment.\n",
    "\n",
    "##### When to Use\n",
    "- User base is **naturally skewed** (e.g., 70% mobile, 30% desktop)  \n",
    "- Important to control for **known confounders** like geography or device  \n",
    "- You want balance **within subgroups**, not just overall\n",
    "\n",
    "##### How It Works\n",
    "- Pick a stratification variable (e.g., platform)  \n",
    "- Split population into strata (groups)  \n",
    "- Randomly assign users **within each stratum**  \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43aeb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stratified_randomization(df, stratify_col, group_labels=group_labels, group_col=group_col, seed=my_seed):\n",
    "    \"\"\"\n",
    "    Performs stratified randomization to assign rows into multiple groups while maintaining balance across strata.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to assign groups to\n",
    "    - stratify_col: column to balance across (e.g., platform, region)\n",
    "    - group_labels: list or tuple of group names\n",
    "    - group_col: name of the column to store group assignments\n",
    "    - seed: random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with a new group assignment column\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    df[group_col] = None\n",
    "    n_groups = len(group_labels)\n",
    "\n",
    "    # Stratify and assign\n",
    "    for stratum_value, stratum_df in df.groupby(stratify_col):\n",
    "        shuffled = stratum_df.sample(frac=1, random_state=seed)\n",
    "        group_assignments = np.tile(group_labels, int(np.ceil(len(shuffled) / n_groups)))[:len(shuffled)]\n",
    "        df.loc[shuffled.index, group_col] = group_assignments\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b69b4f6",
   "metadata": {},
   "source": [
    "### Block Randomization  \n",
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "Groups users into fixed-size blocks and randomly assigns groups within each block.\n",
    "\n",
    "##### When to Use\n",
    "- Users arrive in **time-based batches** (e.g., daily cohorts)  \n",
    "- Sample size is **small** and needs enforced balance  \n",
    "- You want to minimize **temporal or ordering effects**\n",
    "\n",
    "##### How It Works\n",
    "- Create blocks based on order or ID (e.g., every 10 users)  \n",
    "- Randomize assignments **within each block**  \n",
    "- Ensures near-equal split in every batch  \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04a062a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_block_randomization(df, observation_id_col, group_col=group_col, block_size=10, group_labels=group_labels, seed=my_seed):\n",
    "    \"\"\"\n",
    "    Assigns group labels using block randomization to ensure balance within fixed-size blocks.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to assign groups\n",
    "    - observation_id_col: Unique ID to sort and block on (e.g., user_id)\n",
    "    - group_col: Name of column to store assigned group labels\n",
    "    - block_size: Number of observations in each block\n",
    "    - group_labels: Tuple or list of group names (e.g., ('control', 'treatment', 'variant_B'))\n",
    "    - seed: Random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with a new column [group_col] indicating assigned group\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    df = df.sort_values(observation_id_col).reset_index(drop=True).copy()\n",
    "    n_groups = len(group_labels)\n",
    "\n",
    "    # Create block ID per row\n",
    "    df['_block'] = df.index // block_size\n",
    "\n",
    "    # Assign groups within each block\n",
    "    group_assignments = []\n",
    "    for _, block_df in df.groupby('_block'):\n",
    "        block_n = len(block_df)\n",
    "        reps = int(np.ceil(block_n / n_groups))\n",
    "        candidates = np.tile(group_labels, reps)[:block_n]\n",
    "        np.random.shuffle(candidates)\n",
    "        group_assignments.extend(candidates)\n",
    "\n",
    "    df[group_col] = group_assignments\n",
    "    df = df.drop(columns=['_block'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7433cc",
   "metadata": {},
   "source": [
    "### Match Pair Randomization\n",
    "\n",
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "Participants are **paired based on similar characteristics** before random group assignment.  \n",
    "This reduces variance and improves **statistical power** by ensuring balance on key covariates.\n",
    "\n",
    "##### When to Use\n",
    "- Small sample size with high risk of **confounding**\n",
    "- Outcomes influenced by user traits (e.g., **age, income, tenure**)  \n",
    "- Need to **minimize variance** across groups\n",
    "\n",
    "##### How It Works\n",
    "1. Identify important covariates (e.g., age, purchase history)  \n",
    "2. Sort users by those variables  \n",
    "3. Create matched pairs (or small groups)  \n",
    "4. Randomly assign one to **control**, the other to **treatment**  \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ba496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_matched_pair_randomization(df, sort_col, group_col=group_col, group_labels=group_labels):\n",
    "    \"\"\"\n",
    "    Assigns groups using matched-pair randomization based on a sorting variable.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to assign groups to\n",
    "    - sort_col: column used to sort users before pairing (e.g., engagement score)\n",
    "    - group_col: name of the column to store group assignments\n",
    "    - group_labels: tuple of group names (e.g., ('control', 'treatment'))\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with alternating group assignments within sorted pairs\n",
    "    \"\"\"\n",
    "    # Sort by matching variable so similar users are adjacent\n",
    "    df = df.sort_values(by=sort_col).reset_index(drop=True)\n",
    "\n",
    "    # Cycle through group labels for each row\n",
    "    df[group_col] = [group_labels[i % len(group_labels)] for i in range(len(df))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0872f04b",
   "metadata": {},
   "source": [
    "### Cluster Randomization\n",
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "Entire **groups or clusters** (e.g., cities, stores, schools) are assigned to control or treatment.  \n",
    "Used when it's impractical or risky to randomize individuals within a cluster.\n",
    "\n",
    "###### When to Use\n",
    "- Users naturally exist in **groups** (e.g., teams, locations, devices)\n",
    "- There's a risk of **interference** between users (e.g., word-of-mouth)\n",
    "- Operational or tech constraints prevent individual-level randomization\n",
    "\n",
    "###### How It Works\n",
    "1. Define the cluster unit (e.g., store, city)  \n",
    "2. Randomly assign each cluster to control or treatment  \n",
    "3. All users within the cluster inherit the group assignment  \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b28e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_cluster_randomization(df, cluster_col, group_col=group_col, group_labels=group_labels, seed=my_seed):\n",
    "    \"\"\"\n",
    "    Assigns groups using cluster-level randomization — all observations in a cluster\n",
    "    receive the same group assignment.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame to assign groups to\n",
    "    - cluster_col: column representing the cluster unit (e.g., city, store)\n",
    "    - group_col: name of the column where group labels will be stored\n",
    "    - group_labels: tuple of group names to randomly assign (e.g., ('control', 'treatment'))\n",
    "    - seed: random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with assigned groups at the cluster level\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Unique clusters (e.g., unique city/store values)\n",
    "    unique_clusters = df[cluster_col].unique()\n",
    "\n",
    "    # Randomly assign each cluster to a group\n",
    "    cluster_assignments = dict(\n",
    "        zip(unique_clusters, np.random.choice(group_labels, size=len(unique_clusters)))\n",
    "    )\n",
    "\n",
    "    # Map group assignments to full DataFrame\n",
    "    df[group_col] = df[cluster_col].map(cluster_assignments)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8419594",
   "metadata": {},
   "source": [
    "### CUPED (Controlled Pre-Experiment Data)\n",
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "A statistical adjustment that uses **pre-experiment behavior** to reduce variance and improve power.  \n",
    "It helps detect smaller effects without increasing sample size.\n",
    "\n",
    "##### When to Use\n",
    "- You have reliable **pre-experiment metrics** (e.g., past spend, engagement)\n",
    "- You want to **reduce variance** and improve test sensitivity\n",
    "- You’re dealing with **small lifts** or **costly sample sizes**\n",
    "\n",
    "##### How It Works\n",
    "1. Identify a pre-period metric **correlated with your outcome**\n",
    "2. Use regression to compute an adjustment (theta)  \n",
    "3. Subtract the correlated component from your outcome metric  \n",
    "4. Analyze the adjusted metric instead of the raw one  \n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86dda432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def apply_cuped(\n",
    "    df,\n",
    "    pre_metric,\n",
    "    outcome_metric_col,  # observed outcome column (e.g., engagement_score)\n",
    "    outcome_col=None,\n",
    "    group_col=group_col,\n",
    "    group_labels=group_labels,\n",
    "    seed=my_seed\n",
    "):\n",
    "    \"\"\"\n",
    "    Applies CUPED (Controlled Pre-Experiment Data) adjustment to reduce variance\n",
    "    in the outcome metric using a pre-experiment covariate.\n",
    "\n",
    "    CUPED is a post-randomization technique that reduces variance by adjusting the \n",
    "    observed outcome using a baseline (pre-metric) variable that is correlated \n",
    "    with the outcome.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Input DataFrame containing experiment data.\n",
    "    pre_metric : str\n",
    "        Column name of the pre-experiment covariate (e.g., 'past_purchase_count').\n",
    "        This is the variable used to compute the adjustment factor (theta).\n",
    "    outcome_metric_col : str\n",
    "        Column name of the original observed outcome (e.g., 'engagement_score') \n",
    "        that you are comparing across groups.\n",
    "    outcome_col : str, default=None\n",
    "        Name of the new column where the adjusted outcome will be stored.\n",
    "    group_col : str\n",
    "        Column indicating the experiment group assignment (e.g., 'control' vs 'treatment').\n",
    "    group_labels : tuple\n",
    "        Tuple containing the names of the experiment groups.\n",
    "    seed : int\n",
    "        Random seed for reproducibility (used only if randomness is introduced later).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with an additional column [outcome_col] containing the CUPED-adjusted outcome.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Step 1: Use actual observed experiment outcome\n",
    "    y = df[outcome_metric_col].values\n",
    "\n",
    "    # Step 2: Regress outcome on pre-metric to estimate correction factor (theta)\n",
    "    X = sm.add_constant(df[[pre_metric]])\n",
    "    theta = sm.OLS(y, X).fit().params[pre_metric]\n",
    "\n",
    "    # Step 3: Apply CUPED adjustment and save in new column\n",
    "    if outcome_col is None:\n",
    "        outcome_col = f'{outcome_metric_col}_cuped_adjusted'\n",
    "    df[outcome_col] = y - theta * df[pre_metric]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d47842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply randomization method\n",
    "if randomization_method == \"simple\":\n",
    "    users = apply_simple_randomization(users, group_col=group_col, seed=my_seed)\n",
    "\n",
    "elif randomization_method == \"stratified\":\n",
    "    users = apply_stratified_randomization(users, stratify_col='platform', group_col=group_col, seed=my_seed)\n",
    "\n",
    "elif randomization_method == \"block\":\n",
    "    users = apply_block_randomization(users, observation_id_col='user_id', group_col=group_col, block_size=10, seed=my_seed)\n",
    "\n",
    "elif randomization_method == \"matched_pair\":\n",
    "    users = apply_matched_pair_randomization(users, sort_col=outcome_metric_col, group_col=group_col, seed=my_seed)\n",
    "\n",
    "elif randomization_method == \"cluster\":\n",
    "    users = apply_cluster_randomization(users, cluster_col='city', group_col=group_col, seed=my_seed)\n",
    "\n",
    "elif randomization_method == \"cuped\":\n",
    "    users = apply_cuped(users, pre_metric='past_purchase_count', outcome_metric_col=outcome_metric_col, group_col=group_col, group_labels=group_labels, seed=my_seed)\n",
    "    # Update global outcome to CUPED-adjusted version\n",
    "    outcome_metric_col = f\"{outcome_metric_col}_cuped_adjusted\"\n",
    "else:\n",
    "    raise ValueError(f\"❌ Unsupported randomization method: {randomization_method}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbf7e94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>device_type</th>\n",
       "      <th>user_tier</th>\n",
       "      <th>region</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>city</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>converted</th>\n",
       "      <th>past_purchase_count</th>\n",
       "      <th>bounce_rate</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>iOS</td>\n",
       "      <td>mobile</td>\n",
       "      <td>new</td>\n",
       "      <td>East</td>\n",
       "      <td>basic</td>\n",
       "      <td>chicago</td>\n",
       "      <td>40.191524</td>\n",
       "      <td>0</td>\n",
       "      <td>60.899050</td>\n",
       "      <td>0.739936</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Android</td>\n",
       "      <td>mobile</td>\n",
       "      <td>new</td>\n",
       "      <td>West</td>\n",
       "      <td>premium</td>\n",
       "      <td>austin</td>\n",
       "      <td>50.409701</td>\n",
       "      <td>0</td>\n",
       "      <td>44.288160</td>\n",
       "      <td>0.692463</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Android</td>\n",
       "      <td>desktop</td>\n",
       "      <td>returning</td>\n",
       "      <td>South</td>\n",
       "      <td>premium</td>\n",
       "      <td>chicago</td>\n",
       "      <td>49.289439</td>\n",
       "      <td>1</td>\n",
       "      <td>50.438288</td>\n",
       "      <td>0.232384</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>iOS</td>\n",
       "      <td>desktop</td>\n",
       "      <td>new</td>\n",
       "      <td>East</td>\n",
       "      <td>basic</td>\n",
       "      <td>austin</td>\n",
       "      <td>26.267349</td>\n",
       "      <td>0</td>\n",
       "      <td>59.558027</td>\n",
       "      <td>0.535306</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>iOS</td>\n",
       "      <td>desktop</td>\n",
       "      <td>new</td>\n",
       "      <td>East</td>\n",
       "      <td>basic</td>\n",
       "      <td>austin</td>\n",
       "      <td>35.894016</td>\n",
       "      <td>0</td>\n",
       "      <td>45.157416</td>\n",
       "      <td>0.669822</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>iOS</td>\n",
       "      <td>mobile</td>\n",
       "      <td>returning</td>\n",
       "      <td>West</td>\n",
       "      <td>basic</td>\n",
       "      <td>chicago</td>\n",
       "      <td>41.588586</td>\n",
       "      <td>0</td>\n",
       "      <td>49.540712</td>\n",
       "      <td>0.639349</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>iOS</td>\n",
       "      <td>mobile</td>\n",
       "      <td>returning</td>\n",
       "      <td>West</td>\n",
       "      <td>basic</td>\n",
       "      <td>sf</td>\n",
       "      <td>19.456692</td>\n",
       "      <td>0</td>\n",
       "      <td>49.834316</td>\n",
       "      <td>0.689519</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Android</td>\n",
       "      <td>desktop</td>\n",
       "      <td>returning</td>\n",
       "      <td>North</td>\n",
       "      <td>basic</td>\n",
       "      <td>austin</td>\n",
       "      <td>50.712402</td>\n",
       "      <td>0</td>\n",
       "      <td>56.833245</td>\n",
       "      <td>0.663517</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Android</td>\n",
       "      <td>mobile</td>\n",
       "      <td>new</td>\n",
       "      <td>East</td>\n",
       "      <td>premium</td>\n",
       "      <td>chicago</td>\n",
       "      <td>46.263922</td>\n",
       "      <td>0</td>\n",
       "      <td>55.907443</td>\n",
       "      <td>0.704955</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Android</td>\n",
       "      <td>mobile</td>\n",
       "      <td>returning</td>\n",
       "      <td>North</td>\n",
       "      <td>basic</td>\n",
       "      <td>ny</td>\n",
       "      <td>24.906591</td>\n",
       "      <td>0</td>\n",
       "      <td>47.798863</td>\n",
       "      <td>0.546476</td>\n",
       "      <td>treatment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id platform device_type  user_tier region plan_type     city  \\\n",
       "0        1      iOS      mobile        new   East     basic  chicago   \n",
       "1        2  Android      mobile        new   West   premium   austin   \n",
       "2        3  Android     desktop  returning  South   premium  chicago   \n",
       "3        4      iOS     desktop        new   East     basic   austin   \n",
       "4        5      iOS     desktop        new   East     basic   austin   \n",
       "5        6      iOS      mobile  returning   West     basic  chicago   \n",
       "6        7      iOS      mobile  returning   West     basic       sf   \n",
       "7        8  Android     desktop  returning  North     basic   austin   \n",
       "8        9  Android      mobile        new   East   premium  chicago   \n",
       "9       10  Android      mobile  returning  North     basic       ny   \n",
       "\n",
       "   engagement_score  converted  past_purchase_count  bounce_rate      group  \n",
       "0         40.191524          0            60.899050     0.739936    control  \n",
       "1         50.409701          0            44.288160     0.692463  treatment  \n",
       "2         49.289439          1            50.438288     0.232384    control  \n",
       "3         26.267349          0            59.558027     0.535306    control  \n",
       "4         35.894016          0            45.157416     0.669822    control  \n",
       "5         41.588586          0            49.540712     0.639349  treatment  \n",
       "6         19.456692          0            49.834316     0.689519    control  \n",
       "7         50.712402          0            56.833245     0.663517    control  \n",
       "8         46.263922          0            55.907443     0.704955    control  \n",
       "9         24.906591          0            47.798863     0.546476  treatment  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73691185",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23948c42",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09901d14",
   "metadata": {},
   "source": [
    "#### Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d8c77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "def test_normality(df, outcome_metric_col, group_col, group_labels):\n",
    "    results = {}\n",
    "    for group in group_labels:\n",
    "        group_data = df[df[group_col] == group][outcome_metric_col]\n",
    "        stat, p = shapiro(group_data)\n",
    "        results[group] = {'statistic': stat, 'p_value': p, 'normal': p > 0.05}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2525c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality test (Shapiro-Wilk) results:\n",
      "control: p = 0.3252 → Normal\n",
      "treatment: p = 0.5486 → Normal\n"
     ]
    }
   ],
   "source": [
    "normality_results = test_normality(users, outcome_metric_col=outcome_metric_col, group_col='group', group_labels=group_labels)\n",
    "\n",
    "print(\"Normality test (Shapiro-Wilk) results:\")\n",
    "for group, result in normality_results.items():\n",
    "    print(f\"{group}: p = {result['p_value']:.4f} → {'Normal' if result['normal'] else 'Non-normal'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "171688c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_metric_col': 'engagement_score',\n",
       " 'outcome_metric_datatype': 'continuous',\n",
       " 'group_labels': ('control', 'treatment'),\n",
       " 'group_count': 2,\n",
       " 'variant': 'independent',\n",
       " 'observation_id_col': 'user_id',\n",
       " 'pre_experiment_metric': 'past_purchase_count',\n",
       " 'normality': True,\n",
       " 'equal_variance': None,\n",
       " 'family': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume both groups must be normal to proceed with parametric tests\n",
    "test_config['normality'] = all(result['normal'] for result in normality_results.values())\n",
    "test_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583e166",
   "metadata": {},
   "source": [
    "#### Variance Homogeneity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93caa915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "def test_equal_variance(df, outcome_metric_col, group_col, group_labels):\n",
    "    group_data = [df[df[group_col] == label][outcome_metric_col] for label in group_labels]\n",
    "    stat, p = levene(*group_data)\n",
    "    return {'statistic': stat, 'p_value': p, 'equal_variance': p > 0.05}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "852916f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statistic': 0.24844666871679105,\n",
       " 'p_value': 0.6182807851868815,\n",
       " 'equal_variance': True}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance_result = test_equal_variance(users, outcome_metric_col=outcome_metric_col, group_col='group', group_labels=group_labels)\n",
    "variance_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9a1ac86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene’s test: p = 0.6183 → Equal variances\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'outcome_metric_col': 'engagement_score',\n",
       " 'outcome_metric_datatype': 'continuous',\n",
       " 'group_labels': ('control', 'treatment'),\n",
       " 'group_count': 2,\n",
       " 'variant': 'independent',\n",
       " 'observation_id_col': 'user_id',\n",
       " 'pre_experiment_metric': 'past_purchase_count',\n",
       " 'normality': True,\n",
       " 'equal_variance': True,\n",
       " 'family': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Levene’s test: p = {variance_result['p_value']:.4f} → {'Equal variances' if variance_result['equal_variance'] else 'Unequal variances'}\")\n",
    "test_config['equal_variance'] = variance_result['equal_variance']\n",
    "test_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150fee7",
   "metadata": {},
   "source": [
    "#### Test Family"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aadf7b",
   "metadata": {},
   "source": [
    "🧪 Experiment Type → Test Family Mapping\n",
    "\n",
    "| Outcome Type     | Normality | Group Count | Selected Test Family                      |\n",
    "|------------------|-----------|--------------|-------------------------------------------|\n",
    "| **binary**       | —         | 2            | `z_test`                                   |\n",
    "| **binary**       | —         | 3+           | `chi_square`                               |\n",
    "| **continuous**   | ✅        | 2            | `t_test`                                   |\n",
    "| **continuous**   | ✅        | 3+           | `anova`                                    |\n",
    "| **continuous**   | ❌        | 2            | `non_parametric` (Mann-Whitney U)         |\n",
    "| **continuous**   | ❌        | 3+           | `non_parametric` (Kruskal-Wallis)         |\n",
    "| **categorical**  | —         | 2            | `chi_square`                               |\n",
    "| **categorical**  | —         | 3+           | `chi_square`                               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "990d8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_test_family(test_config):\n",
    "    \"\"\"\n",
    "    Decide which family of statistical test to use based on:\n",
    "    - outcome data type: binary / continuous / categorical\n",
    "    - group count: 2 or 3+\n",
    "    - variant: independent or paired (optional for family level)\n",
    "    - normality assumption: passed or not\n",
    "    \"\"\"\n",
    "\n",
    "    data_type = test_config['outcome_metric_datatype']\n",
    "    group_count = test_config['group_count']\n",
    "    variant = test_config['variant']\n",
    "    normality = test_config['normality']\n",
    "\n",
    "    # Binary outcome → Z-test for 2 groups, Chi-square for 3+ groups\n",
    "    if data_type == 'binary':\n",
    "        if group_count == 2:\n",
    "            return 'z_test'           # Compare proportions across 2 groups\n",
    "        else:\n",
    "            return 'chi_square'      # 2x3+ contingency test\n",
    "\n",
    "    # Continuous outcome → check for normality and group count\n",
    "    elif data_type == 'continuous':\n",
    "        if not normality:\n",
    "            return 'non_parametric'  # Mann-Whitney U or Kruskal-Wallis\n",
    "        if group_count == 2:\n",
    "            return 't_test'          # Independent or paired t-test\n",
    "        else:\n",
    "            return 'anova'           # One-way ANOVA\n",
    "\n",
    "    # Categorical outcome → Chi-square always\n",
    "    elif data_type == 'categorical':\n",
    "        return 'chi_square'\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported outcome_metric_datatype: {data_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f8bb05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_metric_col': 'engagement_score',\n",
       " 'outcome_metric_datatype': 'continuous',\n",
       " 'group_labels': ('control', 'treatment'),\n",
       " 'group_count': 2,\n",
       " 'variant': 'independent',\n",
       " 'observation_id_col': 'user_id',\n",
       " 'pre_experiment_metric': 'past_purchase_count',\n",
       " 'normality': True,\n",
       " 'equal_variance': True,\n",
       " 'family': 't_test'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Selected test family: t_test\n"
     ]
    }
   ],
   "source": [
    "test_config['family'] = determine_test_family(test_config)\n",
    "test_config\n",
    "\n",
    "print(f\"✅ Selected test family: {test_config['family']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e172b5d",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d61b9",
   "metadata": {},
   "source": [
    "# AA Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0f628",
   "metadata": {},
   "source": [
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "\n",
    "A/A testing is a **preliminary experiment** where both groups (e.g., “control” and “treatment”) receive the exact same experience. It's used to validate the experimental setup before running an actual A/B test.\n",
    "\n",
    "##### What Are We Checking?\n",
    "- Are users being assigned fairly and randomly?\n",
    "- Are key outcome metrics statistically similar across groups?\n",
    "- Can we trust the experimental framework?\n",
    "\n",
    "##### Why A/A Testing Matters\n",
    "- **Validates Randomization**  \n",
    "  Confirms the groups are balanced at baseline (no bias or leakage)\n",
    "  \n",
    "- **Detects SRM (Sample Ratio Mismatch)**  \n",
    "  Ensures the actual split (e.g., 50/50) matches what was intended\n",
    "  \n",
    "- **Estimates Variability**  \n",
    "  Helps calibrate variance for accurate power calculations later\n",
    "  \n",
    "- **Trust Check**  \n",
    "  Catches bugs in assignment logic, event tracking, or instrumentation\n",
    "\n",
    "##### A/A Test Process\n",
    "\n",
    "1. **Randomly assign users** into two equal groups  \n",
    "   Just like you would for an A/B test (e.g., control vs treatment)\n",
    "\n",
    "2. **Measure key outcome**  \n",
    "   This depends on your experiment type:  \n",
    "   - `binary` → conversion rate  \n",
    "   - `continuous` → avg. revenue, time spent  \n",
    "   - `categorical` → feature adoption, plan selected\n",
    "\n",
    "3. **Run statistical test**  \n",
    "   - `binary` → Z-test or Chi-square  \n",
    "   - `continuous` → t-test  \n",
    "   - `categorical` → Chi-square test\n",
    "\n",
    "4. **Check SRM**  \n",
    "   Use a chi-square goodness-of-fit test to detect assignment imbalances\n",
    "\n",
    "##### Possible Outcomes\n",
    "| Result                            | Interpretation                                     |\n",
    "|-----------------------------------|----------------------------------------------------|\n",
    "| No significant difference         | ✅ Randomization looks good. Test setup is sound.  |\n",
    "| Statistically significant difference | ⚠️ Something’s off — check assignment logic, instrumentation, or sample leakage |\n",
    "\n",
    "*Run A/A tests whenever you launch a new experiment framework, roll out a new randomizer, or need to build stakeholder trust.*\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82acab3b",
   "metadata": {},
   "source": [
    "##### SRM Check \n",
    "\n",
    "\n",
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "Is group assignment balanced?\n",
    "- SRM (Sample Ratio Mismatch) checks whether the observed group sizes match the expected ratio.\n",
    "- In a perfect world, random assignment to 'A1' and 'A2' should give ~50/50 split.\n",
    "- SRM helps catch bugs in randomization, data logging, or user eligibility filtering.\n",
    "\n",
    "##### Real-World Experiment Split Ratios\n",
    "| **Scenario**                     | **Split**              | **Why**                                 |\n",
    "|----------------------------------|------------------------|------------------------------------------|\n",
    "| Default A/B                      | 50 / 50                | Maximizes power and ensures fairness     |\n",
    "| Risky feature                    | 10 / 90 or 20 / 80     | Limits user exposure to minimize risk    |\n",
    "| Ramp-up                          | Step-wise (1-5-25-50…) | Gradual rollout to catch issues early    |\n",
    "| A/B/C Test                       | 33 / 33 / 33 or weighted | Compare multiple variants fairly or with bias |\n",
    "| High control confidence needed   | 70 / 30 or 60 / 40     | More stability in baseline comparisons   |\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2575b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sample_ratio_mismatch(df, group_col, group_labels, expected_ratios=None, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Checks for Sample Ratio Mismatch (SRM) using Chi-Square test.\n",
    "\n",
    "    Parameters:\n",
    "    - df : pd.DataFrame\n",
    "        The dataset containing group assignments.\n",
    "    - group_col : str\n",
    "        Column name where group assignment is stored.\n",
    "    - group_labels : list or tuple\n",
    "        List of group labels (e.g., ['control', 'treatment'])\n",
    "    - expected_ratios : list or tuple\n",
    "        Expected traffic allocation ratios per group (must match order in group_labels).\n",
    "        If None, assumes equal allocation to all groups.\n",
    "    - alpha : float\n",
    "        Significance level for SRM detection.\n",
    "\n",
    "    Returns:\n",
    "    - None (prints results)\n",
    "    \"\"\"\n",
    "    print(\"🔍 Sample Ratio Mismatch (SRM) Check\")\n",
    "\n",
    "    observed_counts = df[group_col].value_counts().reindex(group_labels, fill_value=0)\n",
    "\n",
    "    if expected_ratios is None:\n",
    "        expected_ratios = [1 / len(group_labels)] * len(group_labels)\n",
    "    else:\n",
    "        total = sum(expected_ratios)\n",
    "        expected_ratios = [r / total for r in expected_ratios]  # Normalize to sum to 1\n",
    "\n",
    "    expected_counts = [len(df) * ratio for ratio in expected_ratios]\n",
    "\n",
    "    # Print group breakdown\n",
    "    for grp, expected in zip(group_labels, expected_counts):\n",
    "        observed = observed_counts.get(grp, 0)\n",
    "        pct = observed / len(df) * 100\n",
    "        print(f\"Group {grp}: {observed} users ({pct:.2f}%) — Expected: {expected:.1f}\")\n",
    "\n",
    "    # Chi-square test\n",
    "    chi2_stat, chi2_p = stats.chisquare(f_obs=observed_counts, f_exp=expected_counts)\n",
    "    print(f\"\\nChi2 Statistic: {chi2_stat:.4f}\")\n",
    "    print(f\"P-value       : {chi2_p:.4f}\")\n",
    "    if chi2_p < alpha:\n",
    "        print(\"⚠️ SRM Detected — investigate group assignment.\\n\")\n",
    "    else:\n",
    "        print(\"✅ No SRM — group sizes look balanced.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "762d5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_outcome_similarity_test(df, group_col, metric_col, experiment_type, group_labels, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Runs outcome similarity test between two groups based on experiment_type.\n",
    "    Returns p-value and prints human-readable interpretation.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - group_col: column name representing group assignment\n",
    "    - metric_col: column name of the outcome metric\n",
    "    - experiment_type: one of ['binary', 'continuous_independent', 'continuous_paired', 'categorical']\n",
    "    - group_labels: tuple of (control_group_name, treatment_group_name)\n",
    "    - alpha: significance level (default 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - p-value (float)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"📏 Outcome Similarity Check\\n\")\n",
    "\n",
    "    # Subset values\n",
    "    group1_data = df[df[group_col] == group_labels[0]][metric_col]\n",
    "    group2_data = df[df[group_col] == group_labels[1]][metric_col]\n",
    "\n",
    "    if experiment_type == 'binary':\n",
    "        conv1, conv2 = group1_data.mean(), group2_data.mean()\n",
    "        n1, n2 = len(group1_data), len(group2_data)\n",
    "        pooled_prob = (group1_data.sum() + group2_data.sum()) / (n1 + n2)\n",
    "        se = np.sqrt(pooled_prob * (1 - pooled_prob) * (1/n1 + 1/n2))\n",
    "        z_score = (conv2 - conv1) / se\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "        test_name = \"z-test for proportions\"\n",
    "\n",
    "        print(f\"Conversion Rate — {group_labels[0]}: {conv1:.4f}, {group_labels[1]}: {conv2:.4f}\")\n",
    "        print(f\"Z-score: {z_score:.4f}\")\n",
    "        print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "    elif experiment_type == 'continuous_independent':\n",
    "        t_stat, p_value = stats.ttest_ind(group1_data, group2_data, equal_var=False)\n",
    "        test_name = \"independent t-test\"\n",
    "        print(f\"T-statistic: {t_stat:.4f}\")\n",
    "        print(f\"P-value    : {p_value:.4f}\")\n",
    "\n",
    "    elif experiment_type == 'continuous_paired':\n",
    "        if len(group1_data) != len(group2_data):\n",
    "            print(\"❌ Paired t-test requires equal number of observations in each group.\")\n",
    "            return None\n",
    "        t_stat, p_value = stats.ttest_rel(group1_data, group2_data)\n",
    "        test_name = \"paired t-test\"\n",
    "        print(f\"Paired T-statistic: {t_stat:.4f}\")\n",
    "        print(f\"P-value           : {p_value:.4f}\")\n",
    "\n",
    "    elif experiment_type == 'categorical':\n",
    "        contingency = pd.crosstab(df[group_col], df[metric_col])\n",
    "        chi2_stat, p_value, _, _ = stats.chi2_contingency(contingency)\n",
    "        test_name = \"chi-square test\"\n",
    "        print(\"Chi-square test on categorical outcome\")\n",
    "        print(f\"Chi2-statistic: {chi2_stat:.4f}\")\n",
    "        print(f\"P-value       : {p_value:.4f}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"❌ Unsupported experiment_type: {experiment_type}\")\n",
    "        return None\n",
    "\n",
    "    # ---------------- Interpretation ----------------\n",
    "    print(\"\\n🧠 Interpretation:\")\n",
    "    if experiment_type == 'binary':\n",
    "        print(f\"Used a {test_name} to compare conversion rates between groups.\")\n",
    "        print(\"Null Hypothesis: conversion rates are the same.\")\n",
    "    elif experiment_type.startswith('continuous'):\n",
    "        print(f\"Used a {test_name} to compare means of '{metric_col}' across groups.\")\n",
    "        print(\"Null Hypothesis: population means are equal.\")\n",
    "    elif experiment_type == 'categorical':\n",
    "        print(f\"Used a {test_name} to test whether '{metric_col}' distribution depends on group.\")\n",
    "        print(\"Null Hypothesis: no association between group and category.\")\n",
    "\n",
    "    print(f\"\\nWe use α = {alpha:.2f}\")\n",
    "    if p_value < alpha:\n",
    "        print(f\"➡️ p = {p_value:.4f} < α → Reject null hypothesis. Statistically significant difference.\")\n",
    "    else:\n",
    "        print(f\"➡️ p = {p_value:.4f} ≥ α → Fail to reject null. No statistically significant difference.\")\n",
    "\n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37f8483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_aa_distribution(\n",
    "    df,\n",
    "    group1,\n",
    "    group2,\n",
    "    group_col,\n",
    "    metric_col,\n",
    "    experiment_type,\n",
    "    group_labels=('control', 'treatment')\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualizes A/A test outcome distributions based on experiment type.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Original DataFrame (needed for categorical visual)\n",
    "    - group1, group2: Series of metric values for each group\n",
    "    - group_col: Name of the group assignment column\n",
    "    - metric_col: Name of the metric/outcome column\n",
    "    - experiment_type: 'binary', 'continuous_independent', 'continuous_paired', or 'categorical'\n",
    "    - group_labels: Tuple of group names (default: ('control', 'treatment'))\n",
    "    \"\"\"\n",
    "    if experiment_type.startswith('continuous'):\n",
    "        plt.hist(group1, bins=30, alpha=0.5, label=group_labels[0])\n",
    "        plt.hist(group2, bins=30, alpha=0.5, label=group_labels[1])\n",
    "        plt.title(f'A/A Test: {metric_col} Distribution')\n",
    "        plt.xlabel(metric_col)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "\n",
    "    elif experiment_type == 'binary':\n",
    "        rates = [group1.mean(), group2.mean()]\n",
    "        plt.bar(group_labels, rates)\n",
    "        for i, rate in enumerate(rates):\n",
    "            plt.text(i, rate + 0.01, f\"{rate:.2%}\", ha='center')\n",
    "        plt.title(f'A/A Test: Conversion Rate by Group')\n",
    "        plt.ylabel('Conversion Rate')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.show();\n",
    "\n",
    "    elif experiment_type == 'categorical':\n",
    "        contingency = pd.crosstab(df[group_col], df[metric_col], normalize='index')\n",
    "        contingency.plot(kind='bar', stacked=True)\n",
    "        plt.title(f'A/A Test: Distribution of {metric_col} by Group')\n",
    "        plt.ylabel('Proportion')\n",
    "        plt.xlabel(group_col)\n",
    "        plt.legend(title=metric_col)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dc842a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_aa_testing_generalized(\n",
    "    df,\n",
    "    group_col='group',\n",
    "    metric_col='engagement_score',\n",
    "    group_labels=('control', 'treatment'),\n",
    "    experiment_type='continuous_independent',\n",
    "    alpha=0.05,\n",
    "    visualize=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a generalized A/A test including SRM check, statistical test, and optional visualization.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Input DataFrame\n",
    "    - group_col: Column specifying group assignment\n",
    "    - metric_col: Metric to test (e.g., conversion rate, engagement score)\n",
    "    - group_labels: Tuple of (control, treatment) group names\n",
    "    - experiment_type: 'binary', 'continuous_independent', 'continuous_paired', or 'categorical'\n",
    "    - alpha: Significance level\n",
    "    - visualize: Whether to show distribution plots\n",
    "    \"\"\"\n",
    "    print(f\"\\n📊 A/A Test Summary for metric: '{metric_col}' [{experiment_type}]\\n\")\n",
    "\n",
    "    check_sample_ratio_mismatch(df, group_col, group_labels, alpha=alpha, expected_ratios=[0.5, 0.5])\n",
    "\n",
    "    group1 = df[df[group_col] == group_labels[0]][metric_col]\n",
    "    group2 = df[df[group_col] == group_labels[1]][metric_col]\n",
    "\n",
    "    p_value = run_outcome_similarity_test(\n",
    "        df=df,\n",
    "        group_col=group_col,\n",
    "        metric_col=metric_col,\n",
    "        experiment_type=experiment_type,\n",
    "        group_labels=group_labels,\n",
    "        alpha=alpha\n",
    "    )\n",
    "\n",
    "    if visualize and p_value is not None:\n",
    "        visualize_aa_distribution(\n",
    "            df, group1, group2,\n",
    "            group_col=group_col,\n",
    "            metric_col=metric_col,\n",
    "            experiment_type=experiment_type,\n",
    "            group_labels=group_labels\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4952ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_family_to_experiment_type(config):\n",
    "    if config['family'] == 'z_test':\n",
    "        return 'binary'\n",
    "    elif config['family'] == 't_test':\n",
    "        return 'continuous_independent' if config['variant'] == 'independent' else 'continuous_paired'\n",
    "    elif config['family'] == 'anova':\n",
    "        return 'continuous_independent'\n",
    "    elif config['family'] == 'chi_square':\n",
    "        return 'categorical'\n",
    "    elif config['family'] == 'non_parametric':\n",
    "        return 'continuous_independent'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported test family: {config['family']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0eaa581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 A/A Test Summary for metric: 'engagement_score' [continuous_independent]\n",
      "\n",
      "🔍 Sample Ratio Mismatch (SRM) Check\n",
      "Group control: 490 users (49.00%) — Expected: 500.0\n",
      "Group treatment: 510 users (51.00%) — Expected: 500.0\n",
      "\n",
      "Chi2 Statistic: 0.4000\n",
      "P-value       : 0.5271\n",
      "✅ No SRM — group sizes look balanced.\n",
      "\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.6813\n",
      "P-value    : 0.4958\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.4958 ≥ α → Fail to reject null. No statistically significant difference.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_aa_testing_generalized(\n",
    "    df=users,\n",
    "    group_col='group',\n",
    "    metric_col=test_config['outcome_metric_col'],\n",
    "    group_labels=test_config['group_labels'],\n",
    "    experiment_type=map_family_to_experiment_type(test_config),\n",
    "    alpha=0.05\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002e7d0",
   "metadata": {},
   "source": [
    "#### 🔁 Repeated A/A Tests (Type I Error Simulation)\n",
    "\n",
    "While a single A/A test helps detect obvious flaws in group assignment (like SRM or data leakage), it’s still a one-off check.  \n",
    "To gain confidence in your randomization method, we simulate **multiple A/A tests** using the same logic:\n",
    "\n",
    "- Each run reassigns users randomly into `control` and `treatment` (with no actual change)\n",
    "- We then run the statistical test between groups for each simulation\n",
    "- We track how often the test reports a **false positive** (p < α), which estimates the **Type I error rate**\n",
    "\n",
    "> In theory, if your setup is unbiased and α = 0.05, you'd expect about 5% of simulations to return a significant result — this validates your A/B framework isn’t \"trigger-happy.\"\n",
    "\n",
    "#### 📊 What this tells you:\n",
    "- Too many significant p-values → your framework is too noisy (bad randomization, poor test choice)\n",
    "- Near 5% = healthy noise level, expected by design\n",
    "\n",
    "This step is optional but highly recommended when you're:\n",
    "- Trying out a new randomization strategy\n",
    "- Validating an internal experimentation framework\n",
    "- Stress-testing your end-to-end pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57319664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.6813\n",
      "P-value    : 0.4958\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.4958 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.1693\n",
      "P-value    : 0.2425\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2425 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.2005\n",
      "P-value    : 0.8411\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8411 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.4247\n",
      "P-value    : 0.6712\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6712 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.1353\n",
      "P-value    : 0.8924\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8924 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.9418\n",
      "P-value    : 0.3465\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.3465 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.5034\n",
      "P-value    : 0.6148\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6148 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.2862\n",
      "P-value    : 0.1987\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1987 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.6073\n",
      "P-value    : 0.5438\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.5438 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.3329\n",
      "P-value    : 0.7393\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7393 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.9883\n",
      "P-value    : 0.3232\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.3232 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.9718\n",
      "P-value    : 0.0489\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0489 < α → Reject null hypothesis. Statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.3644\n",
      "P-value    : 0.7157\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7157 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.2414\n",
      "P-value    : 0.2148\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2148 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.1345\n",
      "P-value    : 0.8930\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8930 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.7926\n",
      "P-value    : 0.4282\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.4282 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.4800\n",
      "P-value    : 0.1392\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1392 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.4642\n",
      "P-value    : 0.6426\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6426 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.2267\n",
      "P-value    : 0.8207\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8207 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.0371\n",
      "P-value    : 0.2999\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2999 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.3526\n",
      "P-value    : 0.1765\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1765 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.4796\n",
      "P-value    : 0.6316\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6316 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.2645\n",
      "P-value    : 0.7915\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7915 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.5809\n",
      "P-value    : 0.5615\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.5615 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.1092\n",
      "P-value    : 0.9131\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.9131 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.1571\n",
      "P-value    : 0.2475\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2475 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.1750\n",
      "P-value    : 0.2403\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2403 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.4372\n",
      "P-value    : 0.6621\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6621 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -2.1045\n",
      "P-value    : 0.0356\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0356 < α → Reject null hypothesis. Statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.2605\n",
      "P-value    : 0.7945\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7945 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.7442\n",
      "P-value    : 0.4569\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.4569 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.5763\n",
      "P-value    : 0.1153\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1153 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.1296\n",
      "P-value    : 0.8969\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8969 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.5126\n",
      "P-value    : 0.6084\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6084 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.1812\n",
      "P-value    : 0.8562\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8562 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.2716\n",
      "P-value    : 0.7860\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7860 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.0423\n",
      "P-value    : 0.9663\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.9663 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.6005\n",
      "P-value    : 0.5483\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.5483 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.6437\n",
      "P-value    : 0.5199\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.5199 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.2868\n",
      "P-value    : 0.7743\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7743 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.8982\n",
      "P-value    : 0.3693\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.3693 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.8245\n",
      "P-value    : 0.4098\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.4098 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.3109\n",
      "P-value    : 0.7559\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7559 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.3988\n",
      "P-value    : 0.6901\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6901 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.8027\n",
      "P-value    : 0.4224\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.4224 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.5094\n",
      "P-value    : 0.1315\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1315 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.3752\n",
      "P-value    : 0.7076\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7076 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.7877\n",
      "P-value    : 0.4311\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.4311 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.9190\n",
      "P-value    : 0.3583\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.3583 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.2696\n",
      "P-value    : 0.7875\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7875 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.0705\n",
      "P-value    : 0.2846\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2846 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.1938\n",
      "P-value    : 0.2328\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2328 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.4292\n",
      "P-value    : 0.1533\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1533 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.4604\n",
      "P-value    : 0.6453\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6453 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.4400\n",
      "P-value    : 0.6601\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6601 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.7903\n",
      "P-value    : 0.0737\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0737 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.6199\n",
      "P-value    : 0.1056\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1056 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.8491\n",
      "P-value    : 0.3960\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.3960 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.1954\n",
      "P-value    : 0.2322\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2322 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.0467\n",
      "P-value    : 0.9627\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.9627 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.5595\n",
      "P-value    : 0.5759\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.5759 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.1558\n",
      "P-value    : 0.8762\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8762 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.6252\n",
      "P-value    : 0.5320\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.5320 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.8281\n",
      "P-value    : 0.0678\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0678 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.3500\n",
      "P-value    : 0.1773\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1773 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.2439\n",
      "P-value    : 0.2138\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2138 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.2551\n",
      "P-value    : 0.7987\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7987 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -2.2512\n",
      "P-value    : 0.0246\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0246 < α → Reject null hypothesis. Statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.2211\n",
      "P-value    : 0.8251\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8251 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.1656\n",
      "P-value    : 0.8685\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8685 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.8660\n",
      "P-value    : 0.3867\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.3867 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.1628\n",
      "P-value    : 0.2452\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2452 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -2.7229\n",
      "P-value    : 0.0066\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0066 < α → Reject null hypothesis. Statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.3513\n",
      "P-value    : 0.1769\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1769 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.2979\n",
      "P-value    : 0.1946\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1946 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.7473\n",
      "P-value    : 0.0809\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0809 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.2457\n",
      "P-value    : 0.2132\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2132 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.0413\n",
      "P-value    : 0.9670\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.9670 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.3365\n",
      "P-value    : 0.7366\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7366 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.3368\n",
      "P-value    : 0.7364\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7364 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.1974\n",
      "P-value    : 0.8435\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.8435 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.0121\n",
      "P-value    : 0.9903\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.9903 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.3839\n",
      "P-value    : 0.7012\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7012 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.7288\n",
      "P-value    : 0.4663\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.4663 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.9333\n",
      "P-value    : 0.3509\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.3509 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.3485\n",
      "P-value    : 0.7275\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7275 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.7455\n",
      "P-value    : 0.0812\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0812 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.1177\n",
      "P-value    : 0.2639\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.2639 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.2728\n",
      "P-value    : 0.7851\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7851 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.3269\n",
      "P-value    : 0.7438\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7438 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.8546\n",
      "P-value    : 0.3930\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.3930 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.7790\n",
      "P-value    : 0.0755\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0755 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.4667\n",
      "P-value    : 0.6408\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.6408 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 0.0508\n",
      "P-value    : 0.9595\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.9595 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.6525\n",
      "P-value    : 0.0987\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.0987 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -1.3562\n",
      "P-value    : 0.1753\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1753 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.9816\n",
      "P-value    : 0.3265\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.3265 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: 1.4308\n",
      "P-value    : 0.1528\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.1528 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.8103\n",
      "P-value    : 0.4180\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.4180 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "📏 Outcome Similarity Check\n",
      "\n",
      "T-statistic: -0.3593\n",
      "P-value    : 0.7195\n",
      "\n",
      "🧠 Interpretation:\n",
      "Used a independent t-test to compare means of 'engagement_score' across groups.\n",
      "Null Hypothesis: population means are equal.\n",
      "\n",
      "We use α = 0.05\n",
      "➡️ p = 0.7195 ≥ α → Fail to reject null. No statistically significant difference.\n",
      "\n",
      "📈 Type I Error Rate Estimate: 4/100 = 4.00%\n"
     ]
    }
   ],
   "source": [
    "def simulate_aa_type1_error_rate(\n",
    "    df,\n",
    "    metric_col,\n",
    "    group_labels,\n",
    "    experiment_type,\n",
    "    runs=100,\n",
    "    alpha=0.05,\n",
    "    seed=42\n",
    "):\n",
    "    np.random.seed(seed)\n",
    "    p_values = []\n",
    "    for i in range(runs):\n",
    "        shuffled_df = df.copy()\n",
    "        shuffled_df['group'] = np.random.choice(group_labels, size=len(df))\n",
    "        p = run_outcome_similarity_test(\n",
    "            shuffled_df,\n",
    "            group_col='group',\n",
    "            metric_col=metric_col,\n",
    "            experiment_type=experiment_type,\n",
    "            group_labels=group_labels,\n",
    "            alpha=alpha\n",
    "        )\n",
    "        if p is not None:\n",
    "            p_values.append(p)\n",
    "\n",
    "    significant = sum(p < alpha for p in p_values)\n",
    "    print(f\"\\n📈 Type I Error Rate Estimate: {significant}/{runs} = {significant / runs:.2%}\")\n",
    "\n",
    "\n",
    "simulate_aa_type1_error_rate(\n",
    "    users,\n",
    "    metric_col=test_config['outcome_metric_col'],\n",
    "    group_labels=test_config['group_labels'],\n",
    "    experiment_type=map_family_to_experiment_type(test_config),\n",
    "    runs=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb059a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For continuous metric like engagement_score\n",
    "# run_aa_testing_generalized(users, group_col='group', metric_col='engagement_score', experiment_type='continuous_independent')\n",
    "\n",
    "# For binary outcome like converted (0/1)\n",
    "# run_aa_testing_generalized(users, group_col='group', metric_col='converted', experiment_type='binary')\n",
    "\n",
    "# For paired before/after measurements\n",
    "# run_aa_testing_generalized(pre_post_df, group_col='group', metric_col='time_spent', experiment_type='continuous_paired')\n",
    "\n",
    "# For categorical outcomes (e.g., plan type)\n",
    "# run_aa_testing_generalized(users, group_col='group', metric_col='plan_type', experiment_type='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "409ec437",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stophererewr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stophererewr\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stophererewr' is not defined"
     ]
    }
   ],
   "source": [
    "stophererewr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48617f5",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02dc03",
   "metadata": {},
   "source": [
    "# Power Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf95947",
   "metadata": {},
   "source": [
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "Power analysis helps determine the **minimum sample size** required to detect a true effect with statistical confidence.\n",
    "\n",
    "##### Why It Matters:\n",
    "- Avoids **underpowered tests** (risk of missing real effects)\n",
    "- Balances tradeoffs between Sample size, Minimum Detectable Effect (MDE), Significance level (α), Statistical power (1 - β)\n",
    "\n",
    "##### Key Inputs:\n",
    "| Parameter      | Meaning                                                   |\n",
    "|----------------|------------------------------------------------------------|\n",
    "| **alpha (α)**  | Significance level (probability of false positive), e.g. 0.05 |\n",
    "| **Power (1 - β)** | Probability of detecting a true effect, e.g. 0.80 or 0.90 |\n",
    "| **Baseline**   | Current outcome (e.g., 10% conversion, $50 revenue)         |\n",
    "| **MDE**        | Minimum detectable effect — the smallest meaningful lift (e.g., +2% or +$5) |\n",
    "| **Std Dev**    | Standard deviation of the metric (for continuous outcomes) |\n",
    "| **Effect Size**| Optional: Cohen's d (for t-tests) or f (for ANOVA)         |\n",
    "| **Groups**     | Number of groups (relevant for ANOVA)                      |\n",
    "\n",
    "This notebook automatically selects the correct formula based on `experiment_type` variable.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_power_sample_size(\n",
    "    experiment_type,\n",
    "    alpha=0.05,\n",
    "    power=0.80,\n",
    "    baseline_rate=None, # For binary: e.g., 0.10 = 10% conversion rate\n",
    "    mde=None,           # Minimum Detectable Effect (absolute change)\n",
    "                        # e.g., 0.02 for 2% lift in binary, or $5 increase in continuous\n",
    "    std_dev=None,       # Std deviation of outcome for continuous outcomes\n",
    "    effect_size=None,   # Cohen's d (for t-tests) or w (for chi-square)\n",
    "    num_groups=2        # Only relevant for ANOVA (if ever extended)\n",
    "):\n",
    "    \"\"\"\n",
    "    Generalized sample size calculator for A/B testing based on experiment type.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    experiment_type : str\n",
    "        One of:\n",
    "        - 'binary'                 : Binary outcome (Z-test on proportions)\n",
    "        - 'continuous_independent' : Continuous outcome, different users (independent t-test)\n",
    "        - 'continuous_paired'      : Continuous outcome, same users (paired t-test)\n",
    "        - 'categorical'            : Categorical outcome (Chi-square test)\n",
    "\n",
    "    alpha : float\n",
    "        Significance level (Type I error), usually 0.05\n",
    "\n",
    "    power : float\n",
    "        Desired power of the test, e.g., 0.80 for 80%\n",
    "\n",
    "    baseline_rate : float\n",
    "        Required for binary test — e.g., 0.10 for 10% conversion rate\n",
    "\n",
    "    mde : float\n",
    "        Minimum detectable effect (absolute lift):\n",
    "        - Binary: 0.02 → detect +2% lift\n",
    "        - Continuous: 5 → detect $5 difference\n",
    "\n",
    "    std_dev : float\n",
    "        Required for continuous outcome tests (if effect_size not provided)\n",
    "\n",
    "    effect_size : float\n",
    "        Optional: Cohen’s d (t-tests) or Cohen’s w (Chi-square)\n",
    "\n",
    "    num_groups : int\n",
    "        Reserved for ANOVA extensions; not used in current version.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Required sample size per group\n",
    "    \"\"\"\n",
    "\n",
    "    # ----- 1. Binary Outcome -----\n",
    "    if experiment_type == 'binary':\n",
    "        if baseline_rate is None or mde is None:\n",
    "            raise ValueError(\"baseline_rate and mde are required for binary tests.\")\n",
    "        \n",
    "        z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
    "        z_beta = stats.norm.ppf(power)\n",
    "        p1 = baseline_rate\n",
    "        p2 = p1 + mde\n",
    "        pooled_std = np.sqrt(2 * p1 * (1 - p1))\n",
    "\n",
    "        n = ((z_alpha + z_beta) ** 2 * pooled_std ** 2) / (mde ** 2)\n",
    "        return int(np.ceil(n))\n",
    "\n",
    "    # ----- 2. Continuous (Independent Groups) -----\n",
    "    elif experiment_type == 'continuous_independent':\n",
    "        if std_dev is None and effect_size is None:\n",
    "            raise ValueError(\"Provide std_dev or effect_size for continuous_independent test.\")\n",
    "        if effect_size is None:\n",
    "            effect_size = mde / std_dev\n",
    "        \n",
    "        analysis = TTestIndPower()\n",
    "        n = analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha)\n",
    "        return int(np.ceil(n))\n",
    "\n",
    "    # ----- 3. Continuous (Paired Users) -----\n",
    "    elif experiment_type == 'continuous_paired':\n",
    "        if std_dev is None and effect_size is None:\n",
    "            raise ValueError(\"Provide std_dev or effect_size for continuous_paired test.\")\n",
    "        if effect_size is None:\n",
    "            effect_size = mde / std_dev\n",
    "\n",
    "        analysis = TTestPower()\n",
    "        n = analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha)\n",
    "        return int(np.ceil(n))\n",
    "\n",
    "    # ----- 4. Categorical Outcome (Chi-square) -----\n",
    "    elif experiment_type == 'categorical':\n",
    "        if effect_size is None:\n",
    "            raise ValueError(\"effect_size (Cohen's w) is required for categorical tests.\")\n",
    "        \n",
    "        analysis = NormalIndPower()  # Approximate method\n",
    "        n = analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha)\n",
    "        return int(np.ceil(n))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported experiment_type: {experiment_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Experiment assumptions\n",
    "alpha = 0.05                 # Type I error tolerance (false positive rate)\n",
    "power = 0.80                 # 1 - β (probability of detecting a true effect)\n",
    "baseline_rate = 0.10         # For binary: current conversion rate = 10%\n",
    "mde = 0.02                   # Minimum detectable effect (e.g., +2% lift or +$5 increase)\n",
    "std_dev = None               # Required for continuous outcomes if effect_size is not provided\n",
    "effect_size = None           # Optional: Cohen’s d (continuous) or w (categorical)\n",
    "num_groups = None            # Not used currently; placeholder for future ANOVA extension\n",
    "\n",
    "# For continuous_independent experiment type, calculate std_dev if not provided\n",
    "if experiment_type == 'continuous_independent' and std_dev is None:\n",
    "    # Compute std_dev from control group outcome metric if std_dev is not provided\n",
    "    control_data = users[users['group'] == 'control'][outcome_metric_col]\n",
    "    std_dev = control_data.std()\n",
    "\n",
    "# 🧮 Sample size calculation\n",
    "required_sample_size = calculate_power_sample_size(\n",
    "    experiment_type=experiment_type,\n",
    "    alpha=alpha,\n",
    "    power=power,\n",
    "    baseline_rate=baseline_rate,\n",
    "    mde=mde,\n",
    "    std_dev=std_dev,\n",
    "    effect_size=effect_size,\n",
    "    num_groups=num_groups\n",
    ")\n",
    "\n",
    "print(f\"✅ Required sample size per group: {required_sample_size}\")\n",
    "print(f\"👥 Total sample size (Control + Treatment): {required_sample_size * 2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_power_analysis_summary(\n",
    "    experiment_type,\n",
    "    alpha,\n",
    "    power,\n",
    "    baseline_rate=None,\n",
    "    mde=None,\n",
    "    std_dev=None,\n",
    "    effect_size=None,\n",
    "    num_groups=None,\n",
    "    required_sample_size=None\n",
    "):\n",
    "    print(\"📈 Power Analysis Summary\")\n",
    "    print(f\"- Significance level (α): {alpha}\")\n",
    "    print(f\"- Statistical power (1 - β): {power}\")\n",
    "\n",
    "    if experiment_type == 'binary':\n",
    "        print(f\"- Baseline conversion rate: {baseline_rate}\")\n",
    "        print(f\"- Minimum detectable effect (MDE): {mde}\")\n",
    "        if baseline_rate is not None and mde is not None:\n",
    "            print(f\"- Target conversion rate: {baseline_rate + mde:.2f}\")\n",
    "        print(f\"\\n✅ Result:\")\n",
    "        print(f\"To detect a lift from {baseline_rate:.2f} to {baseline_rate + mde:.2f},\")\n",
    "        print(f\"you need {required_sample_size} users in each group (control and treatment).\")\n",
    "        print(f\"Total sample size: {required_sample_size * 2} users.\")\n",
    "\n",
    "    elif experiment_type == 'continuous_independent':\n",
    "        if std_dev:\n",
    "            print(f\"- Std Dev (between users): {std_dev}\")\n",
    "            print(f\"- MDE (difference to detect): {mde}\")\n",
    "            print(f\"- Effect size (Cohen's d): {mde / std_dev:.2f}\")\n",
    "        else:\n",
    "            print(f\"- Effect size (Cohen's d): {effect_size}\")\n",
    "        \n",
    "        print(f\"\\n✅ Result:\")\n",
    "        print(f\"To detect a mean difference of {mde} between two independent groups,\")\n",
    "        print(f\"you need {required_sample_size} users per group (total {required_sample_size * 2}).\")\n",
    "\n",
    "    elif experiment_type == 'continuous_paired':\n",
    "        if std_dev:\n",
    "            print(f\"- Std Dev (of within-user differences): {std_dev}\")\n",
    "            print(f\"- MDE (within-user change): {mde}\")\n",
    "            print(f\"- Effect size (Cohen's d): {mde / std_dev:.2f}\")\n",
    "        else:\n",
    "            print(f\"- Effect size (Cohen's d): {effect_size}\")\n",
    "        \n",
    "        print(f\"\\n✅ Result:\")\n",
    "        print(f\"To detect a mean change of {mde} within the same users,\")\n",
    "        print(f\"you need data from {required_sample_size} users.\")\n",
    "\n",
    "    elif experiment_type == 'categorical':\n",
    "        print(f\"- Outcome type: Categorical\")\n",
    "        print(f\"- Effect size (Cohen's w): {effect_size}\")\n",
    "        print(f\"\\n✅ Result:\")\n",
    "        print(f\"To detect a significant difference in categorical outcome distribution between groups,\")\n",
    "        print(f\"you need {required_sample_size} users per group (total {required_sample_size * 2}).\")\n",
    "\n",
    "    else:\n",
    "        print(\"⚠️ Unknown experiment type — no summary printed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803c60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_power_analysis_summary(\n",
    "    experiment_type=experiment_type,  # 'binary', 'continuous_independent', 'continuous_paired', or 'categorical'\n",
    "    alpha=alpha,                      # e.g., 0.05\n",
    "    power=power,                      # e.g., 0.80\n",
    "    baseline_rate=baseline_rate,      # Required for 'binary'\n",
    "    mde=mde,                          # Required for binary and continuous if effect_size is not used\n",
    "    std_dev=std_dev,                  # For continuous types\n",
    "    effect_size=effect_size,          # Optional override for t-test or chi-square\n",
    "    num_groups=None,                  # Currently unused, keep as None\n",
    "    required_sample_size=required_sample_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e3add",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e68463",
   "metadata": {},
   "source": [
    "# AB Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25b9fec",
   "metadata": {},
   "source": [
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "\n",
    "##### 🧪 A/B Testing - Outcome Comparison\n",
    "\n",
    "This section compares the outcome metric between control and treatment groups using the appropriate statistical test based on the experiment type.\n",
    "\n",
    "##### Metric Tracked:\n",
    "- **Primary metric:** Depends on use case:\n",
    "  - Binary: Conversion rate (clicked or not)\n",
    "  - Continuous: Average engagement, revenue, time spent\n",
    "  - Categorical: Plan type, user tier, etc.\n",
    "- **Unit of analysis:** Unique user or unique observation\n",
    "\n",
    "##### Outcome Analysis Steps:\n",
    "- Choose the **right statistical test** based on `experiment_type`\n",
    "  - `'binary'` → **Z-test for proportions**\n",
    "  - `'continuous_independent'` → **Two-sample t-test**\n",
    "  - `'continuous_paired'` → **Paired t-test**\n",
    "  - `'categorical'` → **Chi-square test of independence**\n",
    "- Calculate test statistics, p-values, and confidence intervals\n",
    "- Visualize the comparison to aid interpretation\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f7f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ab_test(\n",
    "    df,\n",
    "    group_col=group_col,\n",
    "    metric_col=outcome_metric_col,\n",
    "    experiment_type=experiment_type,\n",
    "    group_labels=group_labels,\n",
    "    alpha=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Run A/B test and perform statistical test based on the experiment type.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing the test data\n",
    "    group_col : str\n",
    "        Column indicating group assignment\n",
    "    metric_col : str\n",
    "        Column indicating outcome metric\n",
    "    experiment_type : str\n",
    "        Type of test: 'binary', 'continuous_independent', 'continuous_paired', or 'categorical'\n",
    "    group_labels : tuple\n",
    "        Tuple containing labels for control and treatment (default = ('control', 'treatment'))\n",
    "    alpha : float\n",
    "        Significance level (default = 0.05)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with summary statistics, test type, and test results\n",
    "    \"\"\"\n",
    "    group1, group2 = group_labels\n",
    "    data1 = df[df[group_col] == group1][metric_col]\n",
    "    data2 = df[df[group_col] == group2][metric_col]\n",
    "\n",
    "    result = {\n",
    "        'experiment_type': experiment_type,\n",
    "        'group_labels': group_labels,\n",
    "        'alpha': alpha,\n",
    "        'summary': {}\n",
    "    }\n",
    "\n",
    "    # --- Summary stats ---\n",
    "    result['summary'][group1] = {\n",
    "        'n': len(data1),\n",
    "        'mean': data1.mean(),\n",
    "        'std': data1.std() if experiment_type.startswith('continuous') else None,\n",
    "        'sum': data1.sum() if experiment_type == 'binary' else None\n",
    "    }\n",
    "    result['summary'][group2] = {\n",
    "        'n': len(data2),\n",
    "        'mean': data2.mean(),\n",
    "        'std': data2.std() if experiment_type.startswith('continuous') else None,\n",
    "        'sum': data2.sum() if experiment_type == 'binary' else None\n",
    "    }\n",
    "\n",
    "    # --- Run appropriate test ---\n",
    "    if experiment_type == 'binary':\n",
    "        x1, n1 = data1.sum(), len(data1)\n",
    "        x2, n2 = data2.sum(), len(data2)\n",
    "        p_pooled = (x1 + x2) / (n1 + n2)\n",
    "        # if p_pooled in [0, 1] or n1 == 0 or n2 == 0:\n",
    "        #     se = np.nan\n",
    "        #     z_stat = np.nan\n",
    "        #     p_value = np.nan\n",
    "        #     print(\"⚠️ Cannot compute z-statistic: division by zero or perfect separation.\")\n",
    "        # else:\n",
    "        #     se = np.sqrt(p_pooled * (1 - p_pooled) * (1/n1 + 1/n2))\n",
    "        #     z_stat = (x2/n2 - x1/n1) / se\n",
    "        #     p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "        se = np.sqrt(p_pooled * (1 - p_pooled) * (1/n1 + 1/n2))\n",
    "        z_stat = (x2/n2 - x1/n1) / se\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))\n",
    "        result['test'] = 'z-test for proportions'\n",
    "        result['z_stat'] = z_stat\n",
    "        result['p_value'] = p_value\n",
    "\n",
    "    elif experiment_type == 'continuous_independent':\n",
    "        t_stat, p_value = stats.ttest_ind(data1, data2)\n",
    "        result['test'] = 'independent t-test'\n",
    "        result['t_stat'] = t_stat\n",
    "        result['p_value'] = p_value\n",
    "\n",
    "    elif experiment_type == 'continuous_paired':\n",
    "        if len(data1) != len(data2):\n",
    "            raise ValueError(\"Paired test requires equal-length groups with matching units.\")\n",
    "        t_stat, p_value = stats.ttest_rel(data1, data2)\n",
    "        result['test'] = 'paired t-test'\n",
    "        result['t_stat'] = t_stat\n",
    "        result['p_value'] = p_value\n",
    "\n",
    "    elif experiment_type == 'categorical':\n",
    "        contingency = pd.crosstab(df[group_col], df[metric_col])\n",
    "        chi2, p_value, _, _ = stats.chi2_contingency(contingency)\n",
    "        result['test'] = 'chi-square test'\n",
    "        result['chi2_stat'] = chi2\n",
    "        result['p_value'] = p_value\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported experiment_type: {experiment_type}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63be386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Binary outcome: e.g., Conversion (0 or 1)\n",
    "# result = run_ab_test(users, group_col=group_col, metric_col='converted', experiment_type='binary')\n",
    "\n",
    "# ✅ Continuous outcome, independent groups: e.g., Engagement score or revenue\n",
    "# result = run_ab_test(users, group_col=group_col, metric_col=outcome_metric_col, experiment_type=experiment_type)\n",
    "\n",
    "# ✅ Continuous outcome, paired users: e.g., Before/after time spent\n",
    "# result = run_ab_test(pre_post_df, group_col=group_col, metric_col='time_spent', experiment_type='continuous_paired')\n",
    "\n",
    "# ✅ Categorical outcome: e.g., plan_type (basic/premium/pro)\n",
    "# result = run_ab_test(users, group_col=group_col, metric_col='plan_type', experiment_type='categorical')\n",
    "\n",
    "\n",
    "result = run_ab_test(users, group_col=group_col, metric_col=outcome_metric_col, experiment_type=experiment_type)\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f10423",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d6dc29",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fbb583",
   "metadata": {},
   "source": [
    "#### Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f177f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_ab_test_result(result):\n",
    "    \"\"\"\n",
    "    Prints statistical test results and summarizes group stats.\n",
    "    No plots here — visualization handled separately.\n",
    "    \"\"\"\n",
    "\n",
    "    exp_type = result['experiment_type']\n",
    "    group1, group2 = result['group_labels']\n",
    "    p_value = result.get('p_value')\n",
    "    alpha = result.get('alpha', 0.05)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*45)\n",
    "    print(f\"🧪 A/B Test Result Summary [{exp_type}]\")\n",
    "    print(\"=\"*45)\n",
    "\n",
    "    # ---- Hypothesis Test Output ----\n",
    "    print(\"\\n📊 Hypothesis Test Result\")\n",
    "    print(f\"Test used: {result.get('test', 'N/A')}\")\n",
    "    if 'z_stat' in result:\n",
    "        print(f\"Z-statistic: {result['z_stat']:.4f}\")\n",
    "    elif 't_stat' in result:\n",
    "        print(f\"T-statistic: {result['t_stat']:.4f}\")\n",
    "    elif 'chi2_stat' in result:\n",
    "        print(f\"Chi2-statistic: {result['chi2_stat']:.4f}\")\n",
    "\n",
    "    if p_value is not None:\n",
    "        print(f\"P-value    : {p_value:.4f}\")\n",
    "        print(\"✅ Statistically significant difference detected.\" if p_value < alpha else \"🚫 No significant difference detected.\")\n",
    "    else:\n",
    "        print(\"⚠️ P-value not found.\")\n",
    "\n",
    "    # ---- Summary Table ----\n",
    "    print(\"\\n📋 Group Summary:\\n\")\n",
    "    display(pd.DataFrame(result['summary']).T)\n",
    "\n",
    "    # ---- Lift Analysis (binary or continuous_independent) ----\n",
    "    if exp_type in ['binary', 'continuous_independent']:\n",
    "        group1_mean = result['summary'][group1]['mean']\n",
    "        group2_mean = result['summary'][group2]['mean']\n",
    "        lift = group2_mean - group1_mean\n",
    "        pct_lift = lift / group1_mean if group1_mean else np.nan\n",
    "\n",
    "        print(\"\\n📈 Lift Analysis\")\n",
    "        print(f\"- Absolute Lift   : {lift:.4f}\")\n",
    "        print(f\"- Percentage Lift : {pct_lift:.2%}\")\n",
    "\n",
    "        try:\n",
    "            n1 = result['summary'][group1]['n']\n",
    "            n2 = result['summary'][group2]['n']\n",
    "\n",
    "            if exp_type == 'binary':\n",
    "                se = np.sqrt(group1_mean * (1 - group1_mean) / n1 + group2_mean * (1 - group2_mean) / n2)\n",
    "            else:\n",
    "                sd1 = result['summary'][group1].get('std')\n",
    "                sd2 = result['summary'][group2].get('std')\n",
    "                if sd1 is not None and sd2 is not None:\n",
    "                    se = np.sqrt((sd1 ** 2) / n1 + (sd2 ** 2) / n2)\n",
    "                else:\n",
    "                    raise ValueError(\"Standard deviation missing for one or both groups.\")\n",
    "\n",
    "            z = 1.96\n",
    "            ci_low = lift - z * se\n",
    "            ci_high = lift + z * se\n",
    "            print(f\"- 95% CI for Lift : [{ci_low:.4f}, {ci_high:.4f}]\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not compute confidence interval: {e}\")\n",
    "\n",
    "    print(\"=\"*45 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93bc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_ab_test_result(result)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21904129",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8abd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ab_test_results(result):\n",
    "    \"\"\"\n",
    "    Generates visualization for A/B test results based on experiment type.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    exp_type = result['experiment_type']\n",
    "    group1, group2 = result['group_labels']\n",
    "\n",
    "    print(\"\\n📊 Visualization:\")\n",
    "\n",
    "    if exp_type in ['binary', 'continuous_independent', 'continuous_paired']:\n",
    "        labels = [group1, group2]\n",
    "        values = [result['summary'][group1]['mean'], result['summary'][group2]['mean']]\n",
    "        plt.bar(labels, values, color=['gray', 'skyblue'])\n",
    "\n",
    "        for i, val in enumerate(values):\n",
    "            label = f\"{val:.2%}\" if exp_type == 'binary' else f\"{val:.2f}\"\n",
    "            plt.text(i, val + 0.01, label, ha='center')\n",
    "\n",
    "        ylabel = \"Conversion Rate\" if exp_type == 'binary' else \"Average Value\"\n",
    "        plt.ylabel(ylabel);\n",
    "        plt.title(f\"{ylabel} by Group\");\n",
    "        plt.ylim(0, max(values) + 0.1 * max(values));\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.6);\n",
    "        plt.show();\n",
    "\n",
    "    elif exp_type == 'categorical':\n",
    "        dist = pd.DataFrame(result['summary'])\n",
    "        dist.T.plot(kind='bar', stacked=True);\n",
    "        plt.title(f\"Categorical Distribution by Group\");\n",
    "        plt.ylabel(\"Proportion\");\n",
    "        plt.xlabel(\"Group\");\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.6);\n",
    "        plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f050fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ab_test_results(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d922e",
   "metadata": {},
   "source": [
    "#### 95% Confidence Intervals \n",
    "for `outcome in groups`\n",
    "\n",
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "\n",
    "- The 95% confidence interval gives a range in which we expect the **true conversion rate** to fall for each group.\n",
    "- If the confidence intervals **do not overlap**, it's strong evidence that the difference is statistically significant.\n",
    "- If they **do overlap**, it doesn't guarantee insignificance — you still need the p-value to decide — but it suggests caution when interpreting lift.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39ba0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confidence_intervals(result, z=1.96):\n",
    "    \"\"\"\n",
    "    Plot 95% confidence intervals for group means (conversion rate or average outcome).\n",
    "    \n",
    "    Parameters:\n",
    "    - result: dictionary returned by run_ab_test()\n",
    "    - z: Z-score for confidence interval (default: 1.96 for 95%)\n",
    "    \"\"\"\n",
    "    exp_type = result['experiment_type']\n",
    "    group1, group2 = result['group_labels']\n",
    "    summary = result['summary']\n",
    "    \n",
    "    if exp_type not in ['binary', 'continuous_independent', 'continuous_paired']:\n",
    "        print(f\"⚠️ Confidence interval plotting not supported for experiment_type: {exp_type}\")\n",
    "        return\n",
    "\n",
    "    # Extract values\n",
    "    p1 = summary[group1]['mean']\n",
    "    p2 = summary[group2]['mean']\n",
    "    n1 = summary[group1]['n']\n",
    "    n2 = summary[group2]['n']\n",
    "\n",
    "    if exp_type == 'binary':\n",
    "        # Standard error for proportions\n",
    "        se1 = np.sqrt(p1 * (1 - p1) / n1)\n",
    "        se2 = np.sqrt(p2 * (1 - p2) / n2)\n",
    "        ylabel = \"Conversion Rate\"\n",
    "        title = \"Conversion Rate with 95% Confidence Intervals\"\n",
    "    else:\n",
    "        # Use std if available\n",
    "        sd1 = summary[group1].get('std')\n",
    "        sd2 = summary[group2].get('std')\n",
    "        if sd1 is None or sd2 is None:\n",
    "            print(\"⚠️ Standard deviation not available — cannot compute CI for continuous data.\")\n",
    "            return\n",
    "        se1 = sd1 / np.sqrt(n1)\n",
    "        se2 = sd2 / np.sqrt(n2)\n",
    "        ylabel = \"Mean Outcome\"\n",
    "        title = f\"{ylabel} with 95% Confidence Intervals\"\n",
    "\n",
    "    # Confidence intervals\n",
    "    ci1 = (p1 - z * se1, p1 + z * se1)\n",
    "    ci2 = (p2 - z * se2, p2 + z * se2)\n",
    "\n",
    "    # Plot\n",
    "    plt.errorbar([group1, group2],\n",
    "                 [p1, p2],\n",
    "                 yerr=[[p1 - ci1[0], p2 - ci2[0]],\n",
    "                       [ci1[1] - p1, ci2[1] - p2]],\n",
    "                 fmt='o', capsize=10, color='black')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11642dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confidence_intervals(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb707b79",
   "metadata": {},
   "source": [
    "#### `Lift Analysis`  \n",
    "AKA 95% Confidence Intervals for (`difference in outcomes`).\n",
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "This confidence interval helps quantify uncertainty around the observed **lift** between treatment and control groups. It answers:\n",
    "\n",
    "- *How large is the difference between groups?*\n",
    "- *How confident are we in this lift estimate?*\n",
    "\n",
    "We compute a 95% CI for the difference in means (or proportions), not just for each group. If this interval **does not include 0**, we can reasonably trust there's a true difference. If it **does include 0**, the observed difference might be due to random chance.\n",
    "\n",
    "This complements the p-value — while p-values tell us if the difference is significant, **CIs tell us how big the effect is, and how uncertain we are.**\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lift_confidence_interval(result):\n",
    "    \"\"\"\n",
    "    Computes and interprets the confidence interval for the difference in outcomes (lift)\n",
    "    based on experiment type.\n",
    "\n",
    "    Parameters:\n",
    "    - result: dictionary returned by run_ab_test()\n",
    "\n",
    "    Output:\n",
    "    - Prints lift summary and 95% confidence interval (when applicable)\n",
    "    \"\"\"\n",
    "\n",
    "    exp_type = result['experiment_type']\n",
    "    group1, group2 = result['group_labels']\n",
    "    alpha = result.get('alpha', 0.05)\n",
    "    z = 1.96  # For 95% confidence\n",
    "\n",
    "    print(\"\\n\" + \"=\"*45)\n",
    "    print(f\"📈 95% CI for Difference in Outcome [{exp_type}]\")\n",
    "    print(\"=\"*45)\n",
    "\n",
    "    if exp_type in ['binary', 'continuous_independent']:\n",
    "        mean1 = result['summary'][group1]['mean']\n",
    "        mean2 = result['summary'][group2]['mean']\n",
    "        lift = mean2 - mean1\n",
    "        n1 = result['summary'][group1]['n']\n",
    "        n2 = result['summary'][group2]['n']\n",
    "\n",
    "        if exp_type == 'binary':\n",
    "            # SE for difference in proportions\n",
    "            se_diff = np.sqrt(mean1 * (1 - mean1) / n1 + mean2 * (1 - mean2) / n2)\n",
    "        else: # continuous_independent\n",
    "            sd1 = result['summary'][group1].get('std')\n",
    "            sd2 = result['summary'][group2].get('std')\n",
    "            if sd1 is None or sd2 is None:\n",
    "                print(\"⚠️ Standard deviation missing. Cannot compute CI.\")\n",
    "                return\n",
    "            se_diff = np.sqrt((sd1 ** 2) / n1 + (sd2 ** 2) / n2)\n",
    "\n",
    "        ci_low = lift - z * se_diff\n",
    "        ci_high = lift + z * se_diff\n",
    "\n",
    "        print(f\"- Absolute Lift         : {lift:.4f}\")\n",
    "        print(f\"- 95% Confidence Interval: [{ci_low:.4f}, {ci_high:.4f}]\")\n",
    "\n",
    "        if ci_low > 0:\n",
    "            print(\"✅ We’re 95% confident the treatment improved the outcome.\")\n",
    "        elif ci_high < 0:\n",
    "            print(\"🚫 We’re 95% confident the treatment worsened the outcome.\")\n",
    "        else:\n",
    "            print(\"🤷 The CI includes 0 — result is not statistically significant.\")\n",
    "\n",
    "    elif exp_type == 'continuous_paired':\n",
    "        print(\"- Paired t-test was used, which internally accounts for paired differences.\")\n",
    "        print(\"- The test already captures variance of differences directly.\")\n",
    "        print(\"- ✅ You may optionally compute CI using the standard error of the differences (not included here).\")\n",
    "\n",
    "    elif exp_type == 'categorical':\n",
    "        print(\"- This test compares distributions across multiple categories (e.g., plan_type or country).\")\n",
    "        print(\"- There isn’t a single 'lift' value.\")\n",
    "        print(\"- To compute per-category lift and confidence intervals:\")\n",
    "        print(\"    → Get proportion of users in each category for control and treatment.\")\n",
    "        print(\"    → Compute difference (lift) for each category.\")\n",
    "        print(\"    → Use formula for difference in proportions to estimate CI for each.\")\n",
    "        print(\"⚠️ Placeholder: Categorical CI calculations not included yet.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"⚠️ Unsupported experiment type: {exp_type}\")\n",
    "\n",
    "    print(\"=\"*45 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_lift_confidence_interval(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a553b",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa93754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_final_ab_test_summary(result):\n",
    "    \"\"\"\n",
    "    Prints a final summary block for A/B test results based on experiment type.\n",
    "    \"\"\"\n",
    "    exp_type = result['experiment_type']\n",
    "    group1, group2 = result['group_labels']\n",
    "    p_value = result.get('p_value')\n",
    "    alpha = result.get('alpha', 0.05)\n",
    "    \n",
    "    print(\"=\"*40)\n",
    "    print(\"          📊 FINAL A/B TEST SUMMARY\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # For experiment types where group means are meaningful\n",
    "    if exp_type in ['binary', 'continuous_independent']:\n",
    "        mean1 = result['summary'][group1]['mean']\n",
    "        mean2 = result['summary'][group2]['mean']\n",
    "        lift = mean2 - mean1\n",
    "        pct_lift = lift / mean1 if mean1 else np.nan\n",
    "\n",
    "        label = \"Conversion rate\" if exp_type == 'binary' else \"Avg outcome\"\n",
    "        test_name = result.get(\"test\", \"A/B test\")\n",
    "\n",
    "        print(f\"👥  {group1.capitalize()} {label:<20}:  {mean1:.4f}\")\n",
    "        print(f\"🧪  {group2.capitalize()} {label:<20}:  {mean2:.4f}\")\n",
    "        print(f\"📈  Absolute lift              :  {lift:.4f}\")\n",
    "        print(f\"📊  Percentage lift            :  {pct_lift:.2%}\")\n",
    "        print(f\"🧪  P-value (from {test_name}) :  {p_value:.4f}\")\n",
    "\n",
    "    elif exp_type == 'continuous_paired':\n",
    "        print(\"🧪 Paired T-Test was used to compare outcomes within the same users.\")\n",
    "        print(f\"🧪 P-value: {p_value:.4f}\")\n",
    "\n",
    "    elif exp_type == 'categorical':\n",
    "        print(\"🧪 Chi-square test was used to compare categorical distributions.\")\n",
    "        print(f\"🧪 P-value: {p_value:.4f}\")\n",
    "\n",
    "    else:\n",
    "        print(\"⚠️ Unknown experiment type.\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Verdict\n",
    "    if p_value is not None:\n",
    "        if p_value < alpha:\n",
    "            print(\"✅ RESULT: Statistically significant difference detected.\")\n",
    "        else:\n",
    "            print(\"❌ RESULT: No statistically significant difference detected.\")\n",
    "    else:\n",
    "        print(\"⚠️ No p-value to determine significance.\")\n",
    "\n",
    "    print(\"=\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f6c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_final_ab_test_summary(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0457202f",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dca748",
   "metadata": {},
   "source": [
    "# How Long\n",
    "##### to run the test?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decf16bf",
   "metadata": {},
   "source": [
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "The duration of an A/B test depends on how quickly you reach the required sample size per group, as estimated during your power analysis.\n",
    "\n",
    "##### ✅ Key Inputs\n",
    "- Daily volume of eligible observations (users, sessions, or orders — depends on your unit of analysis)\n",
    "- Required sample size per group (from power analysis)\n",
    "- Traffic split ratio (e.g., 50/50, 10/90, 33/33/33)\n",
    "\n",
    "##### 🧮 Formula\n",
    "\n",
    "> Test Duration (in days) =  \n",
    "> Required Sample Size per Group ÷ (Daily Eligible Observations × Group Split Proportion)\n",
    "\n",
    "This ensures the experiment runs long enough to detect the expected effect with the desired confidence and power.\n",
    "\n",
    "##### 💡 Planning Tips\n",
    "\n",
    "1. Estimate required sample size using power analysis (based on effect size, baseline, alpha, and power)\n",
    "2. Understand your traffic: \n",
    "   - What’s your average daily eligible traffic?\n",
    "   - What unit of analysis is used (user, session, impression)?\n",
    "3. Apply group split: \n",
    "   - e.g., for a 50/50 A/B test, each group gets 50% of traffic\n",
    "4. Estimate days using the formula above.\n",
    "\n",
    "##### 🧠 Real-World Considerations\n",
    "\n",
    "- ✅ Ramp-Up Period  \n",
    "  Gradually increase traffic exposure: 5% → 25% → 50% → full traffic.  \n",
    "  Helps catch bugs, stability issues, and confounding edge cases early.\n",
    "\n",
    "- ✅ Cool-Down Buffer  \n",
    "  Avoid ending tests on weekends, holidays, or during unusual traffic spikes.  \n",
    "  Add buffer days so your conclusions aren’t skewed by anomalies.\n",
    "\n",
    "- ✅ Trust Checks Before Analysis  \n",
    "  - A/A testing to verify setup  \n",
    "  - SRM checks to confirm user distribution  \n",
    "  - Monitor guardrail metrics (e.g., bounce rate, latency, load time)\n",
    "\n",
    "##### 🗣️ Common Practitioner Advice\n",
    "> “We calculate sample size using power analysis, then divide by daily traffic per group. But we always factor in buffer days — for ramp-up, trust checks, and stability. Better safe than sorry.”\n",
    "> “Power analysis is the starting point. But we don’t blindly stop when we hit N. We monitor confidence intervals, metric stability, and coverage to make sure we’re making decisions the business can trust.”\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ee80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_test_duration(\n",
    "    required_sample_size_per_group,\n",
    "    daily_eligible_users,\n",
    "    allocation_ratios=(0.5, 0.5), # e.g., 50/50 or (0.2, 0.8)\n",
    "    buffer_days=2,\n",
    "    experiment_type=None # optional, e.g., 'binary', 'categorical'\n",
    "):\n",
    "    \"\"\"\n",
    "    Estimate how long an A/B test will take based on sample size, traffic, and allocation split.\n",
    "\n",
    "    Parameters:\n",
    "    - required_sample_size_per_group: int\n",
    "        Number of samples needed per group (from power analysis)\n",
    "    - daily_eligible_users: int\n",
    "        Total eligible observations (users/sessions/etc.) arriving per day\n",
    "    - allocation_ratios: tuple\n",
    "        Traffic proportion for each group (e.g., (0.5, 0.5) for A/B test)\n",
    "    - buffer_days: int\n",
    "        Additional buffer days for ramp-up, anomalies, etc.\n",
    "    - experiment_type: str (optional)\n",
    "        Metadata for reporting context (e.g., 'binary', 'continuous', 'categorical')\n",
    "\n",
    "    Returns:\n",
    "    - dict with per-group duration, max duration, and total estimated runtime\n",
    "    \"\"\"\n",
    "    group_durations = []\n",
    "    for alloc in allocation_ratios:\n",
    "        users_per_day = daily_eligible_users * alloc\n",
    "        days = required_sample_size_per_group / users_per_day if users_per_day else float('inf')\n",
    "        group_durations.append(np.ceil(days))\n",
    "\n",
    "    longest_group_runtime = int(max(group_durations))\n",
    "    total_with_buffer = longest_group_runtime + buffer_days\n",
    "\n",
    "    print(\"\\n🧮 Estimated Test Duration\")\n",
    "    if experiment_type:\n",
    "        print(f\"- Experiment type           : {experiment_type}\")\n",
    "    print(f\"- Required sample per group : {required_sample_size_per_group}\")\n",
    "    print(f\"- Daily eligible traffic    : {daily_eligible_users}\")\n",
    "    print(f\"- Allocation ratio (per group): {allocation_ratios}\")\n",
    "    print(f\"- Longest group runtime     : {longest_group_runtime} days\")\n",
    "    print(f\"- Buffer days (ramp-up etc.): {buffer_days}\")\n",
    "    print(f\"✅ Total recommended runtime: {total_with_buffer} days\\n\")\n",
    "\n",
    "    return {\n",
    "        'experiment_type': experiment_type,\n",
    "        'per_group_days': group_durations,\n",
    "        'longest_group_runtime': longest_group_runtime,\n",
    "        'recommended_total_duration': total_with_buffer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5273cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pending ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48203b7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>🧭 Monitoring Dashboard</summary>\n",
    "\n",
    "- **Overall Test Health**\n",
    "  - Start/end date, traffic ramp-up %, time remaining  \n",
    "  - SRM (Sample Ratio Mismatch) indicator  \n",
    "  - P-value and effect size summary (updated daily)  \n",
    "\n",
    "- **Primary Metric Tracking**\n",
    "  - Daily trends for primary outcome (conversion, revenue, etc.)  \n",
    "  - Cumulative lift + confidence intervals  \n",
    "  - Statistical significance tracker (p-value, test stat)  \n",
    "\n",
    "- **Guardrail Metrics**\n",
    "  - Bounce rate, load time, checkout errors, etc.  \n",
    "  - Alert thresholds (e.g., +10% increase in latency)  \n",
    "  - Trend vs baseline and prior experiments  \n",
    "\n",
    "- **Segment Drilldowns**\n",
    "  - Platform (iOS vs Android), geography, user tier  \n",
    "  - Detect heterogeneous treatment effects  \n",
    "  - Option to toggle test results per segment  \n",
    "\n",
    "- **Cohort Coverage**\n",
    "  - Total users assigned vs eligible  \n",
    "  - Daily inclusion and exclusion trends  \n",
    "  - Debugging filters (e.g., why user X didn’t get assigned)  \n",
    "\n",
    "- **Variance & Stability Checks**\n",
    "  - Volatility of key metrics  \n",
    "  - Pre vs post baseline comparisons  \n",
    "  - Funnel conversion variance analysis  \n",
    "\n",
    "- **Notes & Annotations**\n",
    "  - Manual tagging of major incidents (e.g., bug fix deployed, pricing change)  \n",
    "  - Timeline of changes affecting experiment interpretation  \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e17a8c",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11ce892",
   "metadata": {},
   "source": [
    "# Post Hoc Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78601d2",
   "metadata": {},
   "source": [
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "\n",
    "> After statistical significance, post-hoc analysis helps **connect results to business confidence**.  \n",
    "> It's not just *did it work* — but *how, for whom, and at what cost or benefit?*\n",
    "\n",
    "##### 🧠 Why Post Hoc Analysis Matters\n",
    "- Segments may **respond differently** — average lift may hide underperformance in subgroups  \n",
    "- Guardrails may show **collateral damage** (e.g., slower load time, higher churn)  \n",
    "- Stakeholders need **impact translation** — what does this mean in revenue, retention, or strategy?\n",
    "\n",
    "##### 🔎 Typical Post Hoc Questions\n",
    "\n",
    "- Segment Lift\n",
    "  - Did certain platforms, geos, cohorts, or user types benefit more?\n",
    "  - Any negative lift in high-value user segments?\n",
    "\n",
    "- Guardrail Checks\n",
    "  - Did the treatment impact non-primary metrics (e.g., latency, engagement, bounce rate)?\n",
    "  - Were alert thresholds breached?\n",
    "\n",
    "- Business Impact Simulation\n",
    "  - How does the observed lift scale to 100% of eligible users?\n",
    "  - What’s the projected change in conversions, revenue, or user satisfaction?\n",
    "\n",
    "- Edge Case Discovery\n",
    "  - Any bugs, instrumentation gaps, or unexpected usage patterns?\n",
    "  - Did any user types get excluded disproportionately?\n",
    "\n",
    "##### 📊 What to Report\n",
    "\n",
    "| Area                  | What to Show                                                                 |\n",
    "|-----------------------|------------------------------------------------------------------------------|\n",
    "| Segment Analysis      | Table or chart showing lift per segment, sorted by effect size or risk      |\n",
    "| Guardrail Metrics     | Summary table of guardrails vs baseline, with thresholds or annotations     |\n",
    "| Revenue Simulation    | Projected uplift × traffic volume × conversion = business impact            |\n",
    "| Confidence Range      | 95% CI for key metrics per segment (wherever possible)                      |\n",
    "| Rollout Readiness     | Any blockers, mitigations, or next steps if full rollout is considered      |\n",
    "\n",
    "##### 💡 Pro Tip  \n",
    "Even if your p-value says “yes,” **business rollout is a risk-based decision**.  \n",
    "Post-hoc analysis is where **statistical rigor meets product judgment**.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4025c73",
   "metadata": {},
   "source": [
    "#### Segmented Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bed84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_segment_lift(df_segment, segment_col):\n",
    "    \"\"\"\n",
    "    Visualizes lift per segment using a horizontal bar chart.\n",
    "    \"\"\"\n",
    "    df_viz = df_segment.dropna(subset=['lift'])\n",
    "    df_viz = df_viz.sort_values(by='lift', ascending=False)\n",
    "\n",
    "    if df_viz.empty:\n",
    "        print(f\"⚠️ No lift data to visualize for '{segment_col}'\\n\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 0.4 * len(df_viz) + 2))\n",
    "    bars = plt.barh(df_viz[segment_col], df_viz['lift'], color='skyblue')\n",
    "    for bar, val in zip(bars, df_viz['lift']):\n",
    "        plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2,\n",
    "                 f\"{val:.2f}\", va='center', ha='left', fontsize=9)\n",
    "    plt.axvline(0, color='gray', linestyle='--')\n",
    "    plt.title(f\"Lift from Control to Treatment by {segment_col}\")\n",
    "    plt.xlabel(\"Mean Difference (Treatment – Control)\")\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_segment_lift(\n",
    "    df,\n",
    "    group_col='group',\n",
    "    metric_col='converted',\n",
    "    segment_cols=['platform', 'device_type', 'user_tier', 'region'],\n",
    "    group_labels=('control', 'treatment'),\n",
    "    experiment_type='binary',\n",
    "    min_count_per_group=30,\n",
    "    visualize=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform post-hoc segmented lift analysis for a given set of segments.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing experiment results\n",
    "    - group_col: Name of group column (e.g., 'group')\n",
    "    - metric_col: Metric to compute lift on\n",
    "    - segment_cols: List of columns to segment by\n",
    "    - group_labels: Tuple of control and treatment group names\n",
    "    - experiment_type: One of ['binary', 'continuous_independent', 'continuous_paired', 'categorical']\n",
    "    - min_count_per_group: Minimum sample size per group to analyze segment\n",
    "    - visualize: Whether to plot segmented lift\n",
    "    \"\"\"\n",
    "    group1, group2 = group_labels\n",
    "\n",
    "    for segment in segment_cols:\n",
    "        print(f\"\\n🔎 Segmenting by: {segment}\")\n",
    "        seg_data = []\n",
    "\n",
    "        for val in df[segment].dropna().unique():\n",
    "            subset = df[df[segment] == val]\n",
    "            g1 = subset[subset[group_col] == group1][metric_col]\n",
    "            g2 = subset[subset[group_col] == group2][metric_col]\n",
    "\n",
    "            if len(g1) < min_count_per_group or len(g2) < min_count_per_group:\n",
    "                print(f\"⚠️ Skipping segment '{val}' under '{segment}' — insufficient sample size.\")\n",
    "                continue\n",
    "\n",
    "            lift = g2.mean() - g1.mean() if experiment_type != 'categorical' else np.nan\n",
    "            p_value = None\n",
    "\n",
    "            if experiment_type == 'binary':\n",
    "                p1, n1 = g1.mean(), len(g1)\n",
    "                p2, n2 = g2.mean(), len(g2)\n",
    "                pooled_p = (g1.sum() + g2.sum()) / (n1 + n2)\n",
    "                se = np.sqrt(pooled_p * (1 - pooled_p) * (1/n1 + 1/n2))\n",
    "                z = (p2 - p1) / se\n",
    "                p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "\n",
    "            elif experiment_type == 'continuous_independent':\n",
    "                _, p_value = stats.ttest_ind(g1, g2)\n",
    "\n",
    "            elif experiment_type == 'continuous_paired':\n",
    "                print(f\"⚠️ Skipping segment '{val}' under '{segment}' — segmentation breaks pairing.\")\n",
    "                lift = np.nan\n",
    "                p_value = None\n",
    "\n",
    "            elif experiment_type == 'categorical':\n",
    "                print(f\"⚠️ Segment '{val}' under '{segment}': categorical lift not computed (not numeric).\")\n",
    "                lift = np.nan\n",
    "                p_value = None\n",
    "\n",
    "            seg_data.append({\n",
    "                segment: val,\n",
    "                'count_control': len(g1),\n",
    "                'count_treatment': len(g2),\n",
    "                'mean_control': g1.mean() if not g1.empty else np.nan,\n",
    "                'mean_treatment': g2.mean() if not g2.empty else np.nan,\n",
    "                'std_control': g1.std(ddof=1) if not g1.empty else np.nan,\n",
    "                'std_treatment': g2.std(ddof=1) if not g2.empty else np.nan,\n",
    "                'lift': lift,\n",
    "                'p_value_lift': p_value\n",
    "            })\n",
    "\n",
    "        df_segment = pd.DataFrame(seg_data)\n",
    "        display(df_segment)\n",
    "\n",
    "        if visualize:\n",
    "            visualize_segment_lift(df_segment, segment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac0887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For continuous metric like engagement_score\n",
    "analyze_segment_lift(\n",
    "    df=users,\n",
    "    group_col='group',\n",
    "    metric_col='engagement_score',\n",
    "    segment_cols=['platform', 'device_type', 'user_tier', 'region'],\n",
    "    group_labels=('control', 'treatment'),\n",
    "    experiment_type='continuous_independent',\n",
    "    min_count_per_group=30,\n",
    "    visualize=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8135b7",
   "metadata": {},
   "source": [
    "#### Guardrail Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cca45b",
   "metadata": {},
   "source": [
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "\n",
    "Guardrail metrics are **non-primary metrics** tracked during an experiment to ensure the feature doesn't create **unintended negative consequences**.\n",
    "\n",
    "We monitor them alongside the main success metric to:\n",
    "- 📉 Catch regressions in user behavior or system performance  \n",
    "- 🔍 Detect trade-offs (e.g., conversion ↑ but bounce rate ↑ too)  \n",
    "- 🛑 Block rollouts if a feature does more harm than good\n",
    "\n",
    "###### 🧪 How We Check\n",
    "- Run **statistical tests** on each guardrail metric just like we do for the primary metric\n",
    "- Use the **same experiment type** (binary, continuous, etc.) for evaluation\n",
    "- Report **p-values and lift** to assess significance and direction\n",
    "- Focus more on **risk detection** than optimization\n",
    "\n",
    "###### 📊 Common Guardrail Metrics\n",
    "| Type        | Examples                              |\n",
    "|-------------|----------------------------------------|\n",
    "| **UX Health**   | Bounce Rate, Session Length, Engagement |\n",
    "| **Performance** | Page Load Time, API Latency, CPU Usage |\n",
    "| **Reliability** | Error Rate, Crash Rate, Timeout Errors  |\n",
    "| **Behavioral**  | Scroll Depth, Page Views per Session     |\n",
    "\n",
    "###### ✅ When to Act\n",
    "- If the **treatment significantly worsens** a guardrail metric → investigate\n",
    "- If the **primary metric improves** but **guardrails suffer**, assess trade-offs\n",
    "- Use **p-values**, **lift**, and **domain context** to guide decision-making\n",
    "\n",
    "###### 🧠 Why Guardrails Matter\n",
    "> “We don’t just care *if* a metric moves — we care *what else* it moved. Guardrails give us confidence that improvements aren’t hiding regressions elsewhere.”\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c7ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick average check by group\n",
    "guardrail_avg = users.groupby('group')['bounce_rate'].mean()\n",
    "\n",
    "print(\"🚦 Average Bounce Rate by Group:\")\n",
    "for grp, val in guardrail_avg.items():\n",
    "    print(f\"- {grp}: {val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fcb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_guardrail_metric(df, group_col='group', metric_col='bounce_rate', group_labels=('control', 'treatment'), alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compare guardrail metric across two groups to check for significant changes.\n",
    "    \n",
    "    Parameters:\n",
    "    - df : pd.DataFrame with experimental data\n",
    "    - group_col : str, column name for group assignment\n",
    "    - metric_col : str, guardrail metric to compare\n",
    "    - group_labels : tuple of (control_group, treatment_group)\n",
    "    - alpha : float, significance threshold\n",
    "\n",
    "    Returns:\n",
    "    - None (prints results)\n",
    "    \"\"\"\n",
    "    print(f\"\\n🚦 Guardrail Metric Check: {metric_col}\\n\")\n",
    "    \n",
    "    control, treatment = group_labels\n",
    "    control_vals = df[df[group_col] == control][metric_col]\n",
    "    treatment_vals = df[df[group_col] == treatment][metric_col]\n",
    "\n",
    "    mean_control = control_vals.mean()\n",
    "    mean_treatment = treatment_vals.mean()\n",
    "    diff = mean_treatment - mean_control\n",
    "\n",
    "    t_stat, p_val = ttest_ind(treatment_vals, control_vals)\n",
    "\n",
    "    print(f\"- {control}    : {mean_control:.4f}\")\n",
    "    print(f\"- {treatment}  : {mean_treatment:.4f}\")\n",
    "    print(f\"- Difference : {diff:+.4f}\")\n",
    "    print(f\"- P-value (t-test): {p_val:.4f}\")\n",
    "\n",
    "    if p_val < alpha:\n",
    "        if diff > 0:\n",
    "            print(\"❌ Significant *increase* in this guardrail — potential negative impact.\")\n",
    "        else:\n",
    "            print(\"✅ Significant *decrease* — potential positive impact.\")\n",
    "    else:\n",
    "        print(\"🟡 No statistically significant change — guardrail looks stable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_guardrail_metric(users, metric_col='bounce_rate', group_labels=('control', 'treatment'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbcb939",
   "metadata": {},
   "source": [
    "#### Rollout Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397302e7",
   "metadata": {},
   "source": [
    "<details> <summary><strong>📊 Click to Expand </strong></summary>\n",
    "Once statistical significance is established, it's useful to simulate **business impact** from full rollout.\n",
    "\n",
    "Assume full exposure to **eligible daily traffic**, and estimate **incremental impact** from the observed lift.\n",
    "\n",
    "This helps stakeholders understand the real-world benefit of implementing the change.\n",
    "\n",
    "We typically estimate:\n",
    "\n",
    "- 📈 Daily lift (e.g., additional conversions, dollars, sessions)\n",
    "- 📈 Monthly extrapolation (daily lift × 30)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_rollout_impact(\n",
    "    experiment_result,\n",
    "    daily_eligible_observations,\n",
    "    metric_unit='conversions'\n",
    "):\n",
    "    \"\"\"\n",
    "    Estimate daily and monthly impact of full rollout using observed lift.\n",
    "\n",
    "    Parameters:\n",
    "    - experiment_result : dict\n",
    "        Output of run_ab_test() — must contain summary, group_labels, and lift\n",
    "    - daily_eligible_observations : int\n",
    "        Number of eligible units exposed per day (users, sessions, orders)\n",
    "    - metric_unit : str\n",
    "        Label for what is being impacted (e.g., 'conversions', 'revenue', 'sessions')\n",
    "\n",
    "    Returns:\n",
    "    - Prints estimated daily and monthly lift\n",
    "    \"\"\"\n",
    "\n",
    "    group1, group2 = experiment_result['group_labels']\n",
    "    summary = experiment_result['summary']\n",
    "\n",
    "    mean1 = summary[group1]['mean']\n",
    "    mean2 = summary[group2]['mean']\n",
    "    lift = mean2 - mean1\n",
    "\n",
    "    daily_impact = lift * daily_eligible_observations\n",
    "    monthly_impact = daily_impact * 30\n",
    "\n",
    "    print(\"📦 Rollout Simulation\")\n",
    "    print(f\"- Unit of analysis   : {metric_unit}\")\n",
    "    print(f\"- Observed Lift      : {lift:.4f} per unit\")\n",
    "    print(f\"- Daily Impact       : {daily_impact:.0f} {metric_unit}/day\")\n",
    "    print(f\"- Monthly Impact     : {monthly_impact:.0f} {metric_unit}/month\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc977fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_rollout_impact(\n",
    "    experiment_result=result,               # from run_ab_test()\n",
    "    daily_eligible_observations=10000,      # could be users, sessions, etc.\n",
    "    metric_unit='conversions'               # or 'revenue', 'clicks', etc.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87d394",
   "metadata": {},
   "source": [
    "[Back to the top](#Contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
