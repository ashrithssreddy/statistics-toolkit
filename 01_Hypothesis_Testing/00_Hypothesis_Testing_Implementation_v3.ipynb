{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"table-of-contents\"></a>\n",
    "# üìñ Table of Contents\n",
    "\n",
    "- [üóÇÔ∏è Data Setup](#data-setup)  \n",
    "- [üõ†Ô∏è Test Setup](#test-setup)  \n",
    "- [üìà Inference](#inference)  \n",
    "<!-- - [üß™ Hypothesis Testing](#hypothesis-testing)   -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>üìñ Hypothesis Testing - Assumptions & Methods (Click to Expand)</strong></summary>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Test Type</th>\n",
    "      <th>Use Case</th>\n",
    "      <th>Parametric?</th>\n",
    "      <th>Assumptions</th>\n",
    "      <th>Non-Parametric Alternative</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>One-Sample t-test</td>\n",
    "      <td>Compare sample mean vs. known value</td>\n",
    "      <td>‚úÖ</td>\n",
    "      <td>Normality of sample</td>\n",
    "      <td>Sign test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Two-Sample t-test</td>\n",
    "      <td>Compare means of two independent groups</td>\n",
    "      <td>‚úÖ</td>\n",
    "      <td>- Normality (both groups)<br>- Equal variance (if pooled)<br>- Independence</td>\n",
    "      <td>Mann-Whitney U</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Paired t-test</td>\n",
    "      <td>Compare means of two related samples (before-after, matched)</td>\n",
    "      <td>‚úÖ</td>\n",
    "      <td>- Normality of *differences*<br>- No extreme outliers</td>\n",
    "      <td>Wilcoxon signed-rank</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Proportions z-test</td>\n",
    "      <td>Compare binary rates (e.g., CTR in A vs B)</td>\n",
    "      <td>‚úÖ</td>\n",
    "      <td>- np > 5, nq > 5 (sample size rule)<br>- Independence</td>\n",
    "      <td>Fisher‚Äôs exact</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Chi-Square Test</td>\n",
    "      <td>Categorical association (e.g., device type vs. AR adoption)</td>\n",
    "      <td>‚úÖ</td>\n",
    "      <td>- Expected count ‚â• 5 in ‚â• 80% of cells<br>- Independence</td>\n",
    "      <td>Fisher‚Äôs exact</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>ANOVA</td>\n",
    "      <td>Compare means across 3+ groups</td>\n",
    "      <td>‚úÖ</td>\n",
    "      <td>- Normality<br>- Equal variance<br>- Independence</td>\n",
    "      <td>Kruskal-Wallis</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Mann-Whitney U</td>\n",
    "      <td>Compare medians/ranks of two independent groups</td>\n",
    "      <td>‚ùå</td>\n",
    "      <td>- Same shape distribution (ideally)<br>- Ordinal or continuous data</td>\n",
    "      <td>N/A</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Wilcoxon Signed-Rank</td>\n",
    "      <td>Paired version of Mann-Whitney (for related samples)</td>\n",
    "      <td>‚ùå</td>\n",
    "      <td>- Symmetry in differences<br>- Ordinal or continuous</td>\n",
    "      <td>Sign test</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>üìñ Hypothesis Test Selection Matrix (Click to Expand)</strong></summary>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Outcome Type</th>\n",
    "      <th>Group Relationship</th>\n",
    "      <th>Group Count</th>\n",
    "      <th>Outcome Distribution</th>\n",
    "      <th>Business Problem</th>\n",
    "      <th>Recommended Test</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>one-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Is average order value different from $50?</td>\n",
    "      <td>One-sample t-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>one-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Is conversion rate different from 10%?</td>\n",
    "      <td>One-proportion z-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Do users who saw the new recommendation engine spend more time on site?</td>\n",
    "      <td>Two-sample t-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Is there a difference in revenue between users who got coupon A vs B?</td>\n",
    "      <td>Mann-Whitney U test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Did users spend more after homepage redesign?</td>\n",
    "      <td>Paired t-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Did time on site change after layout update (skewed)?</td>\n",
    "      <td>Wilcoxon signed-rank test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Does a new CTA improve conversions?</td>\n",
    "      <td>Proportions z-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Do users convert more after adding trust badges?</td>\n",
    "      <td>McNemar‚Äôs test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>categorical</td>\n",
    "      <td>independent</td>\n",
    "      <td>multi-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Do plan choices differ between layout A/B/C?</td>\n",
    "      <td>Chi-square test</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>üìñ Hypothesis Test Selection Matrix (Click to Expand)</strong></summary>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Outcome Type</th>\n",
    "      <th>Group Relationship</th>\n",
    "      <th>Group Count</th>\n",
    "      <th>Outcome Distribution</th>\n",
    "      <th>Business Problem</th>\n",
    "      <th>Recommended Test</th>\n",
    "      <th>Notes</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>one-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Is average order value different from $50?</td>\n",
    "      <td>One-sample t-test</td>\n",
    "      <td>Use Wilcoxon signed-rank if not normal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>one-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Is conversion rate different from 10%?</td>\n",
    "      <td>One-proportion z-test</td>\n",
    "      <td>Use binomial exact test if n is small</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Do users who saw recs spend more time on site?</td>\n",
    "      <td>Two-sample t-test</td>\n",
    "      <td>Use Welch‚Äôs t-test if variances unequal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Is revenue different between coupon A vs B?</td>\n",
    "      <td>Mann-Whitney U test</td>\n",
    "      <td>Non-parametric; tests medians</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Did users spend more after redesign?</td>\n",
    "      <td>Paired t-test</td>\n",
    "      <td>Assumes differences are normal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Did time on site change (skewed)?</td>\n",
    "      <td>Wilcoxon signed-rank test</td>\n",
    "      <td>Use for non-normal paired diffs</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Does new CTA improve conversion?</td>\n",
    "      <td>Proportions z-test</td>\n",
    "      <td>Chi-square for raw counts</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Do users convert more after badges?</td>\n",
    "      <td>McNemar‚Äôs test</td>\n",
    "      <td>Use for paired binary outcomes</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>categorical</td>\n",
    "      <td>independent</td>\n",
    "      <td>multi-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Do plan choices differ across layouts?</td>\n",
    "      <td>Chi-square test</td>\n",
    "      <td>Expected counts ‚â•5 in each cell</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>count</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>Poisson</td>\n",
    "      <td>Do users add more items to cart?</td>\n",
    "      <td>Poisson / NB test</td>\n",
    "      <td>Use NB if overdispersion (variance > mean)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>multi-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Does time spent differ across A/B/C?</td>\n",
    "      <td>ANOVA</td>\n",
    "      <td>Welch ANOVA if variances differ</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>multi-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Does spend differ across segments?</td>\n",
    "      <td>Kruskal-Wallis test</td>\n",
    "      <td>Non-parametric alternative to ANOVA</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>any</td>\n",
    "      <td>any</td>\n",
    "      <td>any</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Is effect still significant after adjusting for device & region?</td>\n",
    "      <td>Regression (linear / logistic)</td>\n",
    "      <td>Use when controlling for covariates</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>any</td>\n",
    "      <td>any</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>What‚Äôs the probability that B beats A?</td>\n",
    "      <td>Bayesian A/B test</td>\n",
    "      <td>Reports posterior probability instead of p-value</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>any</td>\n",
    "      <td>any</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>‚Äì</td>\n",
    "      <td>Is observed lift statistically rare?</td>\n",
    "      <td>Permutation / Bootstrap</td>\n",
    "      <td>Use when assumptions are violated</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-setup\"></a>\n",
    "# üóÇÔ∏è Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': None,\n",
       " 'variance_equal': None,\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': None,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grotup or sample?\n",
    "\n",
    "config = {\n",
    "    'outcome_type': 'continuous',        # continuous, binary, categorical, count\n",
    "    'group_relationship': 'independent', # independent or paired\n",
    "    'group_count': 'two-sample',         # one-sample, two-sample, multi-sample\n",
    "    'distribution': None,                # normal or non-normal ‚Üí to be inferred\n",
    "    'variance_equal': None,              # equal or unequal ‚Üí to be inferred\n",
    "    'tail_type': 'two-tailed',           # or 'one-tailed'\n",
    "    'parametric': None,                  # True or False ‚Üí to be inferred\n",
    "    'alpha': 0.05,                       # significance level\n",
    "    'sample_size': 100,                  # per group\n",
    "    'effect_size': 0.5,                  # for generating synthetic difference\n",
    "    # 'generated_data': None               # placeholder for attached df\n",
    "}\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Settings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_test_data(\n",
    "#     outcome_type='continuous', \n",
    "#     variant='independent', \n",
    "#     size=100, \n",
    "#     mean_diff=0.5, \n",
    "#     skew=False,\n",
    "#     seed=42\n",
    "# ):\n",
    "#     np.random.seed(seed)\n",
    "    \n",
    "#     if outcome_type == 'continuous':\n",
    "#         if skew:\n",
    "#             # Right-skewed data using exponential distribution\n",
    "#             A = np.random.exponential(scale=1.0, size=size)\n",
    "#             B = np.random.exponential(scale=1.0 + mean_diff, size=size)\n",
    "#         else:\n",
    "#             A = np.random.normal(loc=5.0, scale=1.0, size=size)\n",
    "#             B = np.random.normal(loc=5.0 + mean_diff, scale=1.0, size=size)\n",
    "\n",
    "#     elif outcome_type == 'binary':\n",
    "#         A = np.random.binomial(1, 0.4, size=size)\n",
    "#         B = np.random.binomial(1, 0.4 + mean_diff, size=size)\n",
    "    \n",
    "#     if variant == 'paired':\n",
    "#         # Ensure same users in both conditions for paired testing\n",
    "#         df = pd.DataFrame({\n",
    "#             'user_id': np.arange(size),\n",
    "#             'group_A': A,\n",
    "#             'group_B': B\n",
    "#         })\n",
    "#     else:\n",
    "#         df = pd.DataFrame({\n",
    "#             'group': ['A'] * size + ['B'] * size,\n",
    "#             'value': np.concatenate([A, B])\n",
    "#         })\n",
    "    \n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SCENARIO 1: Continuous, Independent, Normally Distributed\n",
    "# print(\"üìä Scenario 1: Continuous, Independent, Normal\")\n",
    "# print(\"Hypothesis: Do users who see personalized product recommendations (Group B) spend more time on site than those who don‚Äôt (Group A)?\\n\")\n",
    "# df1 = create_test_data(outcome_type='continuous', variant='independent', size=100)\n",
    "# display(df1.head())\n",
    "# print(\"üóÇ group = control/treatment group (A/B), value = session duration (minutes)\")\n",
    "# print(\"-\" * 100)\n",
    "\n",
    "# # SCENARIO 2: Continuous, Paired, Skewed\n",
    "# print(\"\\nüìä Scenario 2: Continuous, Paired, Skewed\")\n",
    "# print(\"Hypothesis: Does time spent per user increase after a homepage redesign?\\n\")\n",
    "# df2 = create_test_data(outcome_type='continuous', variant='paired', size=100, skew=True)\n",
    "# display(df2.head())\n",
    "# print(\"üóÇ user_id = user ID, group_A = time on old homepage, group_B = time on redesigned homepage\")\n",
    "# print(\"-\" * 100)\n",
    "\n",
    "# # SCENARIO 3: Binary, Independent\n",
    "# print(\"\\nüìä Scenario 3: Binary, Independent\")\n",
    "# print(\"Hypothesis: Does a new CTA button improve conversion rates vs. the current design?\\n\")\n",
    "# df3 = create_test_data(outcome_type='binary', variant='independent', size=500, mean_diff=0.1)\n",
    "# display(df3.head())\n",
    "# print(\"üóÇ group = control/treatment group (A/B), value = conversion (1 = yes, 0 = no)\")\n",
    "# print(\"-\" * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_data_from_config(config, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    outcome = config['outcome_type']\n",
    "    group_count = config['group_count']\n",
    "    relationship = config['group_relationship']\n",
    "    size = config['sample_size']\n",
    "    effect = config['effect_size']\n",
    "    pop_mean = config.get('population_mean', 0)\n",
    "\n",
    "    # 1Ô∏è‚É£ One-sample case\n",
    "    if group_count == 'one-sample':\n",
    "        if outcome == 'continuous':\n",
    "            values = np.random.normal(loc=pop_mean + effect, scale=1.0, size=size)\n",
    "            df = pd.DataFrame({'value': values})\n",
    "        elif outcome == 'binary':\n",
    "            prob = pop_mean + effect\n",
    "            values = np.random.binomial(1, prob, size=size)\n",
    "            df = pd.DataFrame({'value': values})\n",
    "        else:\n",
    "            raise NotImplementedError(\"One-sample generation only supports continuous/binary for now.\")\n",
    "\n",
    "    # 2Ô∏è‚É£ Two-sample case\n",
    "    elif group_count == 'two-sample':\n",
    "        if relationship == 'independent':\n",
    "            if outcome == 'continuous':\n",
    "                A = np.random.normal(loc=5.0, scale=1.0, size=size)\n",
    "                B = np.random.normal(loc=5.0 + effect, scale=1.0, size=size)\n",
    "            elif outcome == 'binary':\n",
    "                A = np.random.binomial(1, 0.4, size=size)\n",
    "                B = np.random.binomial(1, 0.4 + effect, size=size)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            df = pd.DataFrame({\n",
    "                'group': ['A'] * size + ['B'] * size,\n",
    "                'value': np.concatenate([A, B])\n",
    "            })\n",
    "        \n",
    "        elif relationship == 'paired':\n",
    "            if outcome == 'continuous':\n",
    "                before = np.random.normal(loc=5.0, scale=1.0, size=size)\n",
    "                after = before + effect + np.random.normal(0, 0.5, size=size)\n",
    "            elif outcome == 'binary':\n",
    "                before = np.random.binomial(1, 0.4, size=size)\n",
    "                after = np.random.binomial(1, 0.4 + effect, size=size)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            df = pd.DataFrame({\n",
    "                'user_id': np.arange(size),\n",
    "                'group_A': before,\n",
    "                'group_B': after\n",
    "            })\n",
    "        else:\n",
    "            raise ValueError(\"Missing or invalid group relationship.\")\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Multi-sample not supported yet.\")\n",
    "\n",
    "    # attach to config\n",
    "    # config['generated_data'] = df\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>5.496714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>4.861736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>5.647689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>6.523030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>4.765847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>B</td>\n",
       "      <td>5.885317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>B</td>\n",
       "      <td>4.616143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>B</td>\n",
       "      <td>5.653725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>B</td>\n",
       "      <td>5.558209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>B</td>\n",
       "      <td>4.357030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    group     value\n",
       "0       A  5.496714\n",
       "1       A  4.861736\n",
       "2       A  5.647689\n",
       "3       A  6.523030\n",
       "4       A  4.765847\n",
       "..    ...       ...\n",
       "195     B  5.885317\n",
       "196     B  4.616143\n",
       "197     B  5.653725\n",
       "198     B  5.558209\n",
       "199     B  4.357030\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_data_from_config(config)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test-setup\"></a>\n",
    "\n",
    "# üõ†Ô∏è Test Setup\n",
    "\n",
    "\n",
    "<details><summary><strong>üìñ Test Settings Explanation (Click to Expand)</strong></summary>\n",
    "\n",
    "### üìä **Test Type (test_type)**\n",
    "This setting defines the type of test you want to perform.\n",
    "\n",
    "- **one_sample**: Comparing the sample mean against a known value (e.g., a population mean).\n",
    "- **two_sample**: Comparing the means of two independent groups (e.g., A vs B).\n",
    "- **paired**: Comparing means from the same group at two different times (before vs after).\n",
    "- **proportions**: Comparing proportions (e.g., the conversion rates of two groups).\n",
    "\n",
    "**Example**: You might want to test if the mean age of two groups of people (Group A and Group B) differs, or if the proportion of people who converted in each group is different.\n",
    "\n",
    "### üìè **Tail Type (tail_type)**\n",
    "This setting determines whether you are performing a one-tailed or two-tailed test.\n",
    "\n",
    "- **one_tailed**: You are testing if the value is greater than or less than the reference value (directional).\n",
    "- **two_tailed**: You are testing if the value is different from the reference value, either higher or lower (non-directional).\n",
    "\n",
    "**Example**:  \n",
    "- **One-tailed**: Testing if new treatment increases sales (you only care if it's greater).  \n",
    "- **Two-tailed**: Testing if there is any difference in sales between two treatments (it could be either an increase or decrease).\n",
    "\n",
    "### üßÆ **Parametric (parametric)**\n",
    "This setting indicates whether the test is **parametric** or **non-parametric**.\n",
    "\n",
    "- **True (Parametric)**: This means we assume that the data follows a certain distribution, often a **normal distribution**. The most common parametric tests are **t-tests** and **z-tests**. Parametric tests are generally more powerful if the assumptions are met.\n",
    "  \n",
    "- **False (Non-Parametric)**: Non-parametric tests don‚Äôt assume any specific distribution. These are used when the data doesn‚Äôt follow a normal distribution or when the sample size is small. Examples include **Mann-Whitney U** (alternative to the t-test) and **Wilcoxon Signed-Rank** (alternative to paired t-test).\n",
    "\n",
    "**Why does this matter?**  \n",
    "Parametric tests tend to be more powerful because they make assumptions about the distribution of the data (e.g., normality). Non-parametric tests are more flexible and can be used when these assumptions are not met, but they may be less powerful.\n",
    "\n",
    "### üìä **Equal Variance (equal_variance)**\n",
    "This setting is used specifically for **two-sample t-tests**.\n",
    "\n",
    "- **True**: Assumes that the two groups have **equal variances** (i.e., the spread of data is the same in both groups). This is used for the **pooled t-test**.\n",
    "  \n",
    "- **False**: Assumes the two groups have **different variances**. This is used for the **Welch t-test**, which is more robust when the assumption of equal variances is violated.\n",
    "\n",
    "**Why is this important?**  \n",
    "If the variances are not equal, using a pooled t-test (which assumes equal variance) can lead to incorrect conclusions. The Welch t-test is safer when in doubt about the equality of variances.\n",
    "\n",
    "### üîë **Significance Level (alpha)**\n",
    "The **alpha** level is your **threshold for statistical significance**.\n",
    "\n",
    "- Commonly set at **0.05**, this means that you are willing to accept a 5% chance of wrongly rejecting the null hypothesis (i.e., a 5% chance of a Type I error).\n",
    "  \n",
    "- If the **p-value** (calculated from your test) is less than **alpha**, you reject the null hypothesis. If it's greater than alpha, you fail to reject the null hypothesis.\n",
    "\n",
    "**Example**:  \n",
    "- **alpha = 0.05** means there‚Äôs a 5% risk of concluding that a treatment has an effect when it actually doesn‚Äôt.\n",
    "\n",
    "### üéØ **Putting It All Together**\n",
    "\n",
    "For instance, let's say you're testing if a new feature (Group A) increases user engagement compared to the existing feature (Group B). Here‚Äôs how each configuration works together:\n",
    "\n",
    "- **test_type** = `'two_sample'`: You're comparing two independent groups (A vs B).\n",
    "- **tail_type** = `'two_tailed'`: You‚Äôre testing if there‚Äôs any difference (increase or decrease) in engagement.\n",
    "- **parametric** = `True`: You assume the data is normally distributed, so a t-test will be appropriate.\n",
    "- **equal_variance** = `True`: You assume the two groups have equal variance, so you‚Äôll use a pooled t-test.\n",
    "- **alpha** = `0.05`: You‚Äôre using a 5% significance level for your hypothesis test.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': None,\n",
       " 'variance_equal': None,\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': None,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------\n",
    "# CONFIGURATION SETUP\n",
    "# -------------------------\n",
    "# config = {\n",
    "#     'test_type': 'two_sample',         # one_sample, two_sample, paired, proportions\n",
    "#     'tail_type': 'two_tailed',         # one_tailed or two_tailed\n",
    "#     'parametric': True,                # True = t-test/z-test, False = non-parametric\n",
    "#     'equal_variance': True,            # Used in two-sample t-test (pooled vs Welch)\n",
    "#     'alpha': 0.05                      # Significance level\n",
    "# }\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Inference\"></a>\n",
    "\n",
    "# üìà Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import shapiro, levene\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# print(\"\\nüîç Assumption Checks\")\n",
    "\n",
    "# # Normality check\n",
    "# _, p_A = shapiro(group_A)\n",
    "# _, p_B = shapiro(group_B)\n",
    "# print(f\"Normality (Shapiro-Wilk): A p={p_A:.3f}, B p={p_B:.3f}\")\n",
    "\n",
    "# # Variance check\n",
    "# _, p_var = levene(group_A, group_B)\n",
    "# print(f\"Equal Variance (Levene's): p={p_var:.3f}\\n\")\n",
    "\n",
    "# # Visuals\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "# sns.histplot(data, x='value', hue='group', kde=True, ax=axs[0])\n",
    "# axs[0].set_title('Histogram')\n",
    "# sns.boxplot(data=data, x='group', y='value', ax=axs[1])\n",
    "# axs[1].set_title('Boxplot')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': None,\n",
       " 'variance_equal': None,\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': None,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer_distribution_from_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': 'normal',\n",
       " 'variance_equal': None,\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': None,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "def infer_distribution_from_data(config, df):\n",
    "    group_count = config['group_count']\n",
    "    relationship = config['group_relationship']\n",
    "    outcome = config['outcome_type']\n",
    "\n",
    "    if outcome != 'continuous':\n",
    "        config['distribution'] = 'NA'\n",
    "        return config\n",
    "\n",
    "    if group_count == 'one-sample':\n",
    "        stat, p = shapiro(df['value'])\n",
    "        config['distribution'] = 'normal' if p > 0.05 else 'non-normal'\n",
    "        return config\n",
    "    \n",
    "    elif group_count == 'two-sample':\n",
    "        if relationship == 'independent':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "        elif relationship == 'paired':\n",
    "            a = df['group_A']\n",
    "            b = df['group_B']\n",
    "        else:\n",
    "            config['distribution'] = 'NA'\n",
    "            return config\n",
    "\n",
    "        p1 = shapiro(a)[1]\n",
    "        p2 = shapiro(b)[1]\n",
    "        config['distribution'] = 'normal' if (p1 > 0.05 and p2 > 0.05) else 'non-normal'\n",
    "        return config\n",
    "    \n",
    "    else:\n",
    "        config['distribution'] = 'NA'\n",
    "        return config\n",
    "    \n",
    "config = infer_distribution_from_data(config, df)\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer_variance_equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': 'normal',\n",
       " 'variance_equal': 'equal',\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': None,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "def infer_variance_equality(config, df):\n",
    "    if config['group_count'] != 'two-sample' or config['group_relationship'] != 'independent':\n",
    "        config['variance_equal'] = 'NA'\n",
    "        return config\n",
    "\n",
    "    a = df[df['group'] == 'A']['value']\n",
    "    b = df[df['group'] == 'B']['value']\n",
    "    stat, p = levene(a, b)\n",
    "    config['variance_equal'] = 'equal' if p > 0.05 else 'unequal'\n",
    "    return config\n",
    "\n",
    "config = infer_variance_equality(config, df)\n",
    "config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "infer_parametric_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': 'normal',\n",
       " 'variance_equal': 'equal',\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': None,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer_parametric_flag(config):\n",
    "    if config['outcome_type'] != 'continuous':\n",
    "        config['parametric'] = 'NA'\n",
    "        return config\n",
    "\n",
    "    is_normal = config['distribution'] == 'normal'\n",
    "    is_equal_var = config['variance_equal'] in ['equal', 'NA']  # NA = not required for paired\n",
    "\n",
    "    config['parametric'] = True if is_normal and is_equal_var else False\n",
    "    return config\n",
    "\n",
    "config = infer_variance_equality(config, df)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Hypothesis Test Configuration Summary\n",
      "\n",
      "üî∏ Outcome Type           : continuous\n",
      "üî∏ Group Relationship      : independent\n",
      "üî∏ Group Count             : two-sample\n",
      "üî∏ Distribution of Outcome : normal\n",
      "üî∏ Equal Variance          : equal\n",
      "üî∏ Parametric Test         : None\n",
      "üî∏ Tail Type               : two-tailed\n",
      "üî∏ Significance Level Œ±    : 0.05\n",
      "\n",
      "üß† Inference Summary:\n",
      "‚Üí Comparing two independent groups (A vs B).\n",
      "\n",
      "üß™ Selected Test:\n",
      "‚úÖ mann_whitney_u\n"
     ]
    }
   ],
   "source": [
    "def print_config_summary(config):\n",
    "    print(\"üìã Hypothesis Test Configuration Summary\\n\")\n",
    "\n",
    "    print(f\"üî∏ Outcome Type           : {config['outcome_type']}\")\n",
    "    print(f\"üî∏ Group Relationship      : {config['group_relationship']}\")\n",
    "    print(f\"üî∏ Group Count             : {config['group_count']}\")\n",
    "    print(f\"üî∏ Distribution of Outcome : {config['distribution']}\")\n",
    "    print(f\"üî∏ Equal Variance          : {config['variance_equal']}\")\n",
    "    print(f\"üî∏ Parametric Test         : {config['parametric']}\")\n",
    "    print(f\"üî∏ Tail Type               : {config['tail_type']}\")\n",
    "    print(f\"üî∏ Significance Level Œ±    : {config['alpha']}\")\n",
    "\n",
    "    print(\"\\nüß† Inference Summary:\")\n",
    "    if config['group_count'] == 'one-sample':\n",
    "        print(\"‚Üí This is a one-sample test comparing a sample to a known value.\")\n",
    "    elif config['group_count'] == 'two-sample':\n",
    "        if config['group_relationship'] == 'independent':\n",
    "            print(\"‚Üí Comparing two independent groups (A vs B).\")\n",
    "        elif config['group_relationship'] == 'paired':\n",
    "            print(\"‚Üí Comparing paired measurements (before vs after, same users).\")\n",
    "    \n",
    "    print(\"\\nüß™ Selected Test:\")\n",
    "    print(f\"‚úÖ {determine_test_to_run(config)}\")\n",
    "print_config_summary(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Hypothesis Statement\n",
      "\n",
      "H‚ÇÄ: The average (or proportion) is the same across groups A and B.\n",
      "H‚ÇÅ: The average (or proportion) differs between groups.\n"
     ]
    }
   ],
   "source": [
    "def print_hypothesis_statement(config):\n",
    "    test = determine_test_to_run(config)\n",
    "    outcome = config['outcome_type']\n",
    "    tail = config['tail_type']\n",
    "    group_count = config['group_count']\n",
    "    rel = config['group_relationship']\n",
    "\n",
    "    print(\"üß™ Hypothesis Statement\\n\")\n",
    "\n",
    "    # One-sample (mean or proportion)\n",
    "    if test == 'one_sample_ttest':\n",
    "        print(\"H‚ÇÄ: The average outcome equals the benchmark value.\")\n",
    "        print(\"H‚ÇÅ: The average outcome is different from the benchmark.\" if tail == 'two-tailed' else \"H‚ÇÅ: The average outcome is greater/less than the benchmark.\")\n",
    "    \n",
    "    elif test == 'one_proportion_ztest':\n",
    "        print(\"H‚ÇÄ: The proportion equals the expected baseline.\")\n",
    "        print(\"H‚ÇÅ: The proportion is different from the baseline.\" if tail == 'two-tailed' else \"H‚ÇÅ: The proportion is greater/less than the baseline.\")\n",
    "\n",
    "    # Two-sample, independent\n",
    "    elif test in ['two_sample_ttest_pooled', 'two_sample_ttest_welch', 'mann_whitney_u', 'two_proportion_ztest']:\n",
    "        print(\"H‚ÇÄ: The average (or proportion) is the same across groups A and B.\")\n",
    "        print(\"H‚ÇÅ: The average (or proportion) differs between groups.\" if tail == 'two-tailed' else \"H‚ÇÅ: Group B is greater/less than group A.\")\n",
    "    \n",
    "    # Paired\n",
    "    elif test in ['paired_ttest', 'wilcoxon_signed_rank']:\n",
    "        print(\"H‚ÇÄ: There is no average difference between the paired values (before vs after).\")\n",
    "        print(\"H‚ÇÅ: There is an average difference in the paired values.\" if tail == 'two-tailed' else \"H‚ÇÅ: After is greater/less than before.\")\n",
    "\n",
    "    elif test == 'mcnemar':\n",
    "        print(\"H‚ÇÄ: Proportion of success before = after.\")\n",
    "        print(\"H‚ÇÅ: Proportion of success changed after treatment.\")\n",
    "\n",
    "    # Multi-group\n",
    "    elif test in ['anova', 'kruskal_wallis']:\n",
    "        print(\"H‚ÇÄ: All group means (or distributions) are equal.\")\n",
    "        print(\"H‚ÇÅ: At least one group differs.\")\n",
    "\n",
    "    elif test == 'chi_square':\n",
    "        print(\"H‚ÇÄ: Distribution of categories is the same across groups.\")\n",
    "        print(\"H‚ÇÅ: At least one category is distributed differently across groups.\")\n",
    "\n",
    "    # Count data\n",
    "    elif test == 'poisson_test':\n",
    "        print(\"H‚ÇÄ: Count rate (Œª) is equal across groups.\")\n",
    "        print(\"H‚ÇÅ: Count rate differs between groups.\")\n",
    "\n",
    "    # Bayesian / permutation\n",
    "    elif test == 'bayesian_ab':\n",
    "        print(\"Posterior probability that Group B is better than Group A.\")\n",
    "    elif test == 'permutation_test':\n",
    "        print(\"H‚ÇÄ: The observed difference is due to chance.\")\n",
    "        print(\"H‚ÇÅ: The observed difference is rare under random shuffling.\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ùì Could not determine hypothesis statements for test:\", test)\n",
    "print_hypothesis_statement(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hypothesis-testing\"></a>\n",
    "\n",
    "<h1>üß™ Hypothesis Testing</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': 'normal',\n",
       " 'variance_equal': 'equal',\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': True,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_test_to_run(config):\n",
    "    outcome = config['outcome_type']\n",
    "    group_rel = config['group_relationship']\n",
    "    group_count = config['group_count']\n",
    "    dist = config['distribution']\n",
    "    equal_var = config['variance_equal']\n",
    "    parametric = config['parametric']\n",
    "\n",
    "    # 1Ô∏è‚É£ One-sample cases\n",
    "    if group_count == 'one-sample':\n",
    "        if outcome == 'continuous':\n",
    "            return 'one_sample_ttest' if dist == 'normal' else 'one_sample_wilcoxon'\n",
    "        elif outcome == 'binary':\n",
    "            return 'one_proportion_ztest'\n",
    "    \n",
    "    # 2Ô∏è‚É£ Two-sample independent\n",
    "    if group_count == 'two-sample' and group_rel == 'independent':\n",
    "        if outcome == 'continuous':\n",
    "            if parametric:\n",
    "                return 'two_sample_ttest_pooled' if equal_var == 'equal' else 'two_sample_ttest_welch'\n",
    "            else:\n",
    "                return 'mann_whitney_u'\n",
    "        elif outcome == 'binary':\n",
    "            return 'two_proportion_ztest'\n",
    "        elif outcome == 'categorical':\n",
    "            return 'chi_square'\n",
    "\n",
    "    # 3Ô∏è‚É£ Two-sample paired\n",
    "    if group_count == 'two-sample' and group_rel == 'paired':\n",
    "        if outcome == 'continuous':\n",
    "            return 'paired_ttest' if parametric else 'wilcoxon_signed_rank'\n",
    "        elif outcome == 'binary':\n",
    "            return 'mcnemar'\n",
    "\n",
    "    # 4Ô∏è‚É£ Multi-group continuous\n",
    "    if group_count == 'multi-sample' and outcome == 'continuous':\n",
    "        return 'anova' if dist == 'normal' else 'kruskal_wallis'\n",
    "\n",
    "    # 5Ô∏è‚É£ Multi-group categorical\n",
    "    if group_count == 'multi-sample' and outcome == 'categorical':\n",
    "        return 'chi_square'\n",
    "\n",
    "    # 6Ô∏è‚É£ Count data\n",
    "    if outcome == 'count':\n",
    "        return 'poisson_test'\n",
    "\n",
    "    # 7Ô∏è‚É£ Adjusted models or Bayesian\n",
    "    # Could be added later\n",
    "\n",
    "    return 'test_not_found'\n",
    "infer_parametric_flag(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_hypothesis_test(cfg, data):\n",
    "#     from scipy.stats import ttest_ind, ttest_rel, mannwhitneyu, wilcoxon\n",
    "#     from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "#     A = data[data['group'] == 'A']['value']\n",
    "#     B = data[data['group'] == 'B']['value']\n",
    "\n",
    "#     tail = cfg['tail_type']\n",
    "#     alpha = cfg['alpha']\n",
    "\n",
    "#     print(\"\\nüß™ Running Hypothesis Test\")\n",
    "\n",
    "#     if cfg['test_type'] == 'two_sample':\n",
    "#         if cfg['parametric']:\n",
    "#             stat, p = ttest_ind(A, B, equal_var=cfg['equal_variance'])\n",
    "#         else:\n",
    "#             stat, p = mannwhitneyu(A, B)\n",
    "#     elif cfg['test_type'] == 'paired':\n",
    "#         if cfg['parametric']:\n",
    "#             stat, p = ttest_rel(A, B)\n",
    "#         else:\n",
    "#             stat, p = wilcoxon(A, B)\n",
    "#     elif cfg['test_type'] == 'proportions':\n",
    "#         # Binary conversion case\n",
    "#         count = np.array([A.sum(), B.sum()])\n",
    "#         nobs = np.array([len(A), len(B)])\n",
    "#         stat, p = proportions_ztest(count, nobs)\n",
    "#     else:\n",
    "#         print(\"Unsupported test_type\")\n",
    "#         return\n",
    "\n",
    "#     # Adjust for one-tailed\n",
    "#     if tail == 'one_tailed':\n",
    "#         p = p / 2 if stat > 0 else 1 - (p / 2)\n",
    "\n",
    "#     print(f\"Test Statistic: {stat:.3f}  |  p-value: {p:.4f}\")\n",
    "\n",
    "#     if p < alpha:\n",
    "#         print(f\"‚úÖ Reject Null Hypothesis (p < {alpha})\")\n",
    "#     else:\n",
    "#         print(f\"‚ùå Fail to Reject Null Hypothesis (p >= {alpha})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import (\n",
    "    ttest_1samp, ttest_rel, ttest_ind, wilcoxon, mannwhitneyu,\n",
    "    shapiro, chi2_contingency, f_oneway, kruskal, binom_test, fisher_exact\n",
    ")\n",
    "import numpy as np\n",
    "import warnings\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "\n",
    "def run_hypothesis_test(config, df):\n",
    "    test_name = determine_test_to_run(config)\n",
    "    alpha = config.get('alpha', 0.05)\n",
    "\n",
    "    result = {\n",
    "        'test': test_name,\n",
    "        'statistic': None,\n",
    "        'p_value': None,\n",
    "        'significant': None,\n",
    "        'alpha': alpha\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        if test_name == 'one_sample_ttest':\n",
    "            stat, p = ttest_1samp(df['value'], config['population_mean'])\n",
    "\n",
    "        elif test_name == 'one_sample_wilcoxon':\n",
    "            stat, p = wilcoxon(df['value'] - config['population_mean'])\n",
    "\n",
    "        elif test_name == 'one_proportion_ztest':\n",
    "            x = np.sum(df['value'])\n",
    "            n = len(df)\n",
    "            stat, p = proportions_ztest(x, n, value=config['population_mean'])\n",
    "\n",
    "        elif test_name == 'two_sample_ttest_pooled':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "            stat, p = ttest_ind(a, b, equal_var=True)\n",
    "\n",
    "        elif test_name == 'two_sample_ttest_welch':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "            stat, p = ttest_ind(a, b, equal_var=False)\n",
    "\n",
    "        elif test_name == 'mann_whitney_u':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "            stat, p = mannwhitneyu(a, b, alternative='two-sided')\n",
    "\n",
    "        elif test_name == 'paired_ttest':\n",
    "            stat, p = ttest_rel(df['group_A'], df['group_B'])\n",
    "\n",
    "        elif test_name == 'wilcoxon_signed_rank':\n",
    "            stat, p = wilcoxon(df['group_A'], df['group_B'])\n",
    "\n",
    "        elif test_name == 'two_proportion_ztest':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "            counts = [np.sum(a), np.sum(b)]\n",
    "            nobs = [len(a), len(b)]\n",
    "            stat, p = proportions_ztest(count=counts, nobs=nobs)\n",
    "\n",
    "        elif test_name == 'mcnemar':\n",
    "            # Contingency table: [ [before+after], [before only], [after only], [neither] ]\n",
    "            both = np.sum((df['group_A'] == 1) & (df['group_B'] == 1))\n",
    "            before_only = np.sum((df['group_A'] == 1) & (df['group_B'] == 0))\n",
    "            after_only = np.sum((df['group_A'] == 0) & (df['group_B'] == 1))\n",
    "            neither = np.sum((df['group_A'] == 0) & (df['group_B'] == 0))\n",
    "            table = np.array([[both, before_only], [after_only, neither]])\n",
    "            stat, p = chi2_contingency(table, correction=True)[:2]\n",
    "\n",
    "        elif test_name == 'anova':\n",
    "            groups = [g['value'].values for _, g in df.groupby('group')]\n",
    "            stat, p = f_oneway(*groups)\n",
    "\n",
    "        elif test_name == 'kruskal_wallis':\n",
    "            groups = [g['value'].values for _, g in df.groupby('group')]\n",
    "            stat, p = kruskal(*groups)\n",
    "\n",
    "        elif test_name == 'chi_square':\n",
    "            contingency = pd.crosstab(df['group'], df['value'])\n",
    "            stat, p, _, _ = chi2_contingency(contingency)\n",
    "\n",
    "        else:\n",
    "            warnings.warn(f\"Test not implemented: {test_name}\")\n",
    "            return result\n",
    "\n",
    "        result['statistic'] = stat\n",
    "        result['p_value'] = p\n",
    "        result['significant'] = p < alpha\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error running test: {e}\")\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': 'two_sample_ttest_pooled', 'statistic': -4.754695943505297, 'p_value': 3.819135262679201e-06, 'significant': True, 'alpha': 0.05}\n"
     ]
    }
   ],
   "source": [
    "# run_hypothesis_test(config, df)\n",
    "\n",
    "result = run_hypothesis_test(config, df)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
