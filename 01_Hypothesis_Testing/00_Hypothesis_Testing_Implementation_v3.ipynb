{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"table-of-contents\"></a>\n",
    "# 📖 Table of Contents\n",
    "\n",
    "[🗂️ Data Setup](#data-setup)     \n",
    "- [🔍 Generate Data](#generate-data)      \n",
    "- [⚙️ Define Test Configuration](#define-test-config)\n",
    "\n",
    "[🛠️ Test Setup](#test-setup)    \n",
    "- [📋 Print Config Summary](#print-config)\n",
    "\n",
    "[📈 Inference](#inference)  \n",
    "- [🔍 Infer Distribution From Data](#infer-distribution)      \n",
    "- [📏 Infer Variance Equality](#infer-variance)    \n",
    "- [📊 Infer Parametric Flag](#infer-parametric)    \n",
    "\n",
    "[🧪 Hypothesis Testing](#hypothesis-testing)    \n",
    "- [🧭 Determine Test To Run](#determine-test)    \n",
    "- [🧠 Print Hypothesis Statement](#print-hypothesis)    \n",
    "- [🧪 Run Hypothesis Test](#run-test)    \n",
    "\n",
    "[📊 Test Summary](#test-summary)    \n",
    "\n",
    "[🚀 Full Pipeline](#full-pipeline)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>📖 Hypothesis Testing - Assumptions & Methods (Click to Expand)</strong></summary>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Test Type</th>\n",
    "      <th>Use Case</th>\n",
    "      <th>Parametric?</th>\n",
    "      <th>Assumptions</th>\n",
    "      <th>Non-Parametric Alternative</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>One-Sample t-test</td>\n",
    "      <td>Compare sample mean vs. known value</td>\n",
    "      <td>✅</td>\n",
    "      <td>Normality of sample</td>\n",
    "      <td>Sign test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Two-Sample t-test</td>\n",
    "      <td>Compare means of two independent groups</td>\n",
    "      <td>✅</td>\n",
    "      <td>- Normality (both groups)<br>- Equal variance (if pooled)<br>- Independence</td>\n",
    "      <td>Mann-Whitney U</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Paired t-test</td>\n",
    "      <td>Compare means of two related samples (before-after, matched)</td>\n",
    "      <td>✅</td>\n",
    "      <td>- Normality of *differences*<br>- No extreme outliers</td>\n",
    "      <td>Wilcoxon signed-rank</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Proportions z-test</td>\n",
    "      <td>Compare binary rates (e.g., CTR in A vs B)</td>\n",
    "      <td>✅</td>\n",
    "      <td>- np > 5, nq > 5 (sample size rule)<br>- Independence</td>\n",
    "      <td>Fisher’s exact</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Chi-Square Test</td>\n",
    "      <td>Categorical association (e.g., device type vs. AR adoption)</td>\n",
    "      <td>✅</td>\n",
    "      <td>- Expected count ≥ 5 in ≥ 80% of cells<br>- Independence</td>\n",
    "      <td>Fisher’s exact</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>ANOVA</td>\n",
    "      <td>Compare means across 3+ groups</td>\n",
    "      <td>✅</td>\n",
    "      <td>- Normality<br>- Equal variance<br>- Independence</td>\n",
    "      <td>Kruskal-Wallis</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Mann-Whitney U</td>\n",
    "      <td>Compare medians/ranks of two independent groups</td>\n",
    "      <td>❌</td>\n",
    "      <td>- Same shape distribution (ideally)<br>- Ordinal or continuous data</td>\n",
    "      <td>N/A</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Wilcoxon Signed-Rank</td>\n",
    "      <td>Paired version of Mann-Whitney (for related samples)</td>\n",
    "      <td>❌</td>\n",
    "      <td>- Symmetry in differences<br>- Ordinal or continuous</td>\n",
    "      <td>Sign test</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>📖 Hypothesis Test Selection Matrix (Click to Expand)</strong></summary>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Outcome Type</th>\n",
    "      <th>Group Relationship</th>\n",
    "      <th>Group Count</th>\n",
    "      <th>Outcome Distribution</th>\n",
    "      <th>Business Problem</th>\n",
    "      <th>Recommended Test</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>–</td>\n",
    "      <td>one-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Is average order value different from $50?</td>\n",
    "      <td>One-sample t-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>–</td>\n",
    "      <td>one-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>Is conversion rate different from 10%?</td>\n",
    "      <td>One-proportion z-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Do users who saw the new recommendation engine spend more time on site?</td>\n",
    "      <td>Two-sample t-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Is there a difference in revenue between users who got coupon A vs B?</td>\n",
    "      <td>Mann-Whitney U test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Did users spend more after homepage redesign?</td>\n",
    "      <td>Paired t-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Did time on site change after layout update (skewed)?</td>\n",
    "      <td>Wilcoxon signed-rank test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>Does a new CTA improve conversions?</td>\n",
    "      <td>Proportions z-test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>Do users convert more after adding trust badges?</td>\n",
    "      <td>McNemar’s test</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>categorical</td>\n",
    "      <td>independent</td>\n",
    "      <td>multi-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>Do plan choices differ between layout A/B/C?</td>\n",
    "      <td>Chi-square test</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><strong>📖 Hypothesis Test Selection Matrix (Click to Expand)</strong></summary>\n",
    "\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Outcome Type</th>\n",
    "      <th>Group Relationship</th>\n",
    "      <th>Group Count</th>\n",
    "      <th>Outcome Distribution</th>\n",
    "      <th>Business Problem</th>\n",
    "      <th>Recommended Test</th>\n",
    "      <th>Notes</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>–</td>\n",
    "      <td>one-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Is average order value different from $50?</td>\n",
    "      <td>One-sample t-test</td>\n",
    "      <td>Use Wilcoxon signed-rank if not normal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>–</td>\n",
    "      <td>one-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>Is conversion rate different from 10%?</td>\n",
    "      <td>One-proportion z-test</td>\n",
    "      <td>Use binomial exact test if n is small</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Do users who saw recs spend more time on site?</td>\n",
    "      <td>Two-sample t-test</td>\n",
    "      <td>Use Welch’s t-test if variances unequal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Is revenue different between coupon A vs B?</td>\n",
    "      <td>Mann-Whitney U test</td>\n",
    "      <td>Non-parametric; tests medians</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Did users spend more after redesign?</td>\n",
    "      <td>Paired t-test</td>\n",
    "      <td>Assumes differences are normal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Did time on site change (skewed)?</td>\n",
    "      <td>Wilcoxon signed-rank test</td>\n",
    "      <td>Use for non-normal paired diffs</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>Does new CTA improve conversion?</td>\n",
    "      <td>Proportions z-test</td>\n",
    "      <td>Chi-square for raw counts</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>binary</td>\n",
    "      <td>paired</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>Do users convert more after badges?</td>\n",
    "      <td>McNemar’s test</td>\n",
    "      <td>Use for paired binary outcomes</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>categorical</td>\n",
    "      <td>independent</td>\n",
    "      <td>multi-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>Do plan choices differ across layouts?</td>\n",
    "      <td>Chi-square test</td>\n",
    "      <td>Expected counts ≥5 in each cell</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>count</td>\n",
    "      <td>independent</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>Poisson</td>\n",
    "      <td>Do users add more items to cart?</td>\n",
    "      <td>Poisson / NB test</td>\n",
    "      <td>Use NB if overdispersion (variance > mean)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>multi-sample</td>\n",
    "      <td>normal</td>\n",
    "      <td>Does time spent differ across A/B/C?</td>\n",
    "      <td>ANOVA</td>\n",
    "      <td>Welch ANOVA if variances differ</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>continuous</td>\n",
    "      <td>independent</td>\n",
    "      <td>multi-sample</td>\n",
    "      <td>non-normal</td>\n",
    "      <td>Does spend differ across segments?</td>\n",
    "      <td>Kruskal-Wallis test</td>\n",
    "      <td>Non-parametric alternative to ANOVA</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>any</td>\n",
    "      <td>any</td>\n",
    "      <td>any</td>\n",
    "      <td>–</td>\n",
    "      <td>Is effect still significant after adjusting for device & region?</td>\n",
    "      <td>Regression (linear / logistic)</td>\n",
    "      <td>Use when controlling for covariates</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>any</td>\n",
    "      <td>any</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>What’s the probability that B beats A?</td>\n",
    "      <td>Bayesian A/B test</td>\n",
    "      <td>Reports posterior probability instead of p-value</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>any</td>\n",
    "      <td>any</td>\n",
    "      <td>two-sample</td>\n",
    "      <td>–</td>\n",
    "      <td>Is observed lift statistically rare?</td>\n",
    "      <td>Permutation / Bootstrap</td>\n",
    "      <td>Use when assumptions are violated</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-setup\"></a>\n",
    "# 🗂️ Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Settings\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "\n",
    "# Data Transformation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Stats Libraries\n",
    "from scipy.stats import (\n",
    "    ttest_1samp, ttest_rel, ttest_ind, wilcoxon, mannwhitneyu,\n",
    "    shapiro, chi2_contingency, f_oneway, kruskal, binom_test, fisher_exact\n",
    ")\n",
    "from statsmodels.stats.proportion import proportions_ztest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"generate-data\"></a>\n",
    "#### 🧪 Generate Data from Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_from_config(config, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    outcome = config['outcome_type']\n",
    "    group_count = config['group_count']\n",
    "    relationship = config['group_relationship']\n",
    "    size = config['sample_size']\n",
    "    effect = config['effect_size']\n",
    "    pop_mean = config.get('population_mean', 0)\n",
    "\n",
    "    # 1️⃣ One-sample case\n",
    "    if group_count == 'one-sample':\n",
    "        if outcome == 'continuous':\n",
    "            values = np.random.normal(loc=pop_mean + effect, scale=1.0, size=size)\n",
    "            df = pd.DataFrame({'value': values})\n",
    "        elif outcome == 'binary':\n",
    "            prob = pop_mean + effect\n",
    "            values = np.random.binomial(1, prob, size=size)\n",
    "            df = pd.DataFrame({'value': values})\n",
    "        else:\n",
    "            raise NotImplementedError(\"One-sample generation only supports continuous/binary for now.\")\n",
    "\n",
    "    # 2️⃣ Two-sample case\n",
    "    elif group_count == 'two-sample':\n",
    "        if relationship == 'independent':\n",
    "            if outcome == 'continuous':\n",
    "                A = np.random.normal(loc=5.0, scale=1.0, size=size)\n",
    "                B = np.random.normal(loc=5.0 + effect, scale=1.0, size=size)\n",
    "            elif outcome == 'binary':\n",
    "                A = np.random.binomial(1, 0.4, size=size)\n",
    "                B = np.random.binomial(1, 0.4 + effect, size=size)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            df = pd.DataFrame({\n",
    "                'group': ['A'] * size + ['B'] * size,\n",
    "                'value': np.concatenate([A, B])\n",
    "            })\n",
    "        \n",
    "        elif relationship == 'paired':\n",
    "            if outcome == 'continuous':\n",
    "                before = np.random.normal(loc=5.0, scale=1.0, size=size)\n",
    "                after = before + effect + np.random.normal(0, 0.5, size=size)\n",
    "            elif outcome == 'binary':\n",
    "                before = np.random.binomial(1, 0.4, size=size)\n",
    "                after = np.random.binomial(1, 0.4 + effect, size=size)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            df = pd.DataFrame({\n",
    "                'user_id': np.arange(size),\n",
    "                'group_A': before,\n",
    "                'group_B': after\n",
    "            })\n",
    "        else:\n",
    "            raise ValueError(\"Missing or invalid group relationship.\")\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(\"Multi-sample not supported yet.\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"define-test-config\"></a>\n",
    "#### ⚙️ Define Test Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': None,\n",
       " 'variance_equal': None,\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': None,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    'outcome_type': 'continuous',        # continuous, binary, categorical, count\n",
    "    'group_relationship': 'independent', # independent or paired\n",
    "    'group_count': 'two-sample',         # one-sample, two-sample, multi-sample\n",
    "    'distribution': None,                # normal or non-normal → to be inferred\n",
    "    'variance_equal': None,              # equal or unequal → to be inferred\n",
    "    'tail_type': 'two-tailed',           # or 'one-tailed'\n",
    "    'parametric': None,                  # True or False → to be inferred\n",
    "    'alpha': 0.05,                       # significance level\n",
    "    'sample_size': 100,                  # per group\n",
    "    'effect_size': 0.5,                  # for generating synthetic difference\n",
    "    # 'generated_data': None               # placeholder for attached df\n",
    "}\n",
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>5.496714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>4.861736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>5.647689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>6.523030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>4.765847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>B</td>\n",
       "      <td>5.885317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>B</td>\n",
       "      <td>4.616143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>B</td>\n",
       "      <td>5.653725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>B</td>\n",
       "      <td>5.558209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>B</td>\n",
       "      <td>4.357030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    group     value\n",
       "0       A  5.496714\n",
       "1       A  4.861736\n",
       "2       A  5.647689\n",
       "3       A  6.523030\n",
       "4       A  4.765847\n",
       "..    ...       ...\n",
       "195     B  5.885317\n",
       "196     B  4.616143\n",
       "197     B  5.653725\n",
       "198     B  5.558209\n",
       "199     B  4.357030\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_data_from_config(config)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test-setup\"></a>\n",
    "\n",
    "# 🛠️ Test Setup\n",
    "\n",
    "\n",
    "<details><summary><strong>📖 Test Settings Explanation (Click to Expand)</strong></summary>\n",
    "\n",
    "### 📊 **Test Type (test_type)**\n",
    "This setting defines the type of test you want to perform.\n",
    "\n",
    "- **one_sample**: Comparing the sample mean against a known value (e.g., a population mean).\n",
    "- **two_sample**: Comparing the means of two independent groups (e.g., A vs B).\n",
    "- **paired**: Comparing means from the same group at two different times (before vs after).\n",
    "- **proportions**: Comparing proportions (e.g., the conversion rates of two groups).\n",
    "\n",
    "**Example**: You might want to test if the mean age of two groups of people (Group A and Group B) differs, or if the proportion of people who converted in each group is different.\n",
    "\n",
    "### 📏 **Tail Type (tail_type)**\n",
    "This setting determines whether you are performing a one-tailed or two-tailed test.\n",
    "\n",
    "- **one_tailed**: You are testing if the value is greater than or less than the reference value (directional).\n",
    "- **two_tailed**: You are testing if the value is different from the reference value, either higher or lower (non-directional).\n",
    "\n",
    "**Example**:  \n",
    "- **One-tailed**: Testing if new treatment increases sales (you only care if it's greater).  \n",
    "- **Two-tailed**: Testing if there is any difference in sales between two treatments (it could be either an increase or decrease).\n",
    "\n",
    "### 🧮 **Parametric (parametric)**\n",
    "This setting indicates whether the test is **parametric** or **non-parametric**.\n",
    "\n",
    "- **True (Parametric)**: This means we assume that the data follows a certain distribution, often a **normal distribution**. The most common parametric tests are **t-tests** and **z-tests**. Parametric tests are generally more powerful if the assumptions are met.\n",
    "  \n",
    "- **False (Non-Parametric)**: Non-parametric tests don’t assume any specific distribution. These are used when the data doesn’t follow a normal distribution or when the sample size is small. Examples include **Mann-Whitney U** (alternative to the t-test) and **Wilcoxon Signed-Rank** (alternative to paired t-test).\n",
    "\n",
    "**Why does this matter?**  \n",
    "Parametric tests tend to be more powerful because they make assumptions about the distribution of the data (e.g., normality). Non-parametric tests are more flexible and can be used when these assumptions are not met, but they may be less powerful.\n",
    "\n",
    "### 📊 **Equal Variance (equal_variance)**\n",
    "This setting is used specifically for **two-sample t-tests**.\n",
    "\n",
    "- **True**: Assumes that the two groups have **equal variances** (i.e., the spread of data is the same in both groups). This is used for the **pooled t-test**.\n",
    "  \n",
    "- **False**: Assumes the two groups have **different variances**. This is used for the **Welch t-test**, which is more robust when the assumption of equal variances is violated.\n",
    "\n",
    "**Why is this important?**  \n",
    "If the variances are not equal, using a pooled t-test (which assumes equal variance) can lead to incorrect conclusions. The Welch t-test is safer when in doubt about the equality of variances.\n",
    "\n",
    "### 🔑 **Significance Level (alpha)**\n",
    "The **alpha** level is your **threshold for statistical significance**.\n",
    "\n",
    "- Commonly set at **0.05**, this means that you are willing to accept a 5% chance of wrongly rejecting the null hypothesis (i.e., a 5% chance of a Type I error).\n",
    "  \n",
    "- If the **p-value** (calculated from your test) is less than **alpha**, you reject the null hypothesis. If it's greater than alpha, you fail to reject the null hypothesis.\n",
    "\n",
    "**Example**:  \n",
    "- **alpha = 0.05** means there’s a 5% risk of concluding that a treatment has an effect when it actually doesn’t.\n",
    "\n",
    "### 🎯 **Putting It All Together**\n",
    "\n",
    "For instance, let's say you're testing if a new feature (Group A) increases user engagement compared to the existing feature (Group B). Here’s how each configuration works together:\n",
    "\n",
    "- **test_type** = `'two_sample'`: You're comparing two independent groups (A vs B).\n",
    "- **tail_type** = `'two_tailed'`: You’re testing if there’s any difference (increase or decrease) in engagement.\n",
    "- **parametric** = `True`: You assume the data is normally distributed, so a t-test will be appropriate.\n",
    "- **equal_variance** = `True`: You assume the two groups have equal variance, so you’ll use a pooled t-test.\n",
    "- **alpha** = `0.05`: You’re using a 5% significance level for your hypothesis test.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"print-config\"></a>\n",
    "#### 📋 Print Config Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_config_summary(config):\n",
    "    print(\"📋 Hypothesis Test Configuration Summary\\n\")\n",
    "\n",
    "    print(f\"🔸 Outcome Type           : {config['outcome_type']}\")\n",
    "    print(f\"🔸 Group Relationship      : {config['group_relationship']}\")\n",
    "    print(f\"🔸 Group Count             : {config['group_count']}\")\n",
    "    print(f\"🔸 Distribution of Outcome : {config['distribution']}\")\n",
    "    print(f\"🔸 Equal Variance          : {config['variance_equal']}\")\n",
    "    print(f\"🔸 Parametric Test         : {config['parametric']}\")\n",
    "    print(f\"🔸 Tail Type               : {config['tail_type']}\")\n",
    "    print(f\"🔸 Significance Level α    : {config['alpha']}\")\n",
    "\n",
    "    print(\"\\n🧠 Inference Summary:\")\n",
    "    if config['group_count'] == 'one-sample':\n",
    "        print(\"→ This is a one-sample test comparing a sample to a known value.\")\n",
    "    elif config['group_count'] == 'two-sample':\n",
    "        if config['group_relationship'] == 'independent':\n",
    "            print(\"→ Comparing two independent groups (A vs B).\")\n",
    "        elif config['group_relationship'] == 'paired':\n",
    "            print(\"→ Comparing paired measurements (before vs after, same users).\")\n",
    "    \n",
    "    # print(\"\\n🧪 Selected Test:\")\n",
    "    # print(f\"✅ {determine_test_to_run(config)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': None,\n",
       " 'variance_equal': None,\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': None,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Hypothesis Test Configuration Summary\n",
      "\n",
      "🔸 Outcome Type           : continuous\n",
      "🔸 Group Relationship      : independent\n",
      "🔸 Group Count             : two-sample\n",
      "🔸 Distribution of Outcome : None\n",
      "🔸 Equal Variance          : None\n",
      "🔸 Parametric Test         : None\n",
      "🔸 Tail Type               : two-tailed\n",
      "🔸 Significance Level α    : 0.05\n",
      "\n",
      "🧠 Inference Summary:\n",
      "→ Comparing two independent groups (A vs B).\n"
     ]
    }
   ],
   "source": [
    "config\n",
    "print_config_summary(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"inference\"></a>\n",
    "\n",
    "# 📈 Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"infer-distribution\"></a>\n",
    "#### 🔍 Infer Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "def infer_distribution_from_data(config, df):\n",
    "    group_count = config['group_count']\n",
    "    relationship = config['group_relationship']\n",
    "    outcome = config['outcome_type']\n",
    "\n",
    "    if outcome != 'continuous':\n",
    "        config['distribution'] = 'NA'\n",
    "        return config\n",
    "\n",
    "    if group_count == 'one-sample':\n",
    "        stat, p = shapiro(df['value'])\n",
    "        config['distribution'] = 'normal' if p > 0.05 else 'non-normal'\n",
    "        return config\n",
    "    \n",
    "    elif group_count == 'two-sample':\n",
    "        if relationship == 'independent':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "        elif relationship == 'paired':\n",
    "            a = df['group_A']\n",
    "            b = df['group_B']\n",
    "        else:\n",
    "            config['distribution'] = 'NA'\n",
    "            return config\n",
    "\n",
    "        p1 = shapiro(a)[1]\n",
    "        p2 = shapiro(b)[1]\n",
    "        config['distribution'] = 'normal' if (p1 > 0.05 and p2 > 0.05) else 'non-normal'\n",
    "        return config\n",
    "    \n",
    "    else:\n",
    "        config['distribution'] = 'NA'\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"infer-variance\"></a>\n",
    "#### 📏 Infer Variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "def infer_variance_equality(config, df):\n",
    "    if config['group_count'] != 'two-sample' or config['group_relationship'] != 'independent':\n",
    "        config['variance_equal'] = 'NA'\n",
    "        return config\n",
    "\n",
    "    a = df[df['group'] == 'A']['value']\n",
    "    b = df[df['group'] == 'B']['value']\n",
    "    stat, p = levene(a, b)\n",
    "    config['variance_equal'] = 'equal' if p > 0.05 else 'unequal'\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"infer-parametric\"></a>\n",
    "#### 📏 Infer Parametric Flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_parametric_flag(config):\n",
    "    if config['outcome_type'] != 'continuous':\n",
    "        config['parametric'] = 'NA'\n",
    "        return config\n",
    "\n",
    "    is_normal = config['distribution'] == 'normal'\n",
    "    is_equal_var = config['variance_equal'] in ['equal', 'NA']  # NA = not required for paired\n",
    "\n",
    "    config['parametric'] = True if is_normal and is_equal_var else False\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outcome_type': 'continuous',\n",
       " 'group_relationship': 'independent',\n",
       " 'group_count': 'two-sample',\n",
       " 'distribution': None,\n",
       " 'variance_equal': None,\n",
       " 'tail_type': 'two-tailed',\n",
       " 'parametric': None,\n",
       " 'alpha': 0.05,\n",
       " 'sample_size': 100,\n",
       " 'effect_size': 0.5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Hypothesis Test Configuration Summary\n",
      "\n",
      "🔸 Outcome Type           : continuous\n",
      "🔸 Group Relationship      : independent\n",
      "🔸 Group Count             : two-sample\n",
      "🔸 Distribution of Outcome : None\n",
      "🔸 Equal Variance          : None\n",
      "🔸 Parametric Test         : None\n",
      "🔸 Tail Type               : two-tailed\n",
      "🔸 Significance Level α    : 0.05\n",
      "\n",
      "🧠 Inference Summary:\n",
      "→ Comparing two independent groups (A vs B).\n"
     ]
    }
   ],
   "source": [
    "config\n",
    "print_config_summary(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"hypothesis-testing\"></a>\n",
    "<h1>🧪 Hypothesis Testing</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"determine-test\"></a>\n",
    "#### 🧭 Determine Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mann_whitney_u'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_test_to_run(config):\n",
    "    outcome = config['outcome_type']\n",
    "    group_rel = config['group_relationship']\n",
    "    group_count = config['group_count']\n",
    "    dist = config['distribution']\n",
    "    equal_var = config['variance_equal']\n",
    "    parametric = config['parametric']\n",
    "\n",
    "    # 1️⃣ One-sample cases\n",
    "    if group_count == 'one-sample':\n",
    "        if outcome == 'continuous':\n",
    "            return 'one_sample_ttest' if dist == 'normal' else 'one_sample_wilcoxon'\n",
    "        elif outcome == 'binary':\n",
    "            return 'one_proportion_ztest'\n",
    "    \n",
    "    # 2️⃣ Two-sample independent\n",
    "    if group_count == 'two-sample' and group_rel == 'independent':\n",
    "        if outcome == 'continuous':\n",
    "            if parametric:\n",
    "                return 'two_sample_ttest_pooled' if equal_var == 'equal' else 'two_sample_ttest_welch'\n",
    "            else:\n",
    "                return 'mann_whitney_u'\n",
    "        elif outcome == 'binary':\n",
    "            return 'two_proportion_ztest'\n",
    "        elif outcome == 'categorical':\n",
    "            return 'chi_square'\n",
    "\n",
    "    # 3️⃣ Two-sample paired\n",
    "    if group_count == 'two-sample' and group_rel == 'paired':\n",
    "        if outcome == 'continuous':\n",
    "            return 'paired_ttest' if parametric else 'wilcoxon_signed_rank'\n",
    "        elif outcome == 'binary':\n",
    "            return 'mcnemar'\n",
    "\n",
    "    # 4️⃣ Multi-group continuous\n",
    "    if group_count == 'multi-sample' and outcome == 'continuous':\n",
    "        return 'anova' if dist == 'normal' else 'kruskal_wallis'\n",
    "\n",
    "    # 5️⃣ Multi-group categorical\n",
    "    if group_count == 'multi-sample' and outcome == 'categorical':\n",
    "        return 'chi_square'\n",
    "\n",
    "    # 6️⃣ Count data\n",
    "    if outcome == 'count':\n",
    "        return 'poisson_test'\n",
    "\n",
    "    # 7️⃣ Adjusted models or Bayesian\n",
    "    # Could be added later\n",
    "\n",
    "    return 'test_not_found'\n",
    "determine_test_to_run(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"print-hypothesis\"></a>\n",
    "#### 🧠 Print Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Hypothesis Statement\n",
      "\n",
      "H₀: The average (or proportion) is the same across groups A and B.\n",
      "H₁: The average (or proportion) differs between groups.\n"
     ]
    }
   ],
   "source": [
    "def print_hypothesis_statement(config):\n",
    "    test = determine_test_to_run(config)\n",
    "    outcome = config['outcome_type']\n",
    "    tail = config['tail_type']\n",
    "    group_count = config['group_count']\n",
    "    rel = config['group_relationship']\n",
    "\n",
    "    print(\"🧪 Hypothesis Statement\\n\")\n",
    "\n",
    "    # One-sample (mean or proportion)\n",
    "    if test == 'one_sample_ttest':\n",
    "        print(\"H₀: The average outcome equals the benchmark value.\")\n",
    "        print(\"H₁: The average outcome is different from the benchmark.\" if tail == 'two-tailed' else \"H₁: The average outcome is greater/less than the benchmark.\")\n",
    "    \n",
    "    elif test == 'one_proportion_ztest':\n",
    "        print(\"H₀: The proportion equals the expected baseline.\")\n",
    "        print(\"H₁: The proportion is different from the baseline.\" if tail == 'two-tailed' else \"H₁: The proportion is greater/less than the baseline.\")\n",
    "\n",
    "    # Two-sample, independent\n",
    "    elif test in ['two_sample_ttest_pooled', 'two_sample_ttest_welch', 'mann_whitney_u', 'two_proportion_ztest']:\n",
    "        print(\"H₀: The average (or proportion) is the same across groups A and B.\")\n",
    "        print(\"H₁: The average (or proportion) differs between groups.\" if tail == 'two-tailed' else \"H₁: Group B is greater/less than group A.\")\n",
    "    \n",
    "    # Paired\n",
    "    elif test in ['paired_ttest', 'wilcoxon_signed_rank']:\n",
    "        print(\"H₀: There is no average difference between the paired values (before vs after).\")\n",
    "        print(\"H₁: There is an average difference in the paired values.\" if tail == 'two-tailed' else \"H₁: After is greater/less than before.\")\n",
    "\n",
    "    elif test == 'mcnemar':\n",
    "        print(\"H₀: Proportion of success before = after.\")\n",
    "        print(\"H₁: Proportion of success changed after treatment.\")\n",
    "\n",
    "    # Multi-group\n",
    "    elif test in ['anova', 'kruskal_wallis']:\n",
    "        print(\"H₀: All group means (or distributions) are equal.\")\n",
    "        print(\"H₁: At least one group differs.\")\n",
    "\n",
    "    elif test == 'chi_square':\n",
    "        print(\"H₀: Distribution of categories is the same across groups.\")\n",
    "        print(\"H₁: At least one category is distributed differently across groups.\")\n",
    "\n",
    "    # Count data\n",
    "    elif test == 'poisson_test':\n",
    "        print(\"H₀: Count rate (λ) is equal across groups.\")\n",
    "        print(\"H₁: Count rate differs between groups.\")\n",
    "\n",
    "    # Bayesian / permutation\n",
    "    elif test == 'bayesian_ab':\n",
    "        print(\"Posterior probability that Group B is better than Group A.\")\n",
    "    elif test == 'permutation_test':\n",
    "        print(\"H₀: The observed difference is due to chance.\")\n",
    "        print(\"H₁: The observed difference is rare under random shuffling.\")\n",
    "\n",
    "    else:\n",
    "        print(\"❓ Could not determine hypothesis statements for test:\", test)\n",
    "print_hypothesis_statement(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"run-test\"></a>\n",
    "#### 🧪 Run Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hypothesis_test(config, df):\n",
    "    test_name = determine_test_to_run(config)\n",
    "    alpha = config.get('alpha', 0.05)\n",
    "\n",
    "    result = {\n",
    "        'test': test_name,\n",
    "        'statistic': None,\n",
    "        'p_value': None,\n",
    "        'significant': None,\n",
    "        'alpha': alpha\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        if test_name == 'one_sample_ttest':\n",
    "            stat, p = ttest_1samp(df['value'], config['population_mean'])\n",
    "\n",
    "        elif test_name == 'one_sample_wilcoxon':\n",
    "            stat, p = wilcoxon(df['value'] - config['population_mean'])\n",
    "\n",
    "        elif test_name == 'one_proportion_ztest':\n",
    "            x = np.sum(df['value'])\n",
    "            n = len(df)\n",
    "            stat, p = proportions_ztest(x, n, value=config['population_mean'])\n",
    "\n",
    "        elif test_name == 'two_sample_ttest_pooled':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "            stat, p = ttest_ind(a, b, equal_var=True)\n",
    "\n",
    "        elif test_name == 'two_sample_ttest_welch':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "            stat, p = ttest_ind(a, b, equal_var=False)\n",
    "\n",
    "        elif test_name == 'mann_whitney_u':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "            stat, p = mannwhitneyu(a, b, alternative='two-sided')\n",
    "\n",
    "        elif test_name == 'paired_ttest':\n",
    "            stat, p = ttest_rel(df['group_A'], df['group_B'])\n",
    "\n",
    "        elif test_name == 'wilcoxon_signed_rank':\n",
    "            stat, p = wilcoxon(df['group_A'], df['group_B'])\n",
    "\n",
    "        elif test_name == 'two_proportion_ztest':\n",
    "            a = df[df['group'] == 'A']['value']\n",
    "            b = df[df['group'] == 'B']['value']\n",
    "            counts = [np.sum(a), np.sum(b)]\n",
    "            nobs = [len(a), len(b)]\n",
    "            stat, p = proportions_ztest(count=counts, nobs=nobs)\n",
    "\n",
    "        elif test_name == 'mcnemar':\n",
    "            # Contingency table: [ [before+after], [before only], [after only], [neither] ]\n",
    "            both = np.sum((df['group_A'] == 1) & (df['group_B'] == 1))\n",
    "            before_only = np.sum((df['group_A'] == 1) & (df['group_B'] == 0))\n",
    "            after_only = np.sum((df['group_A'] == 0) & (df['group_B'] == 1))\n",
    "            neither = np.sum((df['group_A'] == 0) & (df['group_B'] == 0))\n",
    "            table = np.array([[both, before_only], [after_only, neither]])\n",
    "            stat, p = chi2_contingency(table, correction=True)[:2]\n",
    "\n",
    "        elif test_name == 'anova':\n",
    "            groups = [g['value'].values for _, g in df.groupby('group')]\n",
    "            stat, p = f_oneway(*groups)\n",
    "\n",
    "        elif test_name == 'kruskal_wallis':\n",
    "            groups = [g['value'].values for _, g in df.groupby('group')]\n",
    "            stat, p = kruskal(*groups)\n",
    "\n",
    "        elif test_name == 'chi_square':\n",
    "            contingency = pd.crosstab(df['group'], df['value'])\n",
    "            stat, p, _, _ = chi2_contingency(contingency)\n",
    "\n",
    "        else:\n",
    "            warnings.warn(f\"Test not implemented: {test_name}\")\n",
    "            return result\n",
    "\n",
    "        result['statistic'] = stat\n",
    "        result['p_value'] = p\n",
    "        result['significant'] = p < alpha\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"Error running test: {e}\")\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'mann_whitney_u',\n",
       " 'statistic': 3300.0,\n",
       " 'p_value': 3.288061008165521e-05,\n",
       " 'significant': True,\n",
       " 'alpha': 0.05}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hypothesis_test(config, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test-summary\"></a>\n",
    "# 📊 Test Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"full-pipeline\"></a>\n",
    "# 🚀 Full Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#table-of-contents)\n",
    "___\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
